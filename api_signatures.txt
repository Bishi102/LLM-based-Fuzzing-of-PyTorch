torch.Tensor.lt_(other)
torch.fft.rfftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.sort(input, dim=-1, descending=False, stable=False, *, out=None)
torch.nn.functional.elu(input: torch.Tensor, alpha: float = 1.0, inplace: bool = False)
torch.Tensor.clip(min=None, max=None)
torch.Tensor.baddbmm_(batch1, batch2, *, beta=1, alpha=1)
torch.Tensor.ceil_()
torch.Tensor.abs()
torch.polar(abs, angle, *, out=None)
torch.rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.nn.init.constant_(tensor: torch.Tensor, val: float)
torch.Tensor.masked_select(mask)
torch.QUInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Tensor.ceil()
torch.Tensor.isinf()
torch.meshgrid(*tensors, indexing: Optional[str] = None)
torch.nn.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None)
torch.rot90(input, k=1, dims=[0,1])
torch.Tensor.sin_()
torch.Tensor.sinh()
torch.fft.fft2(input, s=None, dim=(-2, -1), norm=None, *, out=None)
torch.eq(input, other, *, out=None)
torch.random.seed()
torch.arccosh(input, *, out=None)
torch.linalg.pinv(A, *, atol=None, rtol=None, hermitian=False, out=None)
torch.Tensor.logit_()
torch.Tensor.tolist()
torch.special.polygamma(n, input, *, out=None)
torch.jit.unused(fn)
torch.distributed.is_torchelastic_launched()
torch.ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.fft.ifftshift(input, dim=None)
torch.linalg.eigvalsh(A, UPLO='L', *, out=None)
torch.fmin(input, other, *, out=None)
torch.Tensor.positive()
torch.nn.PoissonNLLLoss(log_input: bool = True, full: bool = False, size_average=None, eps: float = 1e-08, reduce=None, reduction: str = 'mean')
torch.nn.LazyInstanceNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.special.erfc(input, *, out=None)
torch.Tensor.tanh()
torch.Tensor.arctanh_(other)
torch.flipud(input)
torch.Tensor.logical_and_()
torch.LongStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.pow(input, exponent, *, out=None)
torch.Tensor.dequantize()
torch.distributions.transforms.ExpTransform(cache_size=0)
torch.multiply(input, other, *, out=None)
torch.resolve_neg(input)
torch.Tensor.sparse_dim()
torch.Tensor.cuda(device=None, non_blocking=False, memory_format=torch.preserve_format)
torch.Tensor.arctan()
torch.take(input, index)
torch.nn.Unfold(kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1)
torch.Tensor.igamma_(other)
torch.nn.functional.normalize(input: torch.Tensor, p: float = 2.0, dim: int = 1, eps: float = 1e-12, out: Optional[torch.Tensor] = None)
torch.nn.functional.alpha_dropout(input: torch.Tensor, p: float = 0.5, training: bool = False, inplace: bool = False)
torch.diff(input, n=1, dim=-1, prepend=None, append=None)
torch.Tensor.addcdiv_(tensor1, tensor2, *, value=1)
torch.distributions.transforms.SoftmaxTransform(cache_size=0)
torch.Tensor.random_(from=0, to=None, *, generator=None)
torch.nn.functional.max_unpool3d(input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None)
torch.trace(input)
torch.Tensor.reciprocal()
torch.Tensor.element_size()
torch.Tensor.bitwise_not()
torch.nn.AdaptiveMaxPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False)
torch.amin(input, dim, keepdim=False, *, out=None)
torch.Tensor.long(memory_format=torch.preserve_format)
torch.Tensor.triu_(diagonal=0)
torch.logaddexp2(input, other, *, out=None)
torch.Tensor.bitwise_xor_()
torch.Tensor.resolve_neg()
torch.unsqueeze(input, dim)
<<<<<<< HEAD
torch.as_tensor(data, dtype=None, device=None)
torch.Tensor.clone(*, memory_format=torch.preserve_format)
torch.special.digamma(input, *, out=None)
torch.special.expit(input, *, out=None)
torch.Tensor.index_add(dim, index, source, *, alpha=1)
torch.linalg.matrix_power(A, n, *, out=None)
torch.index_select(input, dim, index, *, out=None)
torch.logical_not(input, *, out=None)
torch.ne(input, other, *, out=None)
torch.nn.ReplicationPad1d(padding: Union[int, Tuple[int, int]])
torch.BFloat16Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.nn.functional.relu6(input, inplace=False)
torch.nn.init.orthogonal_(tensor, gain=1, generator: Optional[torch._C.Generator] = None)
torch.nn.AlphaDropout(p: float = 0.5, inplace: bool = False)
torch.scatter_add(input, dim, index, src)
torch.nn.functional.adaptive_avg_pool3d(input: torch.Tensor, output_size: None)
torch.Tensor.cholesky_inverse(upper=False)
torch.Tensor.byte(memory_format=torch.preserve_format)
torch.special.erfcx(input, *, out=None)
torch.matrix_exp(A)
torch.Tensor.to_sparse(sparseDims)
torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.special.zeta(input, other, *, out=None)
torch.Tensor.square_()
torch.nn.KLDivLoss(size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False)
torch.tanh(input, *, out=None)
torch.Tensor.addmv(mat, vec, *, beta=1, alpha=1)
=======
torch.use_deterministic_algorithms(mode: bool, *, warn_only: bool = False)
torch.utils.data.BatchSampler(sampler: Union[torch.utils.data.sampler.Sampler[int], Iterable[int]], batch_size: int, drop_last: bool)
torch.utils.data.ChainDataset(datasets: Iterable[torch.utils.data.dataset.Dataset])
torch.utils.data.ConcatDataset(datasets: Iterable[torch.utils.data.dataset.Dataset])
torch.utils.data.DataLoader(dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')
torch.utils.data.RandomSampler(data_source: Sized, replacement: bool = False, num_samples: Optional[int] = None, generator=None)
torch.utils.data.Sampler(data_source: Optional[Sized] = None)
torch.utils.data.SequentialSampler(data_source: Sized)
torch.utils.data.Subset(dataset: torch.utils.data.dataset.Dataset[+T_co], indices: Sequence[int])
torch.utils.data.SubsetRandomSampler(indices: Sequence[int], generator=None)
torch.utils.data.TensorDataset(*tensors: torch.Tensor)
torch.utils.data.WeightedRandomSampler(weights: Sequence[float], num_samples: int, replacement: bool = True, generator=None)
torch.utils.data.distributed.DistributedSampler(dataset: torch.utils.data.dataset.Dataset, num_replicas: Optional[int] = None, rank: Optional[int] = None, shuffle: bool = True, seed: int = 0, drop_last: bool = False)
torch.utils.data.get_worker_info()
torch.utils.data.random_split(dataset: torch.utils.data.dataset.Dataset[~T], lengths: Sequence[Union[int, float]], generator: Optional[torch._C.Generator] = <torch._C.Generator object at 0x10937d7f0>)
torch.utils.dlpack.from_dlpack(ext_tensor)
torch.utils.dlpack.to_dlpack(tensor)
torch.utils.model_zoo.load_url()
torch.vander(x, N=None, increasing=False)
torch.var(input, dim=None, *, correction=1, keepdim=False, out=None)
torch.var_mean(input, dim=None, *, correction=1, keepdim=False, out=None)
torch.vdot(input, other, *, out=None)
torch.view_as_complex(input)
torch.vsplit(input, indices_or_sections)
torch.vstack(tensors, *, out=None)
torch.where(condition, input, other, *, out=None)
torch.xlogy(input, other, *, out=None)
torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.zeros_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
>>>>>>> 7c03f2d99c67d9a9f4569e9778634a39467171b4
