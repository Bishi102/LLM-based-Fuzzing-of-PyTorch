torch.Tensor.lt_(other)
torch.fft.rfftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.sort(input, dim=-1, descending=False, stable=False, *, out=None)
torch.nn.functional.elu(input: torch.Tensor, alpha: float = 1.0, inplace: bool = False)
torch.Tensor.clip(min=None, max=None)
torch.Tensor.baddbmm_(batch1, batch2, *, beta=1, alpha=1)
torch.Tensor.ceil_()
torch.Tensor.abs()
torch.polar(abs, angle, *, out=None)
torch.rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.nn.init.constant_(tensor: torch.Tensor, val: float)
torch.Tensor.masked_select(mask)
torch.QUInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Tensor.ceil()
torch.Tensor.isinf()
torch.meshgrid(*tensors, indexing: Optional[str] = None)
torch.nn.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None)
torch.rot90(input, k=1, dims=[0,1])
torch.Tensor.sin_()
torch.Tensor.sinh()
torch.fft.fft2(input, s=None, dim=(-2, -1), norm=None, *, out=None)
torch.eq(input, other, *, out=None)
torch.random.seed()
torch.arccosh(input, *, out=None)
torch.linalg.pinv(A, *, atol=None, rtol=None, hermitian=False, out=None)
torch.Tensor.logit_()
torch.Tensor.tolist()
torch.special.polygamma(n, input, *, out=None)
torch.jit.unused(fn)
torch.distributed.is_torchelastic_launched()
torch.ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)
torch.fft.ifftshift(input, dim=None)
torch.linalg.eigvalsh(A, UPLO='L', *, out=None)
torch.fmin(input, other, *, out=None)
torch.Tensor.positive()
torch.nn.PoissonNLLLoss(log_input: bool = True, full: bool = False, size_average=None, eps: float = 1e-08, reduce=None, reduction: str = 'mean')
torch.nn.LazyInstanceNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None)
torch.special.erfc(input, *, out=None)
torch.Tensor.tanh()
torch.Tensor.arctanh_(other)
torch.flipud(input)
torch.Tensor.logical_and_()
torch.LongStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.pow(input, exponent, *, out=None)
torch.Tensor.dequantize()
torch.distributions.transforms.ExpTransform(cache_size=0)
torch.multiply(input, other, *, out=None)
torch.resolve_neg(input)
torch.Tensor.sparse_dim()
torch.Tensor.cuda(device=None, non_blocking=False, memory_format=torch.preserve_format)
torch.Tensor.arctan()
torch.take(input, index)
torch.nn.Unfold(kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1)
torch.Tensor.igamma_(other)
torch.nn.functional.normalize(input: torch.Tensor, p: float = 2.0, dim: int = 1, eps: float = 1e-12, out: Optional[torch.Tensor] = None)
torch.nn.functional.alpha_dropout(input: torch.Tensor, p: float = 0.5, training: bool = False, inplace: bool = False)
torch.diff(input, n=1, dim=-1, prepend=None, append=None)
torch.Tensor.addcdiv_(tensor1, tensor2, *, value=1)
torch.distributions.transforms.SoftmaxTransform(cache_size=0)
torch.Tensor.random_(from=0, to=None, *, generator=None)
torch.nn.functional.max_unpool3d(input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None)
torch.trace(input)
torch.Tensor.reciprocal()
torch.Tensor.element_size()
torch.Tensor.bitwise_not()
torch.nn.AdaptiveMaxPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False)
torch.amin(input, dim, keepdim=False, *, out=None)
torch.Tensor.long(memory_format=torch.preserve_format)
torch.Tensor.triu_(diagonal=0)
torch.logaddexp2(input, other, *, out=None)
torch.Tensor.bitwise_xor_()
torch.Tensor.resolve_neg()
torch.unsqueeze(input, dim)
torch.as_tensor(data, dtype=None, device=None)
torch.Tensor.clone(*, memory_format=torch.preserve_format)
torch.special.digamma(input, *, out=None)
torch.special.expit(input, *, out=None)
torch.Tensor.index_add(dim, index, source, *, alpha=1)
torch.linalg.matrix_power(A, n, *, out=None)
torch.index_select(input, dim, index, *, out=None)
torch.logical_not(input, *, out=None)
torch.ne(input, other, *, out=None)
torch.nn.ReplicationPad1d(padding: Union[int, Tuple[int, int]])
torch.BFloat16Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.nn.functional.relu6(input, inplace=False)
torch.nn.init.orthogonal_(tensor, gain=1, generator: Optional[torch._C.Generator] = None)
torch.nn.AlphaDropout(p: float = 0.5, inplace: bool = False)
torch.scatter_add(input, dim, index, src)
torch.nn.functional.adaptive_avg_pool3d(input: torch.Tensor, output_size: None)
torch.Tensor.cholesky_inverse(upper=False)
torch.Tensor.byte(memory_format=torch.preserve_format)
torch.special.erfcx(input, *, out=None)
torch.matrix_exp(A)
torch.Tensor.to_sparse(sparseDims)
torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
torch.special.zeta(input, other, *, out=None)
torch.Tensor.square_()
torch.nn.KLDivLoss(size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False)
torch.tanh(input, *, out=None)
torch.Tensor.addmv(mat, vec, *, beta=1, alpha=1)
