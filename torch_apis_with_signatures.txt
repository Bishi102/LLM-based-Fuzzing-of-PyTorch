torch.Any(*args, **kwds)
torch.BFloat16Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.BoolStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.ByteStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Callable(*args, **kwargs)
torch.CharStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.ComplexDoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.ComplexFloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Dict(*args, **kwargs)
torch.DoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.FloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.GradScaler(device: 'str' = 'cuda', init_scale: 'float' = 65536.0, growth_factor: 'float' = 2.0, backoff_factor: 'float' = 0.5, growth_interval: 'int' = 2000, enabled: 'bool' = True) -> 'None'
torch.HalfStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.IntStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.List(*args, **kwargs)
torch.LongStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Optional(*args, **kwds)
torch.QInt32Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.QInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.QUInt2x4Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.QUInt4x2Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.QUInt8Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Set(*args, **kwargs)
torch.ShortStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Size(iterable=(), /)
torch.Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.SymBool(node)
torch.SymFloat(node)
torch.SymInt(node)
torch.Tuple(*args, **kwargs)
torch.TypedStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.Union(*args, **kwds)
torch.UntypedStorage(*args, **kwargs)
torch.align_tensors(*tensors)
torch.amp.GradScaler(device: 'str' = 'cuda', init_scale: 'float' = 65536.0, growth_factor: 'float' = 2.0, backoff_factor: 'float' = 0.5, growth_interval: 'int' = 2000, enabled: 'bool' = True) -> 'None'
torch.amp.autocast(device_type: str, dtype: Optional[torch.dtype] = None, enabled: bool = True, cache_enabled: Optional[bool] = None)
torch.amp.autocast_mode.Any(*args, **kwds)
torch.amp.autocast_mode.Optional(*args, **kwds)
torch.amp.autocast_mode.autocast(device_type: str, dtype: Optional[torch.dtype] = None, enabled: bool = True, cache_enabled: Optional[bool] = None)
torch.amp.autocast_mode.autocast_decorator(autocast_instance, func)
torch.amp.autocast_mode.custom_bwd(bwd=None, *, device_type: str)
torch.amp.autocast_mode.custom_fwd(fwd=None, *, device_type: str, cast_inputs: Optional[torch.dtype] = None)
torch.amp.autocast_mode.is_autocast_available(device_type: str) -> bool
torch.amp.custom_bwd(bwd=None, *, device_type: str)
torch.amp.custom_fwd(fwd=None, *, device_type: str, cast_inputs: Optional[torch.dtype] = None)
torch.amp.grad_scaler.Any(*args, **kwds)
torch.amp.grad_scaler.Dict(*args, **kwargs)
torch.amp.grad_scaler.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.amp.grad_scaler.GradScaler(device: 'str' = 'cuda', init_scale: 'float' = 65536.0, growth_factor: 'float' = 2.0, backoff_factor: 'float' = 0.5, growth_interval: 'int' = 2000, enabled: 'bool' = True) -> 'None'
torch.amp.grad_scaler.Iterable(*args, **kwargs)
torch.amp.grad_scaler.List(*args, **kwargs)
torch.amp.grad_scaler.OptState(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.amp.grad_scaler.Optional(*args, **kwds)
torch.amp.grad_scaler.Tuple(*args, **kwargs)
torch.amp.grad_scaler.Union(*args, **kwds)
torch.amp.grad_scaler.cast(typ, val)
torch.amp.grad_scaler.overload(func)
torch.amp.is_autocast_available(device_type: str) -> bool
torch.ao.nn.intrinsic.BNReLU2d(batch_norm, relu)
torch.ao.nn.intrinsic.BNReLU3d(batch_norm, relu)
torch.ao.nn.intrinsic.ConvAdd2d(conv, add)
torch.ao.nn.intrinsic.ConvAddReLU2d(conv, add, relu)
torch.ao.nn.intrinsic.ConvBn1d(conv, bn)
torch.ao.nn.intrinsic.ConvBn2d(conv, bn)
torch.ao.nn.intrinsic.ConvBn3d(conv, bn)
torch.ao.nn.intrinsic.ConvBnReLU1d(conv, bn, relu)
torch.ao.nn.intrinsic.ConvBnReLU2d(conv, bn, relu)
torch.ao.nn.intrinsic.ConvBnReLU3d(conv, bn, relu)
torch.ao.nn.intrinsic.ConvReLU1d(conv, relu)
torch.ao.nn.intrinsic.ConvReLU2d(conv, relu)
torch.ao.nn.intrinsic.ConvReLU3d(conv, relu)
torch.ao.nn.intrinsic.LinearBn1d(linear, bn)
torch.ao.nn.intrinsic.LinearLeakyReLU(linear, leaky_relu)
torch.ao.nn.intrinsic.LinearReLU(linear, relu)
torch.ao.nn.intrinsic.LinearTanh(linear, tanh)
torch.ao.nn.intrinsic.modules.BNReLU2d(batch_norm, relu)
torch.ao.nn.intrinsic.modules.BNReLU3d(batch_norm, relu)
torch.ao.nn.intrinsic.modules.ConvAdd2d(conv, add)
torch.ao.nn.intrinsic.modules.ConvAddReLU2d(conv, add, relu)
torch.ao.nn.intrinsic.modules.ConvBn1d(conv, bn)
torch.ao.nn.intrinsic.modules.ConvBn2d(conv, bn)
torch.ao.nn.intrinsic.modules.ConvBn3d(conv, bn)
torch.ao.nn.intrinsic.modules.ConvBnReLU1d(conv, bn, relu)
torch.ao.nn.intrinsic.modules.ConvBnReLU2d(conv, bn, relu)
torch.ao.nn.intrinsic.modules.ConvBnReLU3d(conv, bn, relu)
torch.ao.nn.intrinsic.modules.ConvReLU1d(conv, relu)
torch.ao.nn.intrinsic.modules.ConvReLU2d(conv, relu)
torch.ao.nn.intrinsic.modules.ConvReLU3d(conv, relu)
torch.ao.nn.intrinsic.modules.LinearBn1d(linear, bn)
torch.ao.nn.intrinsic.modules.LinearLeakyReLU(linear, leaky_relu)
torch.ao.nn.intrinsic.modules.LinearReLU(linear, relu)
torch.ao.nn.intrinsic.modules.LinearTanh(linear, tanh)
torch.ao.nn.intrinsic.modules.fused.BNReLU2d(batch_norm, relu)
torch.ao.nn.intrinsic.modules.fused.BNReLU3d(batch_norm, relu)
torch.ao.nn.intrinsic.modules.fused.BatchNorm1d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.ao.nn.intrinsic.modules.fused.BatchNorm2d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.ao.nn.intrinsic.modules.fused.BatchNorm3d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.ao.nn.intrinsic.modules.fused.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.ao.nn.intrinsic.modules.fused.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.ao.nn.intrinsic.modules.fused.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.ao.nn.intrinsic.modules.fused.ConvAdd2d(conv, add)
torch.ao.nn.intrinsic.modules.fused.ConvAddReLU2d(conv, add, relu)
torch.ao.nn.intrinsic.modules.fused.ConvBn1d(conv, bn)
torch.ao.nn.intrinsic.modules.fused.ConvBn2d(conv, bn)
torch.ao.nn.intrinsic.modules.fused.ConvBn3d(conv, bn)
torch.ao.nn.intrinsic.modules.fused.ConvBnReLU1d(conv, bn, relu)
torch.ao.nn.intrinsic.modules.fused.ConvBnReLU2d(conv, bn, relu)
torch.ao.nn.intrinsic.modules.fused.ConvBnReLU3d(conv, bn, relu)
torch.ao.nn.intrinsic.modules.fused.ConvReLU1d(conv, relu)
torch.ao.nn.intrinsic.modules.fused.ConvReLU2d(conv, relu)
torch.ao.nn.intrinsic.modules.fused.ConvReLU3d(conv, relu)
torch.ao.nn.intrinsic.modules.fused.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.ao.nn.intrinsic.modules.fused.LinearBn1d(linear, bn)
torch.ao.nn.intrinsic.modules.fused.LinearLeakyReLU(linear, leaky_relu)
torch.ao.nn.intrinsic.modules.fused.LinearReLU(linear, relu)
torch.ao.nn.intrinsic.modules.fused.LinearTanh(linear, tanh)
torch.ao.nn.intrinsic.modules.fused.ReLU(inplace: bool = False)
torch.ao.nn.intrinsic.modules.fused.type_before_parametrizations(module: torch.nn.modules.module.Module) -> type
torch.ao.nn.intrinsic.qat.ConvBn1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.ConvBn2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.ConvBn3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.ConvBnReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.ConvBnReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.ConvBnReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.LinearBn1d(in_features, out_features, bias=True, eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.LinearReLU(in_features, out_features, bias=True, qconfig=None)
torch.ao.nn.intrinsic.qat.freeze_bn_stats(mod)
torch.ao.nn.intrinsic.qat.modules.ConvBn1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvBn2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvBn3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvBnReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvBnReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvBnReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.modules.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.modules.LinearBn1d(in_features, out_features, bias=True, eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.LinearReLU(in_features, out_features, bias=True, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.ao.nn.intrinsic.qat.modules.conv_fused.Parameter(data=None, requires_grad=True)
torch.ao.nn.intrinsic.qat.modules.conv_fused.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.ao.nn.intrinsic.qat.modules.conv_fused.freeze_bn_stats(mod)
torch.ao.nn.intrinsic.qat.modules.conv_fused.fuse_conv_bn_weights(conv_w: 'torch.Tensor', conv_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'Optional[torch.Tensor]', bn_b: 'Optional[torch.Tensor]', transpose: 'bool' = False) -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.ao.nn.intrinsic.qat.modules.conv_fused.update_bn_stats(mod)
torch.ao.nn.intrinsic.qat.modules.freeze_bn_stats(mod)
torch.ao.nn.intrinsic.qat.modules.linear_fused.LinearBn1d(in_features, out_features, bias=True, eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.linear_fused.Parameter(data=None, requires_grad=True)
torch.ao.nn.intrinsic.qat.modules.linear_fused.fuse_linear_bn_weights(linear_w: 'torch.Tensor', linear_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'torch.Tensor', bn_b: 'torch.Tensor') -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.ao.nn.intrinsic.qat.modules.linear_relu.LinearReLU(in_features, out_features, bias=True, qconfig=None)
torch.ao.nn.intrinsic.qat.modules.update_bn_stats(mod)
torch.ao.nn.intrinsic.qat.update_bn_stats(mod)
torch.ao.nn.intrinsic.quantized.BNReLU2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.BNReLU3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.ConvAdd2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.ConvAddReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.LinearLeakyReLU(in_features, out_features, negative_slope, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.LinearTanh(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.dynamic.modules.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.modules.BNReLU2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.BNReLU3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.ConvAdd2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.ConvAddReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.LinearLeakyReLU(in_features, out_features, negative_slope, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.modules.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.modules.LinearTanh(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAdd2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAddReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.intrinsic.quantized.modules.conv_relu.fuse_conv_bn_weights(conv_w: 'torch.Tensor', conv_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'Optional[torch.Tensor]', bn_b: 'Optional[torch.Tensor]', transpose: 'bool' = False) -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearLeakyReLU(in_features, out_features, negative_slope, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearTanh(in_features, out_features, bias=True, dtype=torch.qint8)
torch.ao.nn.qat.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None, qconfig=None) -> None
torch.ao.nn.qat.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None, include_last_offset=False, padding_idx=None, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.dynamic.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.dynamic.modules.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.dynamic.modules.linear.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None, qconfig=None) -> None
torch.ao.nn.qat.modules.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None, include_last_offset=False, padding_idx=None, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.conv.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.conv.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.conv.Tuple(*args, **kwargs)
torch.ao.nn.qat.modules.conv.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.ao.nn.qat.modules.conv.Union(*args, **kwds)
torch.ao.nn.qat.modules.embedding_ops.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None, qconfig=None) -> None
torch.ao.nn.qat.modules.embedding_ops.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None, include_last_offset=False, padding_idx=None, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.linear.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.ao.nn.qat.modules.linear.LinearReLU(linear, relu)
torch.ao.nn.qat.modules.linear.is_parametrized(module: torch.nn.modules.module.Module, tensor_name: Optional[str] = None) -> bool
torch.ao.nn.qat.modules.linear.transfer_parametrizations_and_params(from_module: torch.nn.modules.module.Module, to_module: torch.nn.modules.module.Module, tensor_name: Optional[str] = None) -> torch.nn.modules.module.Module
torch.ao.nn.qat.modules.linear.type_before_parametrizations(module: torch.nn.modules.module.Module) -> type
torch.ao.nn.quantizable.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantizable.LSTMCell(input_dim: int, hidden_dim: int, bias: bool = True, device=None, dtype=None) -> None
torch.ao.nn.quantizable.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantizable.modules.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantizable.modules.LSTMCell(input_dim: int, hidden_dim: int, bias: bool = True, device=None, dtype=None) -> None
torch.ao.nn.quantizable.modules.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantizable.modules.activation.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantizable.modules.activation.Optional(*args, **kwds)
torch.ao.nn.quantizable.modules.activation.Tuple(*args, **kwargs)
torch.ao.nn.quantizable.modules.rnn.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantizable.modules.rnn.LSTMCell(input_dim: int, hidden_dim: int, bias: bool = True, device=None, dtype=None) -> None
torch.ao.nn.quantizable.modules.rnn.Optional(*args, **kwds)
torch.ao.nn.quantizable.modules.rnn.Tuple(*args, **kwargs)
torch.ao.nn.quantized.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None) -> None
torch.ao.nn.quantized.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.quantized.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None)
torch.ao.nn.quantized.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.DeQuantize(*args, **kwargs) -> None
torch.ao.nn.quantized.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.ao.nn.quantized.ELU(scale, zero_point, alpha=1.0)
torch.ao.nn.quantized.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, dtype=torch.quint8) -> None
torch.ao.nn.quantized.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'sum', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, dtype=torch.quint8) -> None
torch.ao.nn.quantized.FXFloatFunctional(*args, **kwargs) -> None
torch.ao.nn.quantized.FloatFunctional()
torch.ao.nn.quantized.GroupNorm(num_groups, num_channels, weight, bias, scale, zero_point, eps=1e-05, affine=True, device=None, dtype=None) -> None
torch.ao.nn.quantized.Hardswish(scale, zero_point, device=None, dtype=None)
torch.ao.nn.quantized.InstanceNorm1d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.InstanceNorm2d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.InstanceNorm3d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.LayerNorm(normalized_shape, weight, bias, scale, zero_point, eps=1e-05, elementwise_affine=True, device=None, dtype=None) -> None
torch.ao.nn.quantized.LeakyReLU(scale: float, zero_point: int, negative_slope: float = 0.01, inplace: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.ao.nn.quantized.MaxPool2d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.ao.nn.quantized.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.PReLU(output_scale: float, output_zero_point: int, num_parameters: int = 1) -> None
torch.ao.nn.quantized.QFunctional()
torch.ao.nn.quantized.Quantize(scale, zero_point, dtype, factory_kwargs=None)
torch.ao.nn.quantized.ReLU6(inplace=False)
torch.ao.nn.quantized.Sigmoid(output_scale: float, output_zero_point: int)
torch.ao.nn.quantized.Softmax(dim=None, scale=1.0, zero_point=0)
torch.ao.nn.quantized.dynamic.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, reduce_range=True)
torch.ao.nn.quantized.dynamic.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.GRU(*args, **kwargs)
torch.ao.nn.quantized.dynamic.GRUCell(input_size, hidden_size, bias=True, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.LSTM(*args, **kwargs)
torch.ao.nn.quantized.dynamic.LSTMCell(*args, **kwargs)
torch.ao.nn.quantized.dynamic.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, reduce_range=True)
torch.ao.nn.quantized.dynamic.modules.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.GRU(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.GRUCell(input_size, hidden_size, bias=True, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.LSTM(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.LSTMCell(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, reduce_range=True)
torch.ao.nn.quantized.dynamic.modules.conv.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.conv.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.dynamic.modules.linear.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.rnn.Dict(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.rnn.GRU(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.rnn.GRUCell(input_size, hidden_size, bias=True, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.rnn.LSTM(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.rnn.LSTMCell(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.rnn.List(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.rnn.Optional(*args, **kwds)
torch.ao.nn.quantized.dynamic.modules.rnn.PackedParameter(param)
torch.ao.nn.quantized.dynamic.modules.rnn.PackedSequence(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None)
torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase(mode, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.rnn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.rnn.RNNCellBase(input_size, hidden_size, bias=True, num_chunks=4, dtype=torch.qint8)
torch.ao.nn.quantized.dynamic.modules.rnn.Tuple(*args, **kwargs)
torch.ao.nn.quantized.dynamic.modules.rnn.Union(*args, **kwds)
torch.ao.nn.quantized.dynamic.modules.rnn.apply_permutation(tensor: torch.Tensor, permutation: torch.Tensor, dim: int = 1) -> torch.Tensor
torch.ao.nn.quantized.dynamic.modules.rnn.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.ao.nn.quantized.dynamic.modules.rnn.pack_weight_bias(qweight, bias, dtype)
torch.ao.nn.quantized.functional.List(*args, **kwargs)
torch.ao.nn.quantized.functional.Optional(*args, **kwds)
torch.ao.nn.quantized.functional.adaptive_avg_pool2d(input: torch.Tensor, output_size: None) -> torch.Tensor
torch.ao.nn.quantized.functional.adaptive_avg_pool3d(input: torch.Tensor, output_size: None) -> torch.Tensor
torch.ao.nn.quantized.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.ao.nn.quantized.functional.avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.ao.nn.quantized.functional.celu(input: torch.Tensor, scale: float, zero_point: int, alpha: float = 1.0) -> torch.Tensor
torch.ao.nn.quantized.functional.clamp(input: torch.Tensor, min_: float, max_: float) -> torch.Tensor
torch.ao.nn.quantized.functional.conv1d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)
torch.ao.nn.quantized.functional.conv2d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)
torch.ao.nn.quantized.functional.conv3d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)
torch.ao.nn.quantized.functional.elu(input: torch.Tensor, scale: float, zero_point: int, alpha: float = 1.0) -> torch.Tensor
torch.ao.nn.quantized.functional.hardsigmoid(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.ao.nn.quantized.functional.hardswish(input: torch.Tensor, scale: float, zero_point: int) -> torch.Tensor
torch.ao.nn.quantized.functional.hardtanh(input: torch.Tensor, min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False) -> torch.Tensor
torch.ao.nn.quantized.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.ao.nn.quantized.functional.leaky_relu(input: torch.Tensor, negative_slope: float = 0.01, inplace: bool = False, scale: Optional[float] = None, zero_point: Optional[int] = None)
torch.ao.nn.quantized.functional.linear(input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None, scale: Optional[float] = None, zero_point: Optional[int] = None) -> torch.Tensor
torch.ao.nn.quantized.functional.max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)
torch.ao.nn.quantized.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)
torch.ao.nn.quantized.functional.threshold(input: torch.Tensor, threshold: float, value: float) -> torch.Tensor
torch.ao.nn.quantized.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.ao.nn.quantized.functional.upsample_bilinear(input, size=None, scale_factor=None)
torch.ao.nn.quantized.functional.upsample_nearest(input, size=None, scale_factor=None)
torch.ao.nn.quantized.modules.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.quantized.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.DeQuantize(*args, **kwargs) -> None
torch.ao.nn.quantized.modules.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.ao.nn.quantized.modules.ELU(scale, zero_point, alpha=1.0)
torch.ao.nn.quantized.modules.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, dtype=torch.quint8) -> None
torch.ao.nn.quantized.modules.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'sum', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, dtype=torch.quint8) -> None
torch.ao.nn.quantized.modules.FXFloatFunctional(*args, **kwargs) -> None
torch.ao.nn.quantized.modules.FloatFunctional()
torch.ao.nn.quantized.modules.GroupNorm(num_groups, num_channels, weight, bias, scale, zero_point, eps=1e-05, affine=True, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.Hardswish(scale, zero_point, device=None, dtype=None)
torch.ao.nn.quantized.modules.InstanceNorm1d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.InstanceNorm2d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.InstanceNorm3d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.LayerNorm(normalized_shape, weight, bias, scale, zero_point, eps=1e-05, elementwise_affine=True, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.LeakyReLU(scale: float, zero_point: int, negative_slope: float = 0.01, inplace: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.ao.nn.quantized.modules.MaxPool2d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.ao.nn.quantized.modules.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.PReLU(output_scale: float, output_zero_point: int, num_parameters: int = 1) -> None
torch.ao.nn.quantized.modules.QFunctional()
torch.ao.nn.quantized.modules.Quantize(scale, zero_point, dtype, factory_kwargs=None)
torch.ao.nn.quantized.modules.ReLU6(inplace=False)
torch.ao.nn.quantized.modules.Sigmoid(output_scale: float, output_zero_point: int)
torch.ao.nn.quantized.modules.Softmax(dim=None, scale=1.0, zero_point=0)
torch.ao.nn.quantized.modules.activation.ELU(scale, zero_point, alpha=1.0)
torch.ao.nn.quantized.modules.activation.Hardswish(scale, zero_point, device=None, dtype=None)
torch.ao.nn.quantized.modules.activation.LeakyReLU(scale: float, zero_point: int, negative_slope: float = 0.01, inplace: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.activation.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.activation.PReLU(output_scale: float, output_zero_point: int, num_parameters: int = 1) -> None
torch.ao.nn.quantized.modules.activation.ReLU6(inplace=False)
torch.ao.nn.quantized.modules.activation.Sigmoid(output_scale: float, output_zero_point: int)
torch.ao.nn.quantized.modules.activation.Softmax(dim=None, scale=1.0, zero_point=0)
torch.ao.nn.quantized.modules.activation.warn(message, category=None, stacklevel=1, source=None)
torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.ao.nn.quantized.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.conv.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.conv.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.conv.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.conv.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.conv.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.ao.nn.quantized.modules.conv.List(*args, **kwargs)
torch.ao.nn.quantized.modules.conv.Optional(*args, **kwds)
torch.ao.nn.quantized.modules.conv.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.ao.nn.quantized.modules.conv.WeightedQuantizedModule(*args, **kwargs) -> None
torch.ao.nn.quantized.modules.conv.fuse_conv_bn_weights(conv_w: 'torch.Tensor', conv_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'Optional[torch.Tensor]', bn_b: 'Optional[torch.Tensor]', transpose: 'bool' = False) -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.ao.nn.quantized.modules.dropout.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.ao.nn.quantized.modules.embedding_ops.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, dtype=torch.quint8) -> None
torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'sum', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, dtype=torch.quint8) -> None
torch.ao.nn.quantized.modules.embedding_ops.EmbeddingPackedParams(num_embeddings, embedding_dim, dtype=torch.quint8)
torch.ao.nn.quantized.modules.embedding_ops.List(*args, **kwargs)
torch.ao.nn.quantized.modules.embedding_ops.Optional(*args, **kwds)
torch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional(*args, **kwargs) -> None
torch.ao.nn.quantized.modules.functional_modules.FloatFunctional()
torch.ao.nn.quantized.modules.functional_modules.List(*args, **kwargs)
torch.ao.nn.quantized.modules.functional_modules.QFunctional()
torch.ao.nn.quantized.modules.linear.Iterable()
torch.ao.nn.quantized.modules.linear.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.ao.nn.quantized.modules.linear.LinearPackedParams(dtype=torch.qint8)
torch.ao.nn.quantized.modules.linear.Optional(*args, **kwds)
torch.ao.nn.quantized.modules.linear.WeightedQuantizedModule(*args, **kwargs) -> None
torch.ao.nn.quantized.modules.linear.fuse_linear_bn_weights(linear_w: 'torch.Tensor', linear_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'torch.Tensor', bn_b: 'torch.Tensor') -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.ao.nn.quantized.modules.linear.type_before_parametrizations(module: torch.nn.modules.module.Module) -> type
torch.ao.nn.quantized.modules.normalization.GroupNorm(num_groups, num_channels, weight, bias, scale, zero_point, eps=1e-05, affine=True, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.normalization.InstanceNorm1d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.normalization.InstanceNorm2d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.normalization.InstanceNorm3d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.normalization.LayerNorm(normalized_shape, weight, bias, scale, zero_point, eps=1e-05, elementwise_affine=True, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.rnn.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.ao.nn.quantized.modules.utils.WeightedQuantizedModule(*args, **kwargs) -> None
torch.ao.nn.quantized.reference.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.ConvTranspose1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None, device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.GRU(*args, **kwargs)
torch.ao.nn.quantized.reference.GRUCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.LSTM(*args, **kwargs)
torch.ao.nn.quantized.reference.LSTMCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.Linear(in_features: int, out_features: int, bias_: bool = True, device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.RNNCell(input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = 'tanh', device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.ConvTranspose1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None, device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.GRU(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.GRUCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.LSTM(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.LSTMCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.Linear(in_features: int, out_features: int, bias_: bool = True, device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.RNNCell(input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = 'tanh', device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.conv.Any(*args, **kwds)
torch.ao.nn.quantized.reference.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.conv.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.conv.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.conv.ConvTranspose1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.conv.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.conv.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.conv.Dict(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.conv.List(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.conv.Optional(*args, **kwds)
torch.ao.nn.quantized.reference.modules.conv.ReferenceQuantizedModule(*args, **kwargs) -> None
torch.ao.nn.quantized.reference.modules.linear.Any(*args, **kwds)
torch.ao.nn.quantized.reference.modules.linear.Dict(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.linear.Linear(in_features: int, out_features: int, bias_: bool = True, device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None, weight_qparams: Optional[Dict[str, Any]] = None)
torch.ao.nn.quantized.reference.modules.linear.Optional(*args, **kwds)
torch.ao.nn.quantized.reference.modules.linear.ReferenceQuantizedModule(*args, **kwargs) -> None
torch.ao.nn.quantized.reference.modules.rnn.Any(*args, **kwds)
torch.ao.nn.quantized.reference.modules.rnn.Dict(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.rnn.GRU(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.rnn.GRUCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.rnn.LSTM(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.rnn.LSTMCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.rnn.Optional(*args, **kwds)
torch.ao.nn.quantized.reference.modules.rnn.PackedSequence(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None)
torch.ao.nn.quantized.reference.modules.rnn.RNNBase(mode: str, input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, proj_size: int = 0, device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.rnn.RNNCell(input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = 'tanh', device=None, dtype=None, weight_qparams_dict: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.rnn.RNNCellBase(input_size: int, hidden_size: int, bias: bool, num_chunks: int, device=None, dtype=None, weight_qparams_dict=None) -> None
torch.ao.nn.quantized.reference.modules.rnn.Tuple(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.rnn.get_quantized_weight(module, wn)
torch.ao.nn.quantized.reference.modules.sparse.Any(*args, **kwds)
torch.ao.nn.quantized.reference.modules.sparse.Dict(*args, **kwargs)
torch.ao.nn.quantized.reference.modules.sparse.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.sparse.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None, device=None, dtype=None, weight_qparams: Optional[Dict[str, Any]] = None) -> None
torch.ao.nn.quantized.reference.modules.sparse.Optional(*args, **kwds)
torch.ao.nn.quantized.reference.modules.sparse.ReferenceQuantizedModule(*args, **kwargs) -> None
torch.ao.nn.quantized.reference.modules.utils.ReferenceQuantizedModule(*args, **kwargs) -> None
torch.ao.nn.sparse.quantized.Linear(in_features, out_features, row_block_size, col_block_size, bias=True, dtype=torch.qint8)
torch.ao.nn.sparse.quantized.LinearPackedParams(row_block_size=1, col_block_size=4, dtype=torch.qint8)
torch.ao.nn.sparse.quantized.dynamic.Linear(in_features, out_features, row_block_size, col_block_size, bias=True, dtype=torch.qint8)
torch.ao.nn.sparse.quantized.dynamic.linear.Linear(in_features, out_features, row_block_size, col_block_size, bias=True, dtype=torch.qint8)
torch.ao.nn.sparse.quantized.dynamic.linear.LinearBlockSparsePattern(row_block_size=1, col_block_size=4)
torch.ao.nn.sparse.quantized.dynamic.linear.Optional(*args, **kwds)
torch.ao.nn.sparse.quantized.linear.Linear(in_features, out_features, row_block_size, col_block_size, bias=True, dtype=torch.qint8)
torch.ao.nn.sparse.quantized.linear.LinearPackedParams(row_block_size=1, col_block_size=4, dtype=torch.qint8)
torch.ao.nn.sparse.quantized.linear.Optional(*args, **kwds)
torch.ao.nn.sparse.quantized.utils.LinearBlockSparsePattern(row_block_size=1, col_block_size=4)
torch.ao.quantization.Callable(*args, **kwargs)
torch.ao.quantization.DeQuantStub(qconfig=None)
torch.ao.quantization.FakeQuantize(observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=None, quant_max=None, is_dynamic=False, **observer_kwargs)
torch.ao.quantization.FakeQuantizeBase()
torch.ao.quantization.FixedQParamsFakeQuantize(observer)
torch.ao.quantization.FixedQParamsObserver(scale, zero_point, dtype=torch.quint8, qscheme=torch.per_tensor_affine, quant_min=0, quant_max=255, is_dynamic=False, **kwargs)
torch.ao.quantization.FusedMovingAvgObsFakeQuantize(observer: Any = <class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min: int = 0, quant_max: int = 255, **observer_kwargs: Any) -> None
torch.ao.quantization.HistogramObserver(bins: int = 2048, upsample_rate: int = 128, dtype: torch.dtype = torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.List(*args, **kwargs)
torch.ao.quantization.MinMaxObserver(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01, ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.NoopObserver(dtype=torch.float16, custom_op_name='') -> None
torch.ao.quantization.ObserverBase(dtype, is_dynamic=False)
torch.ao.quantization.ObserverOrFakeQuantize(*args, **kwargs)
torch.ao.quantization.Optional(*args, **kwds)
torch.ao.quantization.PerChannelMinMaxObserver(ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.PlaceholderObserver(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.ao.quantization.QConfig(activation, weight)
torch.ao.quantization.QConfigAny(*args, **kwargs)
torch.ao.quantization.QConfigDynamic(activation=<class 'torch.nn.modules.linear.Identity'>, weight=<class 'torch.nn.modules.linear.Identity'>)
torch.ao.quantization.QConfigMapping()
torch.ao.quantization.QuantStub(qconfig=None)
torch.ao.quantization.QuantType(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.ao.quantization.QuantWrapper(module)
torch.ao.quantization.RecordingObserver(dtype=torch.quint8)
torch.ao.quantization.ReuseInputObserver()
torch.ao.quantization.Tuple(*args, **kwargs)
torch.ao.quantization.UniformQuantizationObserverBase(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.Union(*args, **kwds)
torch.ao.quantization.add_quant_dequant(module)
torch.ao.quantization.allow_exported_model_train_eval(model: torch.fx.graph_module.GraphModule)
torch.ao.quantization.convert(module, mapping=None, inplace=False, remove_qconfig=True, is_reference=False, convert_custom_config_dict=None, use_precomputed_fake_quant=False)
torch.ao.quantization.convert_dynamic_jit(model, inplace=False, debug=False, preserved_attrs=None)
torch.ao.quantization.convert_jit(model, inplace=False, debug=False, preserved_attrs=None)
torch.ao.quantization.default_affine_fixed_qparams_fake_quant(*args, **keywords)
torch.ao.quantization.default_affine_fixed_qparams_observer(*args, **keywords)
torch.ao.quantization.default_debug_observer(dtype=torch.quint8)
torch.ao.quantization.default_dynamic_fake_quant(*args, **keywords)
torch.ao.quantization.default_dynamic_quant_observer(*args, **keywords)
torch.ao.quantization.default_embedding_fake_quant(*args, **keywords)
torch.ao.quantization.default_embedding_fake_quant_4bit(*args, **keywords)
torch.ao.quantization.default_eval_fn(model, calib_data)
torch.ao.quantization.default_fake_quant(*args, **keywords)
torch.ao.quantization.default_fixed_qparams_range_0to1_fake_quant(*args, **keywords)
torch.ao.quantization.default_fixed_qparams_range_0to1_observer(*args, **keywords)
torch.ao.quantization.default_fixed_qparams_range_neg1to1_fake_quant(*args, **keywords)
torch.ao.quantization.default_fixed_qparams_range_neg1to1_observer(*args, **keywords)
torch.ao.quantization.default_float_qparams_observer(*args, **keywords)
torch.ao.quantization.default_float_qparams_observer_4bit(*args, **keywords)
torch.ao.quantization.default_fused_act_fake_quant(*args, **keywords)
torch.ao.quantization.default_fused_per_channel_wt_fake_quant(*args, **keywords)
torch.ao.quantization.default_fused_wt_fake_quant(*args, **keywords)
torch.ao.quantization.default_histogram_fake_quant(*args, **keywords)
torch.ao.quantization.default_histogram_observer(*args, **keywords)
torch.ao.quantization.default_observer(*args, **keywords)
torch.ao.quantization.default_per_channel_weight_fake_quant(*args, **keywords)
torch.ao.quantization.default_per_channel_weight_observer(*args, **keywords)
torch.ao.quantization.default_placeholder_observer(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.ao.quantization.default_reuse_input_observer()
torch.ao.quantization.default_symmetric_fixed_qparams_fake_quant(*args, **keywords)
torch.ao.quantization.default_symmetric_fixed_qparams_observer(*args, **keywords)
torch.ao.quantization.default_weight_fake_quant(*args, **keywords)
torch.ao.quantization.default_weight_observer(*args, **keywords)
torch.ao.quantization.disable_fake_quant(mod)
torch.ao.quantization.disable_observer(mod)
torch.ao.quantization.enable_fake_quant(mod)
torch.ao.quantization.enable_observer(mod)
torch.ao.quantization.fake_quantize.ABC()
torch.ao.quantization.fake_quantize.Any(*args, **kwds)
torch.ao.quantization.fake_quantize.FakeQuantize(observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=None, quant_max=None, is_dynamic=False, **observer_kwargs)
torch.ao.quantization.fake_quantize.FakeQuantizeBase()
torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize(observer)
torch.ao.quantization.fake_quantize.FixedQParamsObserver(scale, zero_point, dtype=torch.quint8, qscheme=torch.per_tensor_affine, quant_min=0, quant_max=255, is_dynamic=False, **kwargs)
torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize(observer: Any = <class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min: int = 0, quant_max: int = 255, **observer_kwargs: Any) -> None
torch.ao.quantization.fake_quantize.HistogramObserver(bins: int = 2048, upsample_rate: int = 128, dtype: torch.dtype = torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.fake_quantize.Module(*args, **kwargs) -> None
torch.ao.quantization.fake_quantize.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.fake_quantize.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01, ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.fake_quantize.Tuple(*args, **kwargs)
torch.ao.quantization.fake_quantize.abstractmethod(funcobj)
torch.ao.quantization.fake_quantize.default_affine_fixed_qparams_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_dynamic_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_embedding_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_embedding_fake_quant_4bit(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fixed_qparams_range_0to1_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fixed_qparams_range_0to1_observer(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fixed_qparams_range_neg1to1_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fixed_qparams_range_neg1to1_observer(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fused_act_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_histogram_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_symmetric_fixed_qparams_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.default_weight_fake_quant(*args, **keywords)
torch.ao.quantization.fake_quantize.disable_fake_quant(mod)
torch.ao.quantization.fake_quantize.disable_observer(mod)
torch.ao.quantization.fake_quantize.enable_fake_quant(mod)
torch.ao.quantization.fake_quantize.enable_observer(mod)
torch.ao.quantization.fake_quantize.fused_per_channel_wt_fake_quant_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.fake_quantize.fused_wt_fake_quant_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.fuse_conv_bn(is_qat, conv, bn)
torch.ao.quantization.fuse_conv_bn_jit(model, inplace=False)
torch.ao.quantization.fuse_conv_bn_relu(is_qat, conv, bn, relu)
torch.ao.quantization.fuse_convtranspose_bn(is_qat, convt, bn)
torch.ao.quantization.fuse_linear_bn(is_qat, linear, bn)
torch.ao.quantization.fuse_modules(model, modules_to_fuse, inplace=False, fuser_func=<function fuse_known_modules at 0x0000024A61D5B1C0>, fuse_custom_config_dict=None)
torch.ao.quantization.fuse_modules_qat(model, modules_to_fuse, inplace=False, fuser_func=<function fuse_known_modules at 0x0000024A61D5B1C0>, fuse_custom_config_dict=None)
torch.ao.quantization.fused_per_channel_wt_fake_quant_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.fused_wt_fake_quant_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.fuser_method_mappings.Any(*args, **kwds)
torch.ao.quantization.fuser_method_mappings.Callable(*args, **kwargs)
torch.ao.quantization.fuser_method_mappings.Dict(*args, **kwargs)
torch.ao.quantization.fuser_method_mappings.List(*args, **kwargs)
torch.ao.quantization.fuser_method_mappings.MatchAllNode()
torch.ao.quantization.fuser_method_mappings.Optional(*args, **kwds)
torch.ao.quantization.fuser_method_mappings.Pattern(*args, **kwargs)
torch.ao.quantization.fuser_method_mappings.Tuple(*args, **kwargs)
torch.ao.quantization.fuser_method_mappings.Type(*args, **kwargs)
torch.ao.quantization.fuser_method_mappings.Union(*args, **kwds)
torch.ao.quantization.fuser_method_mappings.fuse_conv_bn(is_qat, conv, bn)
torch.ao.quantization.fuser_method_mappings.fuse_conv_bn_relu(is_qat, conv, bn, relu)
torch.ao.quantization.fuser_method_mappings.fuse_convtranspose_bn(is_qat, convt, bn)
torch.ao.quantization.fuser_method_mappings.fuse_linear_bn(is_qat, linear, bn)
torch.ao.quantization.fuser_method_mappings.get_combined_dict(default_dict, additional_dict)
torch.ao.quantization.fuser_method_mappings.get_fuser_method(op_list, additional_fuser_method_mapping=None)
torch.ao.quantization.fuser_method_mappings.get_fuser_method_new(op_pattern: typing.Union[typing.Callable, typing.Tuple[typing.Callable, typing.Callable], typing.Tuple[typing.Callable, typing.Tuple[typing.Callable, typing.Callable]], typing.Any], fuser_method_mapping: Dict[Union[Callable, Tuple[Callable, Callable], Tuple[Callable, Tuple[Callable, Callable]], Any], Union[torch.nn.modules.container.Sequential, Callable]])
torch.ao.quantization.generate_numeric_debug_handle(graph_module: torch.fx.graph_module.GraphModule) -> None
torch.ao.quantization.get_default_compare_output_module_list() -> Set[Callable]
torch.ao.quantization.get_default_custom_config_dict()
torch.ao.quantization.get_default_dynamic_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_default_dynamic_sparse_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_default_float_to_quantized_operator_mappings() -> Dict[Union[Callable, str], Callable]
torch.ao.quantization.get_default_qat_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_default_qat_qconfig(backend='x86', version=1)
torch.ao.quantization.get_default_qat_qconfig_dict(backend='x86', version=1)
torch.ao.quantization.get_default_qat_qconfig_mapping(backend='x86', version=1) -> 'QConfigMapping'
torch.ao.quantization.get_default_qconfig(backend='x86', version=0)
torch.ao.quantization.get_default_qconfig_dict(backend='x86', version=0)
torch.ao.quantization.get_default_qconfig_mapping(backend='x86', version=0) -> 'QConfigMapping'
torch.ao.quantization.get_default_qconfig_propagation_list() -> Set[Callable]
torch.ao.quantization.get_default_static_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_default_static_quant_reference_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_default_static_sparse_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_dynamic_quant_module_class(float_module_class: Callable, additional_dynamic_quant_mapping: Optional[Dict[Callable, Any]] = None) -> Any
torch.ao.quantization.get_embedding_qat_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_embedding_static_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.get_fuser_method(op_list, additional_fuser_method_mapping=None)
torch.ao.quantization.get_fuser_method_new(op_pattern: typing.Union[typing.Callable, typing.Tuple[typing.Callable, typing.Callable], typing.Tuple[typing.Callable, typing.Tuple[typing.Callable, typing.Callable]], typing.Any], fuser_method_mapping: Dict[Union[Callable, Tuple[Callable, Callable], Tuple[Callable, Tuple[Callable, Callable]], Any], Union[torch.nn.modules.container.Sequential, Callable]])
torch.ao.quantization.get_observer_state_dict(mod)
torch.ao.quantization.get_quantized_operator(float_op: Union[Callable, str]) -> Callable
torch.ao.quantization.get_static_quant_module_class(float_module_class: Callable, additional_static_quant_mapping: Optional[Dict[Callable, Any]] = None, is_reference: bool = False) -> Any
torch.ao.quantization.load_observer_state_dict(mod, obs_dict)
torch.ao.quantization.move_exported_model_to_eval(model: torch.fx.graph_module.GraphModule)
torch.ao.quantization.move_exported_model_to_train(model: torch.fx.graph_module.GraphModule)
torch.ao.quantization.no_observer_set() -> Set[Any]
torch.ao.quantization.observer.ABC()
torch.ao.quantization.observer.ABCMeta(name, bases, namespace, **kwargs)
torch.ao.quantization.observer.Any(*args, **kwds)
torch.ao.quantization.observer.Dict(*args, **kwargs)
torch.ao.quantization.observer.FixedQParamsObserver(scale, zero_point, dtype=torch.quint8, qscheme=torch.per_tensor_affine, quant_min=0, quant_max=255, is_dynamic=False, **kwargs)
torch.ao.quantization.observer.HistogramObserver(bins: int = 2048, upsample_rate: int = 128, dtype: torch.dtype = torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.observer.List(*args, **kwargs)
torch.ao.quantization.observer.MinMaxObserver(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.observer.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01, ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.observer.NoopObserver(dtype=torch.float16, custom_op_name='') -> None
torch.ao.quantization.observer.ObserverBase(dtype, is_dynamic=False)
torch.ao.quantization.observer.Optional(*args, **kwds)
torch.ao.quantization.observer.PerChannelMinMaxObserver(ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.observer.PlaceholderObserver(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.ao.quantization.observer.RecordingObserver(dtype=torch.quint8)
torch.ao.quantization.observer.ReuseInputObserver()
torch.ao.quantization.observer.Tuple(*args, **kwargs)
torch.ao.quantization.observer.UniformQuantizationObserverBase(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.observer.abstractmethod(funcobj)
torch.ao.quantization.observer.calculate_qmin_qmax(quant_min: int, quant_max: int, has_customized_qrange: bool, dtype: torch.dtype, reduce_range: bool) -> Tuple[int, int]
torch.ao.quantization.observer.check_min_max_valid(min_val: torch.Tensor, max_val: torch.Tensor) -> bool
torch.ao.quantization.observer.default_affine_fixed_qparams_observer(*args, **keywords)
torch.ao.quantization.observer.default_debug_observer(dtype=torch.quint8)
torch.ao.quantization.observer.default_dynamic_quant_observer(*args, **keywords)
torch.ao.quantization.observer.default_fixed_qparams_range_0to1_observer(*args, **keywords)
torch.ao.quantization.observer.default_fixed_qparams_range_neg1to1_observer(*args, **keywords)
torch.ao.quantization.observer.default_float_qparams_observer(*args, **keywords)
torch.ao.quantization.observer.default_float_qparams_observer_4bit(*args, **keywords)
torch.ao.quantization.observer.default_histogram_observer(*args, **keywords)
torch.ao.quantization.observer.default_observer(*args, **keywords)
torch.ao.quantization.observer.default_per_channel_weight_observer(*args, **keywords)
torch.ao.quantization.observer.default_placeholder_observer(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.ao.quantization.observer.default_reuse_input_observer()
torch.ao.quantization.observer.default_symmetric_fixed_qparams_observer(*args, **keywords)
torch.ao.quantization.observer.default_weight_observer(*args, **keywords)
torch.ao.quantization.observer.get_observer_state_dict(mod)
torch.ao.quantization.observer.is_per_channel(qscheme)
torch.ao.quantization.observer.is_per_tensor(qscheme)
torch.ao.quantization.observer.load_observer_state_dict(mod, obs_dict)
torch.ao.quantization.observer.per_channel_weight_observer_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.observer.validate_qmin_qmax(quant_min: int, quant_max: int) -> None
torch.ao.quantization.observer.weight_observer_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.per_channel_weight_observer_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.prepare(model, inplace=False, allow_list=None, observer_non_leaf_module_list=None, prepare_custom_config_dict=None)
torch.ao.quantization.prepare_dynamic_jit(model, qconfig_dict, inplace=False)
torch.ao.quantization.prepare_jit(model, qconfig_dict, inplace=False)
torch.ao.quantization.prepare_qat(model, mapping=None, inplace=False)
torch.ao.quantization.propagate_qconfig_(module, qconfig_dict=None, prepare_custom_config_dict=None)
torch.ao.quantization.pt2e.export_utils.model_is_exported(m: torch.nn.modules.module.Module) -> bool
torch.ao.quantization.pt2e.generate_numeric_debug_handle.GraphModule(*args, **kwargs)
torch.ao.quantization.pt2e.generate_numeric_debug_handle.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.ao.quantization.pt2e.generate_numeric_debug_handle.generate_numeric_debug_handle(graph_module: torch.fx.graph_module.GraphModule) -> None
torch.ao.quantization.qconfig.Any(*args, **kwds)
torch.ao.quantization.qconfig.FakeQuantize(observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=None, quant_max=None, is_dynamic=False, **observer_kwargs)
torch.ao.quantization.qconfig.FakeQuantizeBase()
torch.ao.quantization.qconfig.FusedMovingAvgObsFakeQuantize(observer: Any = <class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min: int = 0, quant_max: int = 255, **observer_kwargs: Any) -> None
torch.ao.quantization.qconfig.HistogramObserver(bins: int = 2048, upsample_rate: int = 128, dtype: torch.dtype = torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.qconfig.MinMaxObserver(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.qconfig.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.ao.quantization.qconfig.NoopObserver(dtype=torch.float16, custom_op_name='') -> None
torch.ao.quantization.qconfig.ObserverBase(dtype, is_dynamic=False)
torch.ao.quantization.qconfig.Optional(*args, **kwds)
torch.ao.quantization.qconfig.PlaceholderObserver(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.ao.quantization.qconfig.QConfig(activation, weight)
torch.ao.quantization.qconfig.QConfigAny(*args, **kwargs)
torch.ao.quantization.qconfig.QConfigDynamic(activation=<class 'torch.nn.modules.linear.Identity'>, weight=<class 'torch.nn.modules.linear.Identity'>)
torch.ao.quantization.qconfig.ReuseInputObserver()
torch.ao.quantization.qconfig.Type(*args, **kwargs)
torch.ao.quantization.qconfig.Union(*args, **kwds)
torch.ao.quantization.qconfig.default_debug_observer(dtype=torch.quint8)
torch.ao.quantization.qconfig.default_dynamic_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_dynamic_quant_observer(*args, **keywords)
torch.ao.quantization.qconfig.default_embedding_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_embedding_fake_quant_4bit(*args, **keywords)
torch.ao.quantization.qconfig.default_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_float_qparams_observer(*args, **keywords)
torch.ao.quantization.qconfig.default_float_qparams_observer_4bit(*args, **keywords)
torch.ao.quantization.qconfig.default_fused_act_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_fused_per_channel_wt_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_fused_wt_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_observer(*args, **keywords)
torch.ao.quantization.qconfig.default_per_channel_weight_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_per_channel_weight_observer(*args, **keywords)
torch.ao.quantization.qconfig.default_placeholder_observer(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.ao.quantization.qconfig.default_reuse_input_observer()
torch.ao.quantization.qconfig.default_weight_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig.default_weight_observer(*args, **keywords)
torch.ao.quantization.qconfig.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.ao.quantization.qconfig.fused_per_channel_wt_fake_quant_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.qconfig.fused_wt_fake_quant_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.qconfig.get_default_qat_qconfig(backend='x86', version=1)
torch.ao.quantization.qconfig.get_default_qat_qconfig_dict(backend='x86', version=1)
torch.ao.quantization.qconfig.get_default_qconfig(backend='x86', version=0)
torch.ao.quantization.qconfig.get_default_qconfig_dict(backend='x86', version=0)
torch.ao.quantization.qconfig.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.ao.quantization.qconfig.per_channel_weight_observer_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.qconfig.qconfig_equals(q1: typing.Optional[torch.ao.quantization.qconfig.QConfig], q2: typing.Optional[torch.ao.quantization.qconfig.QConfig])
torch.ao.quantization.qconfig.weight_observer_range_neg_127_to_127(*args, **keywords)
torch.ao.quantization.qconfig_equals(q1: typing.Optional[torch.ao.quantization.qconfig.QConfig], q2: typing.Optional[torch.ao.quantization.qconfig.QConfig])
torch.ao.quantization.qconfig_mapping.Any(*args, **kwds)
torch.ao.quantization.qconfig_mapping.Callable(*args, **kwargs)
torch.ao.quantization.qconfig_mapping.Dict(*args, **kwargs)
torch.ao.quantization.qconfig_mapping.FixedQParamsFakeQuantize(observer)
torch.ao.quantization.qconfig_mapping.List(*args, **kwargs)
torch.ao.quantization.qconfig_mapping.QConfig(activation, weight)
torch.ao.quantization.qconfig_mapping.QConfigAny(*args, **kwargs)
torch.ao.quantization.qconfig_mapping.QConfigMapping()
torch.ao.quantization.qconfig_mapping.Tuple(*args, **kwargs)
torch.ao.quantization.qconfig_mapping.Union(*args, **kwds)
torch.ao.quantization.qconfig_mapping.default_fixed_qparams_range_0to1_observer(*args, **keywords)
torch.ao.quantization.qconfig_mapping.default_fixed_qparams_range_neg1to1_observer(*args, **keywords)
torch.ao.quantization.qconfig_mapping.default_placeholder_observer(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.ao.quantization.qconfig_mapping.default_weight_fake_quant(*args, **keywords)
torch.ao.quantization.qconfig_mapping.default_weight_observer(*args, **keywords)
torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig(backend='x86', version=1)
torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping(backend='x86', version=1) -> 'QConfigMapping'
torch.ao.quantization.qconfig_mapping.get_default_qconfig(backend='x86', version=0)
torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping(backend='x86', version=0) -> 'QConfigMapping'
torch.ao.quantization.quant_type.QuantType(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.ao.quantization.quantization_mappings.Any(*args, **kwds)
torch.ao.quantization.quantization_mappings.Callable(*args, **kwargs)
torch.ao.quantization.quantization_mappings.DeQuantStub(qconfig=None)
torch.ao.quantization.quantization_mappings.Dict(*args, **kwargs)
torch.ao.quantization.quantization_mappings.Optional(*args, **kwds)
torch.ao.quantization.quantization_mappings.QuantStub(qconfig=None)
torch.ao.quantization.quantization_mappings.Set(*args, **kwargs)
torch.ao.quantization.quantization_mappings.Union(*args, **kwds)
torch.ao.quantization.quantization_mappings.default_fixed_qparams_range_0to1_fake_quant(*args, **keywords)
torch.ao.quantization.quantization_mappings.default_fixed_qparams_range_neg1to1_fake_quant(*args, **keywords)
torch.ao.quantization.quantization_mappings.get_combined_dict(default_dict, additional_dict)
torch.ao.quantization.quantization_mappings.get_default_compare_output_module_list() -> Set[Callable]
torch.ao.quantization.quantization_mappings.get_default_dynamic_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_default_dynamic_sparse_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_default_float_to_quantized_operator_mappings() -> Dict[Union[Callable, str], Callable]
torch.ao.quantization.quantization_mappings.get_default_qat_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_default_qconfig_propagation_list() -> Set[Callable]
torch.ao.quantization.quantization_mappings.get_default_static_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_default_static_quant_reference_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_default_static_sparse_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_dynamic_quant_module_class(float_module_class: Callable, additional_dynamic_quant_mapping: Optional[Dict[Callable, Any]] = None) -> Any
torch.ao.quantization.quantization_mappings.get_embedding_qat_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_embedding_static_quant_module_mappings() -> Dict[Callable, Any]
torch.ao.quantization.quantization_mappings.get_quantized_operator(float_op: Union[Callable, str]) -> Callable
torch.ao.quantization.quantization_mappings.get_static_quant_module_class(float_module_class: Callable, additional_static_quant_mapping: Optional[Dict[Callable, Any]] = None, is_reference: bool = False) -> Any
torch.ao.quantization.quantization_mappings.no_observer_set() -> Set[Any]
torch.ao.quantization.quantization_mappings.type_before_parametrizations(module: torch.nn.modules.module.Module) -> type
torch.ao.quantization.quantize(model, run_fn, run_args, mapping=None, inplace=False)
torch.ao.quantization.quantize_dynamic(model, qconfig_spec=None, dtype=torch.qint8, mapping=None, inplace=False)
torch.ao.quantization.quantize_dynamic_jit(model, qconfig_dict, inplace=False, debug=False)
torch.ao.quantization.quantize_jit(model, qconfig_dict, run_fn, run_args, inplace=False, debug=False)
torch.ao.quantization.quantize_qat(model, run_fn, run_args, inplace=False)
torch.ao.quantization.script_qconfig(qconfig)
torch.ao.quantization.script_qconfig_dict(qconfig_dict)
torch.ao.quantization.stubs.DeQuantStub(qconfig=None)
torch.ao.quantization.stubs.QuantStub(qconfig=None)
torch.ao.quantization.stubs.QuantWrapper(module)
torch.ao.quantization.swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant=False)
torch.ao.quantization.utils.Any(*args, **kwds)
torch.ao.quantization.utils.Callable(*args, **kwargs)
torch.ao.quantization.utils.Dict(*args, **kwargs)
torch.ao.quantization.utils.MatchAllNode()
torch.ao.quantization.utils.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.ao.quantization.utils.NodePattern(*args, **kwargs)
torch.ao.quantization.utils.Optional(*args, **kwds)
torch.ao.quantization.utils.Pattern(*args, **kwargs)
torch.ao.quantization.utils.QuantType(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.ao.quantization.utils.QuantizerCls(*args, **kwds)
torch.ao.quantization.utils.Tuple(*args, **kwargs)
torch.ao.quantization.utils.Union(*args, **kwds)
torch.ao.quantization.utils.activation_dtype(qconfig)
torch.ao.quantization.utils.activation_is_dynamically_quantized(qconfig)
torch.ao.quantization.utils.activation_is_int32_quantized(qconfig)
torch.ao.quantization.utils.activation_is_int8_quantized(qconfig)
torch.ao.quantization.utils.activation_is_statically_quantized(qconfig)
torch.ao.quantization.utils.calculate_qmin_qmax(quant_min: int, quant_max: int, has_customized_qrange: bool, dtype: torch.dtype, reduce_range: bool) -> Tuple[int, int]
torch.ao.quantization.utils.check_min_max_valid(min_val: torch.Tensor, max_val: torch.Tensor) -> bool
torch.ao.quantization.utils.check_node(node, modules)
torch.ao.quantization.utils.determine_qparams(min_val: torch.Tensor, max_val: torch.Tensor, quant_min: int, quant_max: int, dtype: torch.dtype, eps: torch.Tensor, has_customized_qrange: bool, qscheme: torch.qscheme = torch.per_tensor_affine) -> Tuple[torch.Tensor, torch.Tensor]
torch.ao.quantization.utils.get_combined_dict(default_dict, additional_dict)
torch.ao.quantization.utils.get_fqn_to_example_inputs(model: torch.nn.modules.module.Module, example_inputs: Tuple[Any, ...]) -> Dict[str, Tuple[Any, ...]]
torch.ao.quantization.utils.get_qconfig_dtypes(qconfig)
torch.ao.quantization.utils.get_qparam_dict(observer_or_fake_quant)
torch.ao.quantization.utils.get_quant_type(qconfig)
torch.ao.quantization.utils.get_swapped_custom_module_class(custom_module, custom_module_class_mapping, qconfig)
torch.ao.quantization.utils.getattr_from_fqn(obj: Any, fqn: str) -> Any
torch.ao.quantization.utils.getfullargspec(func)
torch.ao.quantization.utils.has_no_children_ignoring_parametrizations(module)
torch.ao.quantization.utils.is_parametrized(module: torch.nn.modules.module.Module, tensor_name: Optional[str] = None) -> bool
torch.ao.quantization.utils.is_per_channel(qscheme)
torch.ao.quantization.utils.is_per_tensor(qscheme)
torch.ao.quantization.utils.op_is_int8_dynamically_quantized(qconfig) -> bool
torch.ao.quantization.utils.signature(obj, *, follow_wrapped=True, globals=None, locals=None, eval_str=False)
torch.ao.quantization.utils.to_underlying_dtype(qdtype)
torch.ao.quantization.utils.validate_qmin_qmax(quant_min: int, quant_max: int) -> None
torch.ao.quantization.utils.weight_dtype(qconfig)
torch.ao.quantization.utils.weight_is_quantized(qconfig)
torch.ao.quantization.utils.weight_is_statically_quantized(qconfig)
torch.ao.quantization.weight_observer_range_neg_127_to_127(*args, **keywords)
torch.are_deterministic_algorithms_enabled() -> bool
torch.atleast_1d(*tensors)
torch.atleast_2d(*tensors)
torch.atleast_3d(*tensors)
torch.autocast(device_type: str, dtype: Optional[torch.dtype] = None, enabled: bool = True, cache_enabled: Optional[bool] = None)
torch.autograd.Any(*args, **kwds)
torch.autograd.Callable(*args, **kwargs)
torch.autograd.Function(*args, **kwargs)
torch.autograd.List(*args, **kwargs)
torch.autograd.NestedIOFunction(*args, **kwargs)
torch.autograd.Optional(*args, **kwds)
torch.autograd.Sequence(*args, **kwargs)
torch.autograd.Tuple(*args, **kwargs)
torch.autograd.Union(*args, **kwds)
torch.autograd.anomaly_mode.detect_anomaly(check_nan=True) -> None
torch.autograd.anomaly_mode.set_detect_anomaly(mode: bool, check_nan: bool = True) -> None
torch.autograd.backward(tensors: Union[torch.Tensor, Sequence[torch.Tensor]], grad_tensors: Union[torch.Tensor, Sequence[torch.Tensor], NoneType] = None, retain_graph: Optional[bool] = None, create_graph: bool = False, grad_variables: Union[torch.Tensor, Sequence[torch.Tensor], NoneType] = None, inputs: Union[torch.Tensor, Sequence[torch.Tensor], ForwardRef('torch.autograd.graph.GradientEdge'), Sequence[ForwardRef('torch.autograd.graph.GradientEdge')], NoneType] = None) -> None
torch.autograd.cast(typ, val)
torch.autograd.detect_anomaly(check_nan=True) -> None
torch.autograd.enable_grad(orig_func=None)
torch.autograd.forward_ad.Any(*args, **kwds)
torch.autograd.forward_ad.UnpackedDualTensor(primal, tangent)
torch.autograd.forward_ad.dual_level()
torch.autograd.forward_ad.enter_dual_level()
torch.autograd.forward_ad.exit_dual_level(*, level=None)
torch.autograd.forward_ad.make_dual(tensor, tangent, *, level=None)
torch.autograd.forward_ad.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.autograd.forward_ad.unpack_dual(tensor, *, level=None)
torch.autograd.function.Any(*args, **kwds)
torch.autograd.function.Function(*args, **kwargs)
torch.autograd.function.FunctionCtx()
torch.autograd.function.FunctionMeta(name, bases, attrs)
torch.autograd.function.InplaceFunction(inplace=False)
torch.autograd.function.List(*args, **kwargs)
torch.autograd.function.NestedIOFunction(*args, **kwargs)
torch.autograd.function.Optional(*args, **kwds)
torch.autograd.function.Tuple(*args, **kwargs)
torch.autograd.function.custom_function_call(autograd_function, *args, **kwargs)
torch.autograd.function.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.autograd.function.once_differentiable(fn)
torch.autograd.functional.List(*args, **kwargs)
torch.autograd.functional.Tuple(*args, **kwargs)
torch.autograd.functional.hessian(func, inputs, create_graph=False, strict=False, vectorize=False, outer_jacobian_strategy='reverse-mode')
torch.autograd.functional.hvp(func, inputs, v=None, create_graph=False, strict=False)
torch.autograd.functional.jacobian(func, inputs, create_graph=False, strict=False, vectorize=False, strategy='reverse-mode')
torch.autograd.functional.jvp(func, inputs, v=None, create_graph=False, strict=False)
torch.autograd.functional.vhp(func, inputs, v=None, create_graph=False, strict=False)
torch.autograd.functional.vjp(func, inputs, v=None, create_graph=False, strict=False)
torch.autograd.grad(outputs: Union[torch.Tensor, Sequence[torch.Tensor]], inputs: Union[torch.Tensor, Sequence[torch.Tensor], ForwardRef('torch.autograd.graph.GradientEdge'), Sequence[ForwardRef('torch.autograd.graph.GradientEdge')]], grad_outputs: Union[torch.Tensor, Sequence[torch.Tensor], NoneType] = None, retain_graph: Optional[bool] = None, create_graph: bool = False, only_inputs: bool = True, allow_unused: Optional[bool] = None, is_grads_batched: bool = False, materialize_grads: bool = False) -> Tuple[torch.Tensor, ...]
torch.autograd.grad_mode.Any(*args, **kwds)
torch.autograd.grad_mode.enable_grad(orig_func=None)
torch.autograd.grad_mode.inference_mode(mode=True)
torch.autograd.grad_mode.no_grad() -> None
torch.autograd.grad_mode.set_grad_enabled(mode: bool) -> None
torch.autograd.grad_mode.set_multithreading_enabled(mode: bool) -> None
torch.autograd.gradcheck(func: Callable[..., Union[torch.Tensor, Sequence[torch.Tensor]]], inputs: Union[torch.Tensor, Sequence[torch.Tensor]], *, eps: float = 1e-06, atol: float = 1e-05, rtol: float = 0.001, raise_exception: bool = True, nondet_tol: float = 0.0, check_undefined_grad: bool = True, check_grad_dtypes: bool = False, check_batched_grad: bool = False, check_batched_forward_grad: bool = False, check_forward_ad: bool = False, check_backward_ad: bool = True, fast_mode: bool = False, masked: Optional[bool] = None) -> bool
torch.autograd.gradgradcheck(func: Callable[..., Union[torch.Tensor, Sequence[torch.Tensor]]], inputs: Union[torch.Tensor, Sequence[torch.Tensor]], grad_outputs: Union[torch.Tensor, Sequence[torch.Tensor], NoneType] = None, *, eps: float = 1e-06, atol: float = 1e-05, rtol: float = 0.001, gen_non_contig_grad_outputs: bool = False, raise_exception: bool = True, nondet_tol: float = 0.0, check_undefined_grad: bool = True, check_grad_dtypes: bool = False, check_batched_grad: bool = False, check_fwd_over_rev: bool = False, check_rev_over_rev: bool = True, fast_mode: bool = False, masked: bool = False) -> bool
torch.autograd.graph.Any(*args, **kwds)
torch.autograd.graph.Callable(*args, **kwargs)
torch.autograd.graph.Deque(*args, **kwargs)
torch.autograd.graph.Dict(*args, **kwargs)
torch.autograd.graph.GradientEdge(node, output_nr)
torch.autograd.graph.List(*args, **kwargs)
torch.autograd.graph.Node()
torch.autograd.graph.Optional(*args, **kwds)
torch.autograd.graph.RemovableHandle(hooks_dict: Any, *, extra_dict: Any = None) -> None
torch.autograd.graph.Sequence(*args, **kwargs)
torch.autograd.graph.Set(*args, **kwargs)
torch.autograd.graph.TorchDispatchMode(_dispatch_key=None)
torch.autograd.graph.Tuple(*args, **kwargs)
torch.autograd.graph.Union(*args, **kwds)
torch.autograd.graph.allow_mutation_on_saved_tensors()
torch.autograd.graph.cast(typ, val)
torch.autograd.graph.disable_saved_tensors_hooks(error_message)
torch.autograd.graph.get_gradient_edge(tensor)
torch.autograd.graph.increment_version(tensor)
torch.autograd.graph.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.autograd.graph.register_multi_grad_hook(tensors: Sequence[torch.Tensor], fn: Union[Callable[[Sequence[Optional[torch.Tensor]]], NoneType], Callable[[torch.Tensor], NoneType]], *, mode: str = 'all')
torch.autograd.graph.save_on_cpu(pin_memory=False, device_type='cuda')
torch.autograd.graph.saved_tensors_hooks(pack_hook: Callable[[torch.Tensor], Any], unpack_hook: Callable[[Any], torch.Tensor])
torch.autograd.handle_torch_function(public_api: Callable, relevant_args: Iterable[Any], *args, **kwargs) -> Any
torch.autograd.inference_mode(mode=True)
torch.autograd.is_tensor_like(inp)
torch.autograd.no_grad() -> None
torch.autograd.profiler.Any(*args, **kwds)
torch.autograd.profiler.Dict(*args, **kwargs)
torch.autograd.profiler.EnforceUnique()
torch.autograd.profiler.EventList(*args, **kwargs)
torch.autograd.profiler.FunctionEvent(id, name, thread, start_us, end_us, fwd_thread=None, input_shapes=None, stack=None, scope=0, use_device=None, cpu_memory_usage=0, device_memory_usage=0, is_async=False, is_remote=False, sequence_nr=-1, node_id=-1, device_type=<DeviceType.CPU: 0>, device_index=0, device_resource_id=None, is_legacy=False, flops=None, trace_name=None, concrete_inputs=None)
torch.autograd.profiler.Future(*, devices: 'Optional[List[Union[int, str, torch.device]]]' = None)
torch.autograd.profiler.KinetoStepTracker()
torch.autograd.profiler.List(*args, **kwargs)
torch.autograd.profiler.MemRecordsAcc(mem_records)
torch.autograd.profiler.Optional(*args, **kwds)
torch.autograd.profiler.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.autograd.profiler.emit_itt(enabled=True, record_shapes=False)
torch.autograd.profiler.emit_nvtx(enabled=True, record_shapes=False)
torch.autograd.profiler.load_nvprof(path)
torch.autograd.profiler.parse_nvprof_trace(path)
torch.autograd.profiler.profile(enabled=True, *, use_cuda=False, use_device=None, record_shapes=False, with_flops=False, profile_memory=False, with_stack=False, with_modules=False, use_kineto=False, use_cpu=True, use_mtia=False, experimental_config=None)
torch.autograd.profiler.record_function(name: str, args: Optional[str] = None)
torch.autograd.profiler.warn(message, category=None, stacklevel=1, source=None)
torch.autograd.profiler_util.Any(*args, **kwds)
torch.autograd.profiler_util.Dict(*args, **kwargs)
torch.autograd.profiler_util.EventList(*args, **kwargs)
torch.autograd.profiler_util.FormattedTimesMixin()
torch.autograd.profiler_util.FunctionEvent(id, name, thread, start_us, end_us, fwd_thread=None, input_shapes=None, stack=None, scope=0, use_device=None, cpu_memory_usage=0, device_memory_usage=0, is_async=False, is_remote=False, sequence_nr=-1, node_id=-1, device_type=<DeviceType.CPU: 0>, device_index=0, device_resource_id=None, is_legacy=False, flops=None, trace_name=None, concrete_inputs=None)
torch.autograd.profiler_util.FunctionEventAvg()
torch.autograd.profiler_util.Interval(start, end)
torch.autograd.profiler_util.Kernel(name, device, duration)
torch.autograd.profiler_util.List(*args, **kwargs)
torch.autograd.profiler_util.MemRecordsAcc(mem_records)
torch.autograd.profiler_util.Optional(*args, **kwds)
torch.autograd.profiler_util.Tuple(*args, **kwargs)
torch.autograd.profiler_util.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.autograd.profiler_util.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.autograd.set_detect_anomaly(mode: bool, check_nan: bool = True) -> None
torch.autograd.set_grad_enabled(mode: bool) -> None
torch.autograd.set_multithreading_enabled(mode: bool) -> None
torch.autograd.variable(*args, **kwargs)
torch.backends.ContextProp(getter, setter)
torch.backends.PropModule(m, name)
torch.backends.contextmanager(func)
torch.backends.cpu.get_cpu_capability() -> str
torch.backends.cuda.Union(*args, **kwds)
torch.backends.cuda.can_use_efficient_attention(params: torch.backends.cuda._SDPAParams, debug: bool = False) -> bool
torch.backends.cuda.can_use_flash_attention(params: torch.backends.cuda._SDPAParams, debug: bool = False) -> bool
torch.backends.cuda.cuBLASModule()
torch.backends.cuda.cuFFTPlanCache(device_index)
torch.backends.cuda.cuFFTPlanCacheAttrContextProp(getter, setter)
torch.backends.cuda.cuFFTPlanCacheManager()
torch.backends.cuda.cudnn_sdp_enabled()
torch.backends.cuda.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.backends.cuda.enable_cudnn_sdp(enabled: bool)
torch.backends.cuda.enable_flash_sdp(enabled: bool)
torch.backends.cuda.enable_math_sdp(enabled: bool)
torch.backends.cuda.enable_mem_efficient_sdp(enabled: bool)
torch.backends.cuda.flash_sdp_enabled()
torch.backends.cuda.is_built()
torch.backends.cuda.math_sdp_enabled()
torch.backends.cuda.mem_efficient_sdp_enabled()
torch.backends.cuda.preferred_blas_library(backend: Union[NoneType, str, torch._C._BlasBackend] = None) -> torch._C._BlasBackend
torch.backends.cuda.preferred_linalg_library(backend: Union[NoneType, str, torch._C._LinalgBackend] = None) -> torch._C._LinalgBackend
torch.backends.cuda.sdp_kernel(enable_flash: bool = True, enable_math: bool = True, enable_mem_efficient: bool = True, enable_cudnn: bool = True)
torch.backends.disable_global_flags()
torch.backends.flags_frozen()
torch.backends.mha.get_fastpath_enabled() -> bool
torch.backends.mha.set_fastpath_enabled(value: bool) -> None
torch.backends.mkl.is_available()
torch.backends.mkl.verbose(enable)
torch.backends.mps.Optional(*args, **kwds)
torch.backends.mps.is_available() -> bool
torch.backends.mps.is_built() -> bool
torch.backends.mps.is_macos13_or_newer(minor: int = 0) -> bool
torch.backends.mps.is_macos_or_newer(major: int, minor: int) -> bool
torch.backends.nnpack.ContextProp(getter, setter)
torch.backends.nnpack.PropModule(m, name)
torch.backends.nnpack.contextmanager(func)
torch.backends.nnpack.flags(enabled=False)
torch.backends.nnpack.is_available()
torch.backends.nnpack.set_flags(_enabled)
torch.backends.openmp.is_available()
torch.block_diag(*tensors)
torch.broadcast_shapes(*shapes)
torch.broadcast_tensors(*tensors)
torch.cartesian_prod(*tensors: torch.Tensor) -> torch.Tensor
torch.cdist(x1, x2, p=2.0, compute_mode='use_mm_for_euclid_dist_if_necessary')
torch.chain_matmul(*matrices, out=None)
torch.classproperty(func)
torch.compile(model: Optional[Callable] = None, *, fullgraph: bool = False, dynamic: Optional[bool] = None, backend: Union[str, Callable] = 'inductor', mode: Optional[str] = None, options: Optional[Dict[str, Union[str, int, bool]]] = None, disable: bool = False) -> Callable
torch.compiled_with_cxx11_abi() -> bool
torch.compiler.List(*args, **kwargs)
torch.compiler.allow_in_graph(fn)
torch.compiler.assume_constant_result(fn)
torch.compiler.compile(*args, **kwargs)
torch.compiler.cudagraph_mark_step_begin()
torch.compiler.disable(fn=None, recursive=True)
torch.compiler.is_compiling() -> bool
torch.compiler.is_dynamo_compiling() -> bool
torch.compiler.list_backends(exclude_tags=('debug', 'experimental')) -> List[str]
torch.compiler.reset() -> None
torch.compiler.wrap_numpy(fn)
torch.cond(pred, true_fn, false_fn, operands)
torch.cpu.AbstractContextManager()
torch.cpu.Any(*args, **kwds)
torch.cpu.Event()
torch.cpu.Optional(*args, **kwds)
torch.cpu.Stream(priority: int = -1) -> None
torch.cpu.StreamContext(stream)
torch.cpu.Union(*args, **kwds)
torch.cpu.amp.GradScaler(init_scale: float = 65536.0, growth_factor: float = 2.0, backoff_factor: float = 0.5, growth_interval: int = 2000, enabled: bool = True) -> None
torch.cpu.amp.autocast(enabled: bool = True, dtype: torch.dtype = torch.bfloat16, cache_enabled: bool = True)
torch.cpu.amp.autocast_mode.Any(*args, **kwds)
torch.cpu.amp.autocast_mode.autocast(enabled: bool = True, dtype: torch.dtype = torch.bfloat16, cache_enabled: bool = True)
torch.cpu.amp.autocast_mode.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.cpu.amp.grad_scaler.GradScaler(init_scale: float = 65536.0, growth_factor: float = 2.0, backoff_factor: float = 0.5, growth_interval: int = 2000, enabled: bool = True) -> None
torch.cpu.amp.grad_scaler.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.cpu.current_device() -> str
torch.cpu.current_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.cpu.Stream
torch.cpu.device_count() -> int
torch.cpu.is_available() -> bool
torch.cpu.set_device(device: Union[torch.device, str, int, NoneType]) -> None
torch.cpu.stream(stream: torch.cpu.Stream) -> contextlib.AbstractContextManager
torch.cpu.synchronize(device: Union[torch.device, str, int, NoneType] = None) -> None
torch.cuda.Any(*args, **kwds)
torch.cuda.BFloat16Storage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.BoolStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.ByteStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.CUDAGraph()
torch.cuda.CUDAPluggableAllocator(path_to_so_file: str, alloc_fn_name: str, free_fn_name: str)
torch.cuda.Callable(*args, **kwargs)
torch.cuda.CharStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.ComplexDoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.ComplexFloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.CudaError(code: int) -> None
torch.cuda.Device(*args, **kwargs)
torch.cuda.DoubleStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.Event(enable_timing=False, blocking=False, interprocess=False)
torch.cuda.ExternalStream(stream_ptr, device=None, **kwargs)
torch.cuda.FloatStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.HalfStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.IntStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.List(*args, **kwargs)
torch.cuda.LongStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.Optional(*args, **kwds)
torch.cuda.ShortStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.cuda.Stream(device=None, priority=0, **kwargs)
torch.cuda.StreamContext(stream: Optional[ForwardRef('torch.cuda.Stream')])
torch.cuda.Tuple(*args, **kwargs)
torch.cuda.Union(*args, **kwds)
torch.cuda.amp.GradScaler(init_scale: float = 65536.0, growth_factor: float = 2.0, backoff_factor: float = 0.5, growth_interval: int = 2000, enabled: bool = True) -> None
torch.cuda.amp.amp_definitely_not_available()
torch.cuda.amp.autocast(enabled: bool = True, dtype: torch.dtype = torch.float16, cache_enabled: bool = True)
torch.cuda.amp.autocast_mode.Any(*args, **kwds)
torch.cuda.amp.autocast_mode.autocast(enabled: bool = True, dtype: torch.dtype = torch.float16, cache_enabled: bool = True)
torch.cuda.amp.autocast_mode.custom_bwd(bwd)
torch.cuda.amp.autocast_mode.custom_fwd(fwd=None, *, cast_inputs=None)
torch.cuda.amp.autocast_mode.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.cuda.amp.common.amp_definitely_not_available()
torch.cuda.amp.common.find_spec(name, package=None)
torch.cuda.amp.custom_bwd(bwd)
torch.cuda.amp.custom_fwd(fwd=None, *, cast_inputs=None)
torch.cuda.amp.grad_scaler.GradScaler(init_scale: float = 65536.0, growth_factor: float = 2.0, backoff_factor: float = 0.5, growth_interval: int = 2000, enabled: bool = True) -> None
torch.cuda.amp.grad_scaler.OptState(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.cuda.amp.grad_scaler.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.cuda.caching_allocator_alloc(size, device: Union[int, str, torch.device, NoneType] = None, stream=None)
torch.cuda.caching_allocator_delete(mem_ptr)
torch.cuda.can_device_access_peer(device: Union[torch.device, str, int, NoneType], peer_device: Union[torch.device, str, int, NoneType]) -> bool
torch.cuda.cast(typ, val)
torch.cuda.change_current_allocator(allocator: torch.cuda.memory._CUDAAllocator) -> None
torch.cuda.check_error(res: int) -> None
torch.cuda.classproperty(func)
torch.cuda.clock_rate(device: Union[torch.device, str, int, NoneType] = None) -> int
torch.cuda.cudaStatus()
torch.cuda.cudart()
torch.cuda.current_blas_handle()
torch.cuda.current_device() -> int
torch.cuda.current_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.cuda.streams.Stream
torch.cuda.default_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.cuda.streams.Stream
torch.cuda.device(device: Any)
torch.cuda.device_count() -> int
torch.cuda.device_of(obj)
torch.cuda.empty_cache() -> None
torch.cuda.get_allocator_backend() -> str
torch.cuda.get_arch_list() -> List[str]
torch.cuda.get_device_capability(device: Union[torch.device, str, int, NoneType] = None) -> Tuple[int, int]
torch.cuda.get_device_name(device: Union[torch.device, str, int, NoneType] = None) -> str
torch.cuda.get_device_properties(device: Union[torch.device, str, int, NoneType]) -> torch._C._CudaDeviceProperties
torch.cuda.get_gencode_flags() -> str
torch.cuda.get_rng_state(device: Union[int, str, torch.device] = 'cuda') -> torch.Tensor
torch.cuda.get_rng_state_all() -> List[torch.Tensor]
torch.cuda.get_sync_debug_mode() -> int
torch.cuda.graph(cuda_graph, pool=None, stream=None, capture_error_mode: str = 'global')
torch.cuda.graph_pool_handle()
torch.cuda.graphs.CUDAGraph()
torch.cuda.graphs.graph(cuda_graph, pool=None, stream=None, capture_error_mode: str = 'global')
torch.cuda.graphs.graph_pool_handle()
torch.cuda.graphs.is_current_stream_capturing()
torch.cuda.graphs.make_graphed_callables(callables, sample_args, num_warmup_iters=3, allow_unused_input=False, pool=None)
torch.cuda.init()
torch.cuda.initial_seed() -> int
torch.cuda.ipc_collect()
torch.cuda.is_available() -> bool
torch.cuda.is_bf16_supported(including_emulation: bool = True)
torch.cuda.is_current_stream_capturing()
torch.cuda.is_initialized()
torch.cuda.jiterator.Callable(*args, **kwargs)
torch.cuda.jiterator.List(*args, **kwargs)
torch.cuda.list_gpu_processes(device: Union[int, str, torch.device, NoneType] = None) -> str
torch.cuda.lru_cache(maxsize=128, typed=False)
torch.cuda.make_graphed_callables(callables, sample_args, num_warmup_iters=3, allow_unused_input=False, pool=None)
torch.cuda.manual_seed(seed: int) -> None
torch.cuda.manual_seed_all(seed: int) -> None
torch.cuda.max_memory_allocated(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.max_memory_cached(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.max_memory_reserved(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.mem_get_info(device: Union[int, str, torch.device, NoneType] = None) -> Tuple[int, int]
torch.cuda.memory.Any(*args, **kwds)
torch.cuda.memory.CUDAPluggableAllocator(path_to_so_file: str, alloc_fn_name: str, free_fn_name: str)
torch.cuda.memory.Device(*args, **kwargs)
torch.cuda.memory.Dict(*args, **kwargs)
torch.cuda.memory.Optional(*args, **kwds)
torch.cuda.memory.Tuple(*args, **kwargs)
torch.cuda.memory.Union(*args, **kwds)
torch.cuda.memory.caching_allocator_alloc(size, device: Union[int, str, torch.device, NoneType] = None, stream=None)
torch.cuda.memory.caching_allocator_delete(mem_ptr)
torch.cuda.memory.change_current_allocator(allocator: torch.cuda.memory._CUDAAllocator) -> None
torch.cuda.memory.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.cuda.memory.empty_cache() -> None
torch.cuda.memory.get_allocator_backend() -> str
torch.cuda.memory.is_initialized()
torch.cuda.memory.list_gpu_processes(device: Union[int, str, torch.device, NoneType] = None) -> str
torch.cuda.memory.max_memory_allocated(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory.max_memory_cached(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory.max_memory_reserved(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory.mem_get_info(device: Union[int, str, torch.device, NoneType] = None) -> Tuple[int, int]
torch.cuda.memory.memory_allocated(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory.memory_cached(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory.memory_reserved(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory.memory_snapshot()
torch.cuda.memory.memory_stats(device: Union[int, str, torch.device, NoneType] = None) -> Dict[str, Any]
torch.cuda.memory.memory_stats_as_nested_dict(device: Union[int, str, torch.device, NoneType] = None) -> Dict[str, Any]
torch.cuda.memory.memory_summary(device: Union[int, str, torch.device, NoneType] = None, abbreviated: bool = False) -> str
torch.cuda.memory.reset_accumulated_memory_stats(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.memory.reset_max_memory_allocated(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.memory.reset_max_memory_cached(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.memory.reset_peak_memory_stats(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.memory.set_per_process_memory_fraction(fraction, device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.memory.signature(obj, *, follow_wrapped=True, globals=None, locals=None, eval_str=False)
torch.cuda.memory_allocated(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory_cached(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory_reserved(device: Union[int, str, torch.device, NoneType] = None) -> int
torch.cuda.memory_snapshot()
torch.cuda.memory_stats(device: Union[int, str, torch.device, NoneType] = None) -> Dict[str, Any]
torch.cuda.memory_stats_as_nested_dict(device: Union[int, str, torch.device, NoneType] = None) -> Dict[str, Any]
torch.cuda.memory_summary(device: Union[int, str, torch.device, NoneType] = None, abbreviated: bool = False) -> str
torch.cuda.memory_usage(device: Union[torch.device, str, int, NoneType] = None) -> int
torch.cuda.nccl.Optional(*args, **kwds)
torch.cuda.nccl.Sequence(*args, **kwargs)
torch.cuda.nccl.Union(*args, **kwds)
torch.cuda.nccl.all_gather(inputs: Sequence[torch.Tensor], outputs: Sequence[torch.Tensor], streams=None, comms=None) -> None
torch.cuda.nccl.all_reduce(inputs, outputs=None, op=0, streams=None, comms=None)
torch.cuda.nccl.broadcast(inputs: Sequence[torch.Tensor], root: int = 0, streams=None, comms=None) -> None
torch.cuda.nccl.init_rank(num_ranks, uid, rank)
torch.cuda.nccl.is_available(tensors)
torch.cuda.nccl.reduce(inputs: Sequence[torch.Tensor], output: Union[torch.Tensor, Sequence[torch.Tensor], NoneType] = None, root: int = 0, op: int = 0, streams: Optional[Sequence[torch.cuda.streams.Stream]] = None, comms=None, *, outputs: Optional[Sequence[torch.Tensor]] = None) -> None
torch.cuda.nccl.reduce_scatter(inputs: Sequence[torch.Tensor], outputs: Sequence[torch.Tensor], op: int = 0, streams=None, comms=None) -> None
torch.cuda.nccl.unique_id()
torch.cuda.nccl.version()
torch.cuda.nvtx.contextmanager(func)
torch.cuda.nvtx.mark(msg)
torch.cuda.nvtx.range(msg, *args, **kwargs)
torch.cuda.nvtx.range_end(range_id) -> None
torch.cuda.nvtx.range_pop()
torch.cuda.nvtx.range_push(msg)
torch.cuda.nvtx.range_start(msg) -> int
torch.cuda.power_draw(device: Union[torch.device, str, int, NoneType] = None) -> int
torch.cuda.profiler.check_error(res: int) -> None
torch.cuda.profiler.cudart()
torch.cuda.profiler.init(output_file, flags=None, output_mode='key_value')
torch.cuda.profiler.profile()
torch.cuda.profiler.start()
torch.cuda.profiler.stop()
torch.cuda.reset_accumulated_memory_stats(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.reset_max_memory_allocated(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.reset_max_memory_cached(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.reset_peak_memory_stats(device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.seed() -> None
torch.cuda.seed_all() -> None
torch.cuda.set_device(device: Union[torch.device, str, int, NoneType]) -> None
torch.cuda.set_per_process_memory_fraction(fraction, device: Union[int, str, torch.device, NoneType] = None) -> None
torch.cuda.set_rng_state(new_state: torch.Tensor, device: Union[int, str, torch.device] = 'cuda') -> None
torch.cuda.set_rng_state_all(new_states: Iterable[torch.Tensor]) -> None
torch.cuda.set_stream(stream: torch.cuda.streams.Stream)
torch.cuda.set_sync_debug_mode(debug_mode: Union[int, str]) -> None
torch.cuda.stream(stream: Optional[ForwardRef('torch.cuda.Stream')]) -> torch.cuda.StreamContext
torch.cuda.streams.Event(enable_timing=False, blocking=False, interprocess=False)
torch.cuda.streams.ExternalStream(stream_ptr, device=None, **kwargs)
torch.cuda.streams.Stream(device=None, priority=0, **kwargs)
torch.cuda.synchronize(device: Union[torch.device, str, int, NoneType] = None) -> None
torch.cuda.temperature(device: Union[torch.device, str, int, NoneType] = None) -> int
torch.cuda.tunable.Optional(*args, **kwds)
torch.cuda.tunable.Tuple(*args, **kwargs)
torch.cuda.tunable.enable(val: bool = True) -> None
torch.cuda.tunable.get_filename() -> str
torch.cuda.tunable.get_max_tuning_duration() -> int
torch.cuda.tunable.get_max_tuning_iterations() -> int
torch.cuda.tunable.get_results() -> Tuple[str, str, str, float]
torch.cuda.tunable.get_validators() -> Tuple[str, str]
torch.cuda.tunable.is_enabled() -> bool
torch.cuda.tunable.read_file(filename: Optional[str] = None) -> bool
torch.cuda.tunable.set_filename(filename: str, insert_device_ordinal: bool = False) -> None
torch.cuda.tunable.set_max_tuning_duration(duration: int) -> None
torch.cuda.tunable.set_max_tuning_iterations(iterations: int) -> None
torch.cuda.tunable.tuning_enable(val: bool = True) -> None
torch.cuda.tunable.tuning_is_enabled() -> bool
torch.cuda.tunable.write_file(filename: Optional[str] = None) -> bool
torch.cuda.tunable.write_file_on_exit(val: bool) -> None
torch.cuda.utilization(device: Union[torch.device, str, int, NoneType] = None) -> int
torch.distributed.Backend(name: str)
torch.distributed.BackendConfig(backend: torch.distributed.distributed_c10d.Backend)
torch.distributed.DeviceMesh(device_type: str, mesh: Union[torch.Tensor, ForwardRef('ArrayLike')], *, mesh_dim_names: Optional[Tuple[str, ...]] = None, _init_backend: bool = True) -> None
torch.distributed.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.distributed.GroupMember()
torch.distributed.P2POp(op: Callable, tensor: torch.Tensor, peer: int, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0)
torch.distributed.algorithms.Join(joinables: List[torch.distributed.algorithms.join.Joinable], enable: bool = True, throw_on_early_termination: bool = False, **kwargs)
torch.distributed.algorithms.JoinHook()
torch.distributed.algorithms.Joinable()
torch.distributed.algorithms.join.ABC()
torch.distributed.algorithms.join.Any(*args, **kwds)
torch.distributed.algorithms.join.Join(joinables: List[torch.distributed.algorithms.join.Joinable], enable: bool = True, throw_on_early_termination: bool = False, **kwargs)
torch.distributed.algorithms.join.JoinHook()
torch.distributed.algorithms.join.Joinable()
torch.distributed.algorithms.join.List(*args, **kwargs)
torch.distributed.algorithms.join.NamedTuple(typename, fields=None, /, **kwargs)
torch.distributed.algorithms.join.Optional(*args, **kwds)
torch.distributed.algorithms.join.Type(*args, **kwargs)
torch.distributed.algorithms.join.abstractmethod(funcobj)
torch.distributed.all_gather(tensor_list, tensor, group=None, async_op=False)
torch.distributed.all_gather_coalesced(output_tensor_lists, input_tensor_list, group=None, async_op=False)
torch.distributed.all_gather_into_tensor(output_tensor, input_tensor, group=None, async_op=False)
torch.distributed.all_gather_object(object_list, obj, group=None)
torch.distributed.all_reduce(tensor, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.all_reduce_coalesced(tensors, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.all_to_all(output_tensor_list, input_tensor_list, group=None, async_op=False)
torch.distributed.all_to_all_single(output, input, output_split_sizes=None, input_split_sizes=None, group=None, async_op=False)
torch.distributed.autograd.context()
torch.distributed.autograd.is_available()
torch.distributed.barrier(group=None, async_op=False, device_ids=None)
torch.distributed.batch_isend_irecv(p2p_op_list)
torch.distributed.breakpoint(rank: int = 0)
torch.distributed.broadcast(tensor, src, group=None, async_op=False)
torch.distributed.broadcast_object_list(object_list, src=0, group=None, device=None)
torch.distributed.c10d_logger.Any(*args, **kwds)
torch.distributed.c10d_logger.Callable(*args, **kwargs)
torch.distributed.c10d_logger.Dict(*args, **kwargs)
torch.distributed.c10d_logger.List(*args, **kwargs)
torch.distributed.c10d_logger.ParamSpec(name, *, bound=None, covariant=False, contravariant=False, infer_variance=False, default=typing_extensions.NoDefault)
torch.distributed.c10d_logger.Tuple(*args, **kwargs)
torch.distributed.c10d_logger.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.distributed.constants.Optional(*args, **kwds)
torch.distributed.destroy_process_group(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None)
torch.distributed.device_mesh.DeviceMesh(device_type: str, mesh: Union[torch.Tensor, ForwardRef('ArrayLike')], *, mesh_dim_names: Optional[Tuple[str, ...]] = None, _init_backend: bool = True) -> None
torch.distributed.device_mesh.Dict(*args, **kwargs)
torch.distributed.device_mesh.List(*args, **kwargs)
torch.distributed.device_mesh.Optional(*args, **kwds)
torch.distributed.device_mesh.Tuple(*args, **kwargs)
torch.distributed.device_mesh.Union(*args, **kwds)
torch.distributed.device_mesh.get_process_group_ranks(group: torch.distributed.distributed_c10d.ProcessGroup) -> List[int]
torch.distributed.device_mesh.get_rank(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> int
torch.distributed.device_mesh.get_world_size(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> int
torch.distributed.device_mesh.init_device_mesh(device_type: str, mesh_shape: Tuple[int, ...], *, mesh_dim_names: Optional[Tuple[str, ...]] = None) -> torch.distributed.device_mesh.DeviceMesh
torch.distributed.device_mesh.init_process_group(backend: Optional[str] = None, init_method: Optional[str] = None, timeout: Optional[datetime.timedelta] = None, world_size: int = -1, rank: int = -1, store: Optional[torch.distributed.distributed_c10d.Store] = None, group_name: str = '', pg_options: Optional[Any] = None, device_id: Optional[torch.device] = None) -> None
torch.distributed.device_mesh.is_available() -> bool
torch.distributed.device_mesh.is_initialized() -> bool
torch.distributed.device_mesh.new_group(ranks=None, timeout=None, backend=None, pg_options=None, use_local_synchronization=False, group_desc=None)
torch.distributed.device_mesh.not_none(obj: Optional[~T]) -> ~T
torch.distributed.distributed_c10d.Any(*args, **kwds)
torch.distributed.distributed_c10d.Backend(name: str)
torch.distributed.distributed_c10d.BackendConfig(backend: torch.distributed.distributed_c10d.Backend)
torch.distributed.distributed_c10d.Callable(*args, **kwargs)
torch.distributed.distributed_c10d.Dict(*args, **kwargs)
torch.distributed.distributed_c10d.GroupMember()
torch.distributed.distributed_c10d.List(*args, **kwargs)
torch.distributed.distributed_c10d.Optional(*args, **kwds)
torch.distributed.distributed_c10d.P2POp(op: Callable, tensor: torch.Tensor, peer: int, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0)
torch.distributed.distributed_c10d.Tuple(*args, **kwargs)
torch.distributed.distributed_c10d.Union(*args, **kwds)
torch.distributed.distributed_c10d.all_gather(tensor_list, tensor, group=None, async_op=False)
torch.distributed.distributed_c10d.all_gather_coalesced(output_tensor_lists, input_tensor_list, group=None, async_op=False)
torch.distributed.distributed_c10d.all_gather_into_tensor(output_tensor, input_tensor, group=None, async_op=False)
torch.distributed.distributed_c10d.all_gather_object(object_list, obj, group=None)
torch.distributed.distributed_c10d.all_reduce(tensor, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.distributed_c10d.all_reduce_coalesced(tensors, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.distributed_c10d.all_to_all(output_tensor_list, input_tensor_list, group=None, async_op=False)
torch.distributed.distributed_c10d.all_to_all_single(output, input, output_split_sizes=None, input_split_sizes=None, group=None, async_op=False)
torch.distributed.distributed_c10d.barrier(group=None, async_op=False, device_ids=None)
torch.distributed.distributed_c10d.batch_isend_irecv(p2p_op_list)
torch.distributed.distributed_c10d.broadcast(tensor, src, group=None, async_op=False)
torch.distributed.distributed_c10d.broadcast_object_list(object_list, src=0, group=None, device=None)
torch.distributed.distributed_c10d.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.distributed.distributed_c10d.destroy_process_group(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None)
torch.distributed.distributed_c10d.gather(tensor, gather_list=None, dst=0, group=None, async_op=False)
torch.distributed.distributed_c10d.gather_object(obj, object_gather_list=None, dst=0, group=None)
torch.distributed.distributed_c10d.get_backend(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> torch.distributed.distributed_c10d.Backend
torch.distributed.distributed_c10d.get_backend_config(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> str
torch.distributed.distributed_c10d.get_global_rank(group: torch.distributed.distributed_c10d.ProcessGroup, group_rank: int) -> int
torch.distributed.distributed_c10d.get_group_rank(group: torch.distributed.distributed_c10d.ProcessGroup, global_rank: int) -> int
torch.distributed.distributed_c10d.get_node_local_rank(fallback_rank: Optional[int] = None) -> int
torch.distributed.distributed_c10d.get_pg_count() -> int
torch.distributed.distributed_c10d.get_process_group_ranks(group: torch.distributed.distributed_c10d.ProcessGroup) -> List[int]
torch.distributed.distributed_c10d.get_rank(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> int
torch.distributed.distributed_c10d.get_world_size(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> int
torch.distributed.distributed_c10d.group()
torch.distributed.distributed_c10d.init_process_group(backend: Optional[str] = None, init_method: Optional[str] = None, timeout: Optional[datetime.timedelta] = None, world_size: int = -1, rank: int = -1, store: Optional[torch.distributed.distributed_c10d.Store] = None, group_name: str = '', pg_options: Optional[Any] = None, device_id: Optional[torch.device] = None) -> None
torch.distributed.distributed_c10d.irecv(tensor: torch.Tensor, src: Optional[int] = None, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> Optional[torch.distributed.distributed_c10d.Work]
torch.distributed.distributed_c10d.is_backend_available(backend: str) -> bool
torch.distributed.distributed_c10d.is_gloo_available() -> bool
torch.distributed.distributed_c10d.is_initialized() -> bool
torch.distributed.distributed_c10d.is_mpi_available() -> bool
torch.distributed.distributed_c10d.is_nccl_available() -> bool
torch.distributed.distributed_c10d.is_torchelastic_launched() -> bool
torch.distributed.distributed_c10d.is_ucc_available() -> bool
torch.distributed.distributed_c10d.isend(tensor: torch.Tensor, dst: int, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> Optional[torch.distributed.distributed_c10d.Work]
torch.distributed.distributed_c10d.monitored_barrier(group=None, timeout=None, wait_all_ranks=False)
torch.distributed.distributed_c10d.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.distributed.distributed_c10d.new_group(ranks=None, timeout=None, backend=None, pg_options=None, use_local_synchronization=False, group_desc=None)
torch.distributed.distributed_c10d.new_subgroups(group_size=None, group=None, timeout=None, backend=None, pg_options=None, group_desc=None)
torch.distributed.distributed_c10d.new_subgroups_by_enumeration(ranks_per_subgroup_list, timeout=None, backend=None, pg_options=None, group_desc=None)
torch.distributed.distributed_c10d.not_none(obj: Optional[~T]) -> ~T
torch.distributed.distributed_c10d.recv(tensor: torch.Tensor, src: Optional[int] = None, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> int
torch.distributed.distributed_c10d.recv_object_list(object_list, src=None, group=None, device=None)
torch.distributed.distributed_c10d.reduce(tensor, dst, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.distributed_c10d.reduce_scatter(output, input_list, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.distributed_c10d.reduce_scatter_tensor(output, input, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.distributed_c10d.register_rendezvous_handler(scheme, handler)
torch.distributed.distributed_c10d.rendezvous(url: str, rank: int = -1, world_size: int = -1, **kwargs)
torch.distributed.distributed_c10d.scatter(tensor, scatter_list=None, src=0, group=None, async_op=False)
torch.distributed.distributed_c10d.scatter_object_list(scatter_object_output_list, scatter_object_input_list, src=0, group=None)
torch.distributed.distributed_c10d.send(tensor: torch.Tensor, dst: int, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> None
torch.distributed.distributed_c10d.send_object_list(object_list, dst, group=None, device=None)
torch.distributed.distributed_c10d.set_pytorch_distributed_envs_from_justknobs()
torch.distributed.distributed_c10d.supports_complex(reduceOp: torch.distributed.distributed_c10d.ReduceOp) -> bool
torch.distributed.gather(tensor, gather_list=None, dst=0, group=None, async_op=False)
torch.distributed.gather_object(obj, object_gather_list=None, dst=0, group=None)
torch.distributed.get_backend(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> torch.distributed.distributed_c10d.Backend
torch.distributed.get_backend_config(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> str
torch.distributed.get_global_rank(group: torch.distributed.distributed_c10d.ProcessGroup, group_rank: int) -> int
torch.distributed.get_group_rank(group: torch.distributed.distributed_c10d.ProcessGroup, global_rank: int) -> int
torch.distributed.get_node_local_rank(fallback_rank: Optional[int] = None) -> int
torch.distributed.get_pg_count() -> int
torch.distributed.get_process_group_ranks(group: torch.distributed.distributed_c10d.ProcessGroup) -> List[int]
torch.distributed.get_rank(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> int
torch.distributed.get_world_size(group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None) -> int
torch.distributed.group()
torch.distributed.init_device_mesh(device_type: str, mesh_shape: Tuple[int, ...], *, mesh_dim_names: Optional[Tuple[str, ...]] = None) -> torch.distributed.device_mesh.DeviceMesh
torch.distributed.init_process_group(backend: Optional[str] = None, init_method: Optional[str] = None, timeout: Optional[datetime.timedelta] = None, world_size: int = -1, rank: int = -1, store: Optional[torch.distributed.distributed_c10d.Store] = None, group_name: str = '', pg_options: Optional[Any] = None, device_id: Optional[torch.device] = None) -> None
torch.distributed.irecv(tensor: torch.Tensor, src: Optional[int] = None, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> Optional[torch.distributed.distributed_c10d.Work]
torch.distributed.is_available() -> bool
torch.distributed.is_backend_available(backend: str) -> bool
torch.distributed.is_gloo_available() -> bool
torch.distributed.is_initialized() -> bool
torch.distributed.is_mpi_available() -> bool
torch.distributed.is_nccl_available() -> bool
torch.distributed.is_torchelastic_launched() -> bool
torch.distributed.is_ucc_available() -> bool
torch.distributed.isend(tensor: torch.Tensor, dst: int, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> Optional[torch.distributed.distributed_c10d.Work]
torch.distributed.logging_handlers.Dict(*args, **kwargs)
torch.distributed.logging_handlers.List(*args, **kwargs)
torch.distributed.monitored_barrier(group=None, timeout=None, wait_all_ranks=False)
torch.distributed.new_group(ranks=None, timeout=None, backend=None, pg_options=None, use_local_synchronization=False, group_desc=None)
torch.distributed.new_subgroups(group_size=None, group=None, timeout=None, backend=None, pg_options=None, group_desc=None)
torch.distributed.new_subgroups_by_enumeration(ranks_per_subgroup_list, timeout=None, backend=None, pg_options=None, group_desc=None)
torch.distributed.recv(tensor: torch.Tensor, src: Optional[int] = None, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> int
torch.distributed.recv_object_list(object_list, src=None, group=None, device=None)
torch.distributed.reduce(tensor, dst, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.reduce_scatter(output, input_list, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.reduce_scatter_tensor(output, input, op=<RedOpType.SUM: 0>, group=None, async_op=False)
torch.distributed.register_rendezvous_handler(scheme, handler)
torch.distributed.remote_device.Optional(*args, **kwds)
torch.distributed.remote_device.Union(*args, **kwds)
torch.distributed.rendezvous(url: str, rank: int = -1, world_size: int = -1, **kwargs)
torch.distributed.rpc.Generator(*args, **kwargs)
torch.distributed.rpc.Tuple(*args, **kwargs)
torch.distributed.rpc.is_available() -> bool
torch.distributed.rpc.urlparse(url, scheme='', allow_fragments=True)
torch.distributed.scatter(tensor, scatter_list=None, src=0, group=None, async_op=False)
torch.distributed.scatter_object_list(scatter_object_output_list, scatter_object_input_list, src=0, group=None)
torch.distributed.send(tensor: torch.Tensor, dst: int, group: Optional[torch.distributed.distributed_c10d.ProcessGroup] = None, tag: int = 0) -> None
torch.distributed.send_object_list(object_list, dst, group=None, device=None)
torch.distributed.supports_complex(reduceOp: torch.distributed.distributed_c10d.ReduceOp) -> bool
torch.distributed.utils.Any(*args, **kwds)
torch.distributed.utils.Callable(*args, **kwargs)
torch.distributed.utils.Container(*args, **kwargs)
torch.distributed.utils.Dict(*args, **kwargs)
torch.distributed.utils.List(*args, **kwargs)
torch.distributed.utils.Optional(*args, **kwds)
torch.distributed.utils.OrderedDict(*args, **kwargs)
torch.distributed.utils.PackedSequence(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None)
torch.distributed.utils.Tuple(*args, **kwargs)
torch.distributed.utils.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.distributed.utils.overload(func)
torch.distributions.AbsTransform(cache_size=0)
torch.distributions.AffineTransform(loc, scale, event_dim=0, cache_size=0)
torch.distributions.Bernoulli(probs=None, logits=None, validate_args=None)
torch.distributions.Beta(concentration1, concentration0, validate_args=None)
torch.distributions.Binomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.CatTransform(tseq, dim=0, lengths=None, cache_size=0)
torch.distributions.Categorical(probs=None, logits=None, validate_args=None)
torch.distributions.Cauchy(loc, scale, validate_args=None)
torch.distributions.Chi2(df, validate_args=None)
torch.distributions.ComposeTransform(parts: List[torch.distributions.transforms.Transform], cache_size=0)
torch.distributions.ContinuousBernoulli(probs=None, logits=None, lims=(0.499, 0.501), validate_args=None)
torch.distributions.CorrCholeskyTransform(cache_size=0)
torch.distributions.CumulativeDistributionTransform(distribution, cache_size=0)
torch.distributions.Dirichlet(concentration, validate_args=None)
torch.distributions.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.ExpTransform(cache_size=0)
torch.distributions.Exponential(rate, validate_args=None)
torch.distributions.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.FisherSnedecor(df1, df2, validate_args=None)
torch.distributions.Gamma(concentration, rate, validate_args=None)
torch.distributions.Geometric(probs=None, logits=None, validate_args=None)
torch.distributions.Gumbel(loc, scale, validate_args=None)
torch.distributions.HalfCauchy(scale, validate_args=None)
torch.distributions.HalfNormal(scale, validate_args=None)
torch.distributions.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)
torch.distributions.IndependentTransform(base_transform, reinterpreted_batch_ndims, cache_size=0)
torch.distributions.InverseGamma(concentration, rate, validate_args=None)
torch.distributions.Kumaraswamy(concentration1, concentration0, validate_args=None)
torch.distributions.LKJCholesky(dim, concentration=1.0, validate_args=None)
torch.distributions.Laplace(loc, scale, validate_args=None)
torch.distributions.LogNormal(loc, scale, validate_args=None)
torch.distributions.LogisticNormal(loc, scale, validate_args=None)
torch.distributions.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)
torch.distributions.LowerCholeskyTransform(cache_size=0)
torch.distributions.MixtureSameFamily(mixture_distribution, component_distribution, validate_args=None)
torch.distributions.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)
torch.distributions.NegativeBinomial(total_count, probs=None, logits=None, validate_args=None)
torch.distributions.Normal(loc, scale, validate_args=None)
torch.distributions.OneHotCategorical(probs=None, logits=None, validate_args=None)
torch.distributions.OneHotCategoricalStraightThrough(probs=None, logits=None, validate_args=None)
torch.distributions.Pareto(scale, alpha, validate_args=None)
torch.distributions.Poisson(rate, validate_args=None)
torch.distributions.PositiveDefiniteTransform(cache_size=0)
torch.distributions.PowerTransform(exponent, cache_size=0)
torch.distributions.RelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.RelaxedOneHotCategorical(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.ReshapeTransform(in_shape, out_shape, cache_size=0)
torch.distributions.SigmoidTransform(cache_size=0)
torch.distributions.SoftmaxTransform(cache_size=0)
torch.distributions.SoftplusTransform(cache_size=0)
torch.distributions.StackTransform(tseq, dim=0, cache_size=0)
torch.distributions.StickBreakingTransform(cache_size=0)
torch.distributions.StudentT(df, loc=0.0, scale=1.0, validate_args=None)
torch.distributions.TanhTransform(cache_size=0)
torch.distributions.Transform(cache_size=0)
torch.distributions.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.Uniform(low, high, validate_args=None)
torch.distributions.VonMises(loc, concentration, validate_args=None)
torch.distributions.Weibull(scale, concentration, validate_args=None)
torch.distributions.Wishart(df: Union[torch.Tensor, numbers.Number], covariance_matrix: Optional[torch.Tensor] = None, precision_matrix: Optional[torch.Tensor] = None, scale_tril: Optional[torch.Tensor] = None, validate_args=None)
torch.distributions.bernoulli.Bernoulli(probs=None, logits=None, validate_args=None)
torch.distributions.bernoulli.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.bernoulli.Number()
torch.distributions.bernoulli.binary_cross_entropy_with_logits(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> torch.Tensor
torch.distributions.bernoulli.broadcast_all(*values)
torch.distributions.bernoulli.lazy_property(wrapped)
torch.distributions.bernoulli.logits_to_probs(logits, is_binary=False)
torch.distributions.bernoulli.probs_to_logits(probs, is_binary=False)
torch.distributions.beta.Beta(concentration1, concentration0, validate_args=None)
torch.distributions.beta.Dirichlet(concentration, validate_args=None)
torch.distributions.beta.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.beta.Number()
torch.distributions.beta.Real()
torch.distributions.beta.broadcast_all(*values)
torch.distributions.biject_to(constraint)
torch.distributions.binomial.Binomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.binomial.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.binomial.broadcast_all(*values)
torch.distributions.binomial.lazy_property(wrapped)
torch.distributions.binomial.logits_to_probs(logits, is_binary=False)
torch.distributions.binomial.probs_to_logits(probs, is_binary=False)
torch.distributions.categorical.Categorical(probs=None, logits=None, validate_args=None)
torch.distributions.categorical.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.categorical.lazy_property(wrapped)
torch.distributions.categorical.logits_to_probs(logits, is_binary=False)
torch.distributions.categorical.probs_to_logits(probs, is_binary=False)
torch.distributions.cauchy.Cauchy(loc, scale, validate_args=None)
torch.distributions.cauchy.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.cauchy.Number()
torch.distributions.cauchy.broadcast_all(*values)
torch.distributions.chi2.Chi2(df, validate_args=None)
torch.distributions.chi2.Gamma(concentration, rate, validate_args=None)
torch.distributions.constraint_registry.ConstraintRegistry()
torch.distributions.constraint_registry.biject_to(constraint)
torch.distributions.constraint_registry.transform_to(constraint)
torch.distributions.constraints.Constraint()
torch.distributions.constraints.cat(cseq, dim=0, lengths=None)
torch.distributions.constraints.dependent(*, is_discrete=NotImplemented, event_dim=NotImplemented)
torch.distributions.constraints.dependent_property(fn=None, *, is_discrete=NotImplemented, event_dim=NotImplemented)
torch.distributions.constraints.greater_than(lower_bound)
torch.distributions.constraints.greater_than_eq(lower_bound)
torch.distributions.constraints.half_open_interval(lower_bound, upper_bound)
torch.distributions.constraints.independent(base_constraint, reinterpreted_batch_ndims)
torch.distributions.constraints.integer_interval(lower_bound, upper_bound)
torch.distributions.constraints.interval(lower_bound, upper_bound)
torch.distributions.constraints.is_dependent(constraint)
torch.distributions.constraints.less_than(upper_bound)
torch.distributions.constraints.multinomial(upper_bound)
torch.distributions.constraints.stack(cseq, dim=0)
torch.distributions.continuous_bernoulli.ContinuousBernoulli(probs=None, logits=None, lims=(0.499, 0.501), validate_args=None)
torch.distributions.continuous_bernoulli.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.continuous_bernoulli.Number()
torch.distributions.continuous_bernoulli.binary_cross_entropy_with_logits(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> torch.Tensor
torch.distributions.continuous_bernoulli.broadcast_all(*values)
torch.distributions.continuous_bernoulli.clamp_probs(probs)
torch.distributions.continuous_bernoulli.lazy_property(wrapped)
torch.distributions.continuous_bernoulli.logits_to_probs(logits, is_binary=False)
torch.distributions.continuous_bernoulli.probs_to_logits(probs, is_binary=False)
torch.distributions.dirichlet.Dirichlet(concentration, validate_args=None)
torch.distributions.dirichlet.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.dirichlet.Function(*args, **kwargs)
torch.distributions.dirichlet.once_differentiable(fn)
torch.distributions.distribution.Any(*args, **kwds)
torch.distributions.distribution.Dict(*args, **kwargs)
torch.distributions.distribution.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.distribution.Optional(*args, **kwds)
torch.distributions.distribution.Tuple(*args, **kwargs)
torch.distributions.distribution.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.distributions.distribution.lazy_property(wrapped)
torch.distributions.exp_family.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.exp_family.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.exponential.Exponential(rate, validate_args=None)
torch.distributions.exponential.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.exponential.Number()
torch.distributions.exponential.broadcast_all(*values)
torch.distributions.fishersnedecor.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.fishersnedecor.FisherSnedecor(df1, df2, validate_args=None)
torch.distributions.fishersnedecor.Gamma(concentration, rate, validate_args=None)
torch.distributions.fishersnedecor.Number()
torch.distributions.fishersnedecor.broadcast_all(*values)
torch.distributions.gamma.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.gamma.Gamma(concentration, rate, validate_args=None)
torch.distributions.gamma.Number()
torch.distributions.gamma.broadcast_all(*values)
torch.distributions.geometric.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.geometric.Geometric(probs=None, logits=None, validate_args=None)
torch.distributions.geometric.Number()
torch.distributions.geometric.binary_cross_entropy_with_logits(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> torch.Tensor
torch.distributions.geometric.broadcast_all(*values)
torch.distributions.geometric.lazy_property(wrapped)
torch.distributions.geometric.logits_to_probs(logits, is_binary=False)
torch.distributions.geometric.probs_to_logits(probs, is_binary=False)
torch.distributions.gumbel.AffineTransform(loc, scale, event_dim=0, cache_size=0)
torch.distributions.gumbel.ExpTransform(cache_size=0)
torch.distributions.gumbel.Gumbel(loc, scale, validate_args=None)
torch.distributions.gumbel.Number()
torch.distributions.gumbel.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.gumbel.Uniform(low, high, validate_args=None)
torch.distributions.gumbel.broadcast_all(*values)
torch.distributions.half_cauchy.AbsTransform(cache_size=0)
torch.distributions.half_cauchy.Cauchy(loc, scale, validate_args=None)
torch.distributions.half_cauchy.HalfCauchy(scale, validate_args=None)
torch.distributions.half_cauchy.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.half_normal.AbsTransform(cache_size=0)
torch.distributions.half_normal.HalfNormal(scale, validate_args=None)
torch.distributions.half_normal.Normal(loc, scale, validate_args=None)
torch.distributions.half_normal.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.identity_transform(x)
torch.distributions.independent.Dict(*args, **kwargs)
torch.distributions.independent.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.independent.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)
torch.distributions.inverse_gamma.Gamma(concentration, rate, validate_args=None)
torch.distributions.inverse_gamma.InverseGamma(concentration, rate, validate_args=None)
torch.distributions.inverse_gamma.PowerTransform(exponent, cache_size=0)
torch.distributions.inverse_gamma.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.kl.Bernoulli(probs=None, logits=None, validate_args=None)
torch.distributions.kl.Beta(concentration1, concentration0, validate_args=None)
torch.distributions.kl.Binomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.kl.Callable(*args, **kwargs)
torch.distributions.kl.Categorical(probs=None, logits=None, validate_args=None)
torch.distributions.kl.Cauchy(loc, scale, validate_args=None)
torch.distributions.kl.ContinuousBernoulli(probs=None, logits=None, lims=(0.499, 0.501), validate_args=None)
torch.distributions.kl.Dict(*args, **kwargs)
torch.distributions.kl.Dirichlet(concentration, validate_args=None)
torch.distributions.kl.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.kl.Exponential(rate, validate_args=None)
torch.distributions.kl.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.kl.Gamma(concentration, rate, validate_args=None)
torch.distributions.kl.Geometric(probs=None, logits=None, validate_args=None)
torch.distributions.kl.Gumbel(loc, scale, validate_args=None)
torch.distributions.kl.HalfNormal(scale, validate_args=None)
torch.distributions.kl.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)
torch.distributions.kl.Laplace(loc, scale, validate_args=None)
torch.distributions.kl.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)
torch.distributions.kl.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)
torch.distributions.kl.Normal(loc, scale, validate_args=None)
torch.distributions.kl.OneHotCategorical(probs=None, logits=None, validate_args=None)
torch.distributions.kl.Pareto(scale, alpha, validate_args=None)
torch.distributions.kl.Poisson(rate, validate_args=None)
torch.distributions.kl.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.kl.Tuple(*args, **kwargs)
torch.distributions.kl.Type(*args, **kwargs)
torch.distributions.kl.Uniform(low, high, validate_args=None)
torch.distributions.kl.kl_divergence(p: torch.distributions.distribution.Distribution, q: torch.distributions.distribution.Distribution) -> torch.Tensor
torch.distributions.kl.register_kl(type_p, type_q)
torch.distributions.kl.total_ordering(cls)
torch.distributions.kl_divergence(p: torch.distributions.distribution.Distribution, q: torch.distributions.distribution.Distribution) -> torch.Tensor
torch.distributions.kumaraswamy.AffineTransform(loc, scale, event_dim=0, cache_size=0)
torch.distributions.kumaraswamy.Kumaraswamy(concentration1, concentration0, validate_args=None)
torch.distributions.kumaraswamy.PowerTransform(exponent, cache_size=0)
torch.distributions.kumaraswamy.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.kumaraswamy.Uniform(low, high, validate_args=None)
torch.distributions.kumaraswamy.broadcast_all(*values)
torch.distributions.laplace.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.laplace.Laplace(loc, scale, validate_args=None)
torch.distributions.laplace.Number()
torch.distributions.laplace.broadcast_all(*values)
torch.distributions.lkj_cholesky.Beta(concentration1, concentration0, validate_args=None)
torch.distributions.lkj_cholesky.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.lkj_cholesky.LKJCholesky(dim, concentration=1.0, validate_args=None)
torch.distributions.lkj_cholesky.broadcast_all(*values)
torch.distributions.log_normal.ExpTransform(cache_size=0)
torch.distributions.log_normal.LogNormal(loc, scale, validate_args=None)
torch.distributions.log_normal.Normal(loc, scale, validate_args=None)
torch.distributions.log_normal.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.logistic_normal.LogisticNormal(loc, scale, validate_args=None)
torch.distributions.logistic_normal.Normal(loc, scale, validate_args=None)
torch.distributions.logistic_normal.StickBreakingTransform(cache_size=0)
torch.distributions.logistic_normal.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.lowrank_multivariate_normal.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)
torch.distributions.lowrank_multivariate_normal.lazy_property(wrapped)
torch.distributions.mixture_same_family.Categorical(probs=None, logits=None, validate_args=None)
torch.distributions.mixture_same_family.Dict(*args, **kwargs)
torch.distributions.mixture_same_family.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.mixture_same_family.MixtureSameFamily(mixture_distribution, component_distribution, validate_args=None)
torch.distributions.multinomial.Binomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.multinomial.Categorical(probs=None, logits=None, validate_args=None)
torch.distributions.multinomial.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.multinomial.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)
torch.distributions.multinomial.broadcast_all(*values)
torch.distributions.multivariate_normal.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.multivariate_normal.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)
torch.distributions.multivariate_normal.lazy_property(wrapped)
torch.distributions.negative_binomial.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.negative_binomial.NegativeBinomial(total_count, probs=None, logits=None, validate_args=None)
torch.distributions.negative_binomial.broadcast_all(*values)
torch.distributions.negative_binomial.lazy_property(wrapped)
torch.distributions.negative_binomial.logits_to_probs(logits, is_binary=False)
torch.distributions.negative_binomial.probs_to_logits(probs, is_binary=False)
torch.distributions.normal.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.normal.Normal(loc, scale, validate_args=None)
torch.distributions.normal.Number()
torch.distributions.normal.Real()
torch.distributions.normal.broadcast_all(*values)
torch.distributions.one_hot_categorical.Categorical(probs=None, logits=None, validate_args=None)
torch.distributions.one_hot_categorical.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.one_hot_categorical.OneHotCategorical(probs=None, logits=None, validate_args=None)
torch.distributions.one_hot_categorical.OneHotCategoricalStraightThrough(probs=None, logits=None, validate_args=None)
torch.distributions.pareto.AffineTransform(loc, scale, event_dim=0, cache_size=0)
torch.distributions.pareto.ExpTransform(cache_size=0)
torch.distributions.pareto.Exponential(rate, validate_args=None)
torch.distributions.pareto.Pareto(scale, alpha, validate_args=None)
torch.distributions.pareto.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.pareto.broadcast_all(*values)
torch.distributions.poisson.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.poisson.Number()
torch.distributions.poisson.Poisson(rate, validate_args=None)
torch.distributions.poisson.broadcast_all(*values)
torch.distributions.register_kl(type_p, type_q)
torch.distributions.relaxed_bernoulli.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.relaxed_bernoulli.Number()
torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.relaxed_bernoulli.SigmoidTransform(cache_size=0)
torch.distributions.relaxed_bernoulli.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.relaxed_bernoulli.broadcast_all(*values)
torch.distributions.relaxed_bernoulli.clamp_probs(probs)
torch.distributions.relaxed_bernoulli.lazy_property(wrapped)
torch.distributions.relaxed_bernoulli.logits_to_probs(logits, is_binary=False)
torch.distributions.relaxed_bernoulli.probs_to_logits(probs, is_binary=False)
torch.distributions.relaxed_categorical.Categorical(probs=None, logits=None, validate_args=None)
torch.distributions.relaxed_categorical.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.relaxed_categorical.ExpTransform(cache_size=0)
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature, probs=None, logits=None, validate_args=None)
torch.distributions.relaxed_categorical.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.relaxed_categorical.broadcast_all(*values)
torch.distributions.relaxed_categorical.clamp_probs(probs)
torch.distributions.studentT.Chi2(df, validate_args=None)
torch.distributions.studentT.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.studentT.StudentT(df, loc=0.0, scale=1.0, validate_args=None)
torch.distributions.studentT.broadcast_all(*values)
torch.distributions.transform_to(constraint)
torch.distributions.transformed_distribution.ComposeTransform(parts: List[torch.distributions.transforms.Transform], cache_size=0)
torch.distributions.transformed_distribution.Dict(*args, **kwargs)
torch.distributions.transformed_distribution.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.transformed_distribution.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)
torch.distributions.transformed_distribution.Transform(cache_size=0)
torch.distributions.transformed_distribution.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.transforms.AbsTransform(cache_size=0)
torch.distributions.transforms.AffineTransform(loc, scale, event_dim=0, cache_size=0)
torch.distributions.transforms.CatTransform(tseq, dim=0, lengths=None, cache_size=0)
torch.distributions.transforms.ComposeTransform(parts: List[torch.distributions.transforms.Transform], cache_size=0)
torch.distributions.transforms.CorrCholeskyTransform(cache_size=0)
torch.distributions.transforms.CumulativeDistributionTransform(distribution, cache_size=0)
torch.distributions.transforms.ExpTransform(cache_size=0)
torch.distributions.transforms.IndependentTransform(base_transform, reinterpreted_batch_ndims, cache_size=0)
torch.distributions.transforms.List(*args, **kwargs)
torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)
torch.distributions.transforms.PositiveDefiniteTransform(cache_size=0)
torch.distributions.transforms.PowerTransform(exponent, cache_size=0)
torch.distributions.transforms.ReshapeTransform(in_shape, out_shape, cache_size=0)
torch.distributions.transforms.SigmoidTransform(cache_size=0)
torch.distributions.transforms.SoftmaxTransform(cache_size=0)
torch.distributions.transforms.SoftplusTransform(cache_size=0)
torch.distributions.transforms.StackTransform(tseq, dim=0, cache_size=0)
torch.distributions.transforms.StickBreakingTransform(cache_size=0)
torch.distributions.transforms.TanhTransform(cache_size=0)
torch.distributions.transforms.Transform(cache_size=0)
torch.distributions.transforms.broadcast_all(*values)
torch.distributions.transforms.identity_transform(x)
torch.distributions.transforms.lazy_property(wrapped)
torch.distributions.transforms.pad(input: torch.Tensor, pad: List[int], mode: str = 'constant', value: Optional[float] = None) -> torch.Tensor
torch.distributions.transforms.tril_matrix_to_vec(mat: torch.Tensor, diag: int = 0) -> torch.Tensor
torch.distributions.transforms.vec_to_tril_matrix(vec: torch.Tensor, diag: int = 0) -> torch.Tensor
torch.distributions.uniform.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.uniform.Number()
torch.distributions.uniform.Uniform(low, high, validate_args=None)
torch.distributions.uniform.broadcast_all(*values)
torch.distributions.utils.Any(*args, **kwds)
torch.distributions.utils.Dict(*args, **kwargs)
torch.distributions.utils.Number()
torch.distributions.utils.broadcast_all(*values)
torch.distributions.utils.clamp_probs(probs)
torch.distributions.utils.is_tensor_like(inp)
torch.distributions.utils.lazy_property(wrapped)
torch.distributions.utils.logits_to_probs(logits, is_binary=False)
torch.distributions.utils.probs_to_logits(probs, is_binary=False)
torch.distributions.utils.tril_matrix_to_vec(mat: torch.Tensor, diag: int = 0) -> torch.Tensor
torch.distributions.utils.update_wrapper(wrapper, wrapped, assigned=('__module__', '__name__', '__qualname__', '__doc__', '__annotations__'), updated=('__dict__',))
torch.distributions.utils.vec_to_tril_matrix(vec: torch.Tensor, diag: int = 0) -> torch.Tensor
torch.distributions.von_mises.Distribution(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.von_mises.VonMises(loc, concentration, validate_args=None)
torch.distributions.von_mises.broadcast_all(*values)
torch.distributions.von_mises.lazy_property(wrapped)
torch.distributions.weibull.AffineTransform(loc, scale, event_dim=0, cache_size=0)
torch.distributions.weibull.Exponential(rate, validate_args=None)
torch.distributions.weibull.PowerTransform(exponent, cache_size=0)
torch.distributions.weibull.TransformedDistribution(base_distribution, transforms, validate_args=None)
torch.distributions.weibull.Weibull(scale, concentration, validate_args=None)
torch.distributions.weibull.broadcast_all(*values)
torch.distributions.wishart.ExponentialFamily(batch_shape: torch.Size = torch.Size([]), event_shape: torch.Size = torch.Size([]), validate_args: Optional[bool] = None)
torch.distributions.wishart.Number()
torch.distributions.wishart.Optional(*args, **kwds)
torch.distributions.wishart.Union(*args, **kwds)
torch.distributions.wishart.Wishart(df: Union[torch.Tensor, numbers.Number], covariance_matrix: Optional[torch.Tensor] = None, precision_matrix: Optional[torch.Tensor] = None, scale_tril: Optional[torch.Tensor] = None, validate_args=None)
torch.distributions.wishart.lazy_property(wrapped)
torch.dtype()
torch.eig(self: torch.Tensor, eigenvectors: bool = False, *, e=None, v=None) -> Tuple[torch.Tensor, torch.Tensor]
torch.einsum(*args: Any) -> torch.Tensor
torch.enable_grad(orig_func=None)
torch.export.Any(*args, **kwds)
torch.export.Callable(*args, **kwargs)
torch.export.Constraint(*args, **kwargs)
torch.export.Dict(*args, **kwargs)
torch.export.Dim(name: str, *, min: Optional[int] = None, max: Optional[int] = None)
torch.export.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.export.ExportBackwardSignature(gradients_to_parameters: Dict[str, str], gradients_to_user_inputs: Dict[str, str], loss_output: str) -> None
torch.export.ExportGraphSignature(input_specs: List[torch.export.graph_signature.InputSpec], output_specs: List[torch.export.graph_signature.OutputSpec]) -> None
torch.export.ExportedProgram(root: Union[torch.nn.modules.module.Module, Dict[str, Any]], graph: torch.fx.graph.Graph, graph_signature: torch.export.graph_signature.ExportGraphSignature, state_dict: Dict[str, Union[torch.Tensor, torch.nn.parameter.Parameter]], range_constraints: 'Dict[sympy.Symbol, Any]', module_call_graph: List[torch.export.exported_program.ModuleCallEntry], example_inputs: Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]] = None, verifier: Optional[Type[Any]] = None, tensor_constants: Optional[Dict[str, torch.Tensor]] = None, constants: Optional[Dict[str, Union[torch.Tensor, torch.ScriptObject]]] = None)
torch.export.FlatArgsAdapter()
torch.export.FlattenFunc(*args, **kwargs)
torch.export.FromDumpableContextFn(*args, **kwargs)
torch.export.Iterator(*args, **kwargs)
torch.export.List(*args, **kwargs)
torch.export.ModuleCallEntry(fqn: str, signature: Optional[torch.export.exported_program.ModuleCallSignature] = None) -> None
torch.export.ModuleCallSignature(inputs: List[Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument]], outputs: List[Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument]], in_spec: torch.utils._pytree.TreeSpec, out_spec: torch.utils._pytree.TreeSpec) -> None
torch.export.Optional(*args, **kwds)
torch.export.PassManager(passes=None, constraints=None, steps=None, run_checks_after_each_pass: bool = False, suppress_check_failures: bool = False)
torch.export.PassResult(graph_module, modified)
torch.export.PassType(*args, **kwargs)
torch.export.ShapesCollection()
torch.export.ToDumpableContextFn(*args, **kwargs)
torch.export.Tuple(*args, **kwargs)
torch.export.Type(*args, **kwargs)
torch.export.UnflattenFunc(*args, **kwargs)
torch.export.UnflattenedModule(export_module: torch.export.exported_program.ExportedProgram, flat_args_adapter: Optional[torch.export.unflatten.FlatArgsAdapter] = None)
torch.export.Union(*args, **kwds)
torch.export.auto()
torch.export.compatibility(is_backward_compatible: bool)
torch.export.dims(*names: str, min: Optional[int] = None, max: Optional[int] = None)
torch.export.dynamic_dim(t: torch.Tensor, index: int, debug_name: Optional[str] = None)
torch.export.dynamic_shapes.Any(*args, **kwds)
torch.export.dynamic_shapes.Callable(*args, **kwargs)
torch.export.dynamic_shapes.Constraint(*args, **kwargs)
torch.export.dynamic_shapes.Dict(*args, **kwargs)
torch.export.dynamic_shapes.Dim(name: str, *, min: Optional[int] = None, max: Optional[int] = None)
torch.export.dynamic_shapes.ExportedProgram(root: Union[torch.nn.modules.module.Module, Dict[str, Any]], graph: torch.fx.graph.Graph, graph_signature: torch.export.graph_signature.ExportGraphSignature, state_dict: Dict[str, Union[torch.Tensor, torch.nn.parameter.Parameter]], range_constraints: 'Dict[sympy.Symbol, Any]', module_call_graph: List[torch.export.exported_program.ModuleCallEntry], example_inputs: Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]] = None, verifier: Optional[Type[Any]] = None, tensor_constants: Optional[Dict[str, torch.Tensor]] = None, constants: Optional[Dict[str, Union[torch.Tensor, torch.ScriptObject]]] = None)
torch.export.dynamic_shapes.List(*args, **kwargs)
torch.export.dynamic_shapes.Optional(*args, **kwds)
torch.export.dynamic_shapes.Set(*args, **kwargs)
torch.export.dynamic_shapes.ShapesCollection()
torch.export.dynamic_shapes.Tuple(*args, **kwargs)
torch.export.dynamic_shapes.Union(*args, **kwds)
torch.export.dynamic_shapes.dims(*names: str, min: Optional[int] = None, max: Optional[int] = None)
torch.export.dynamic_shapes.dynamic_dim(t: torch.Tensor, index: int, debug_name: Optional[str] = None)
torch.export.dynamic_shapes.refine_dynamic_shapes_from_suggested_fixes(msg: str, dynamic_shapes: Union[Dict[str, Any], Tuple[Any], List[Any]]) -> Union[Dict[str, Any], Tuple[Any], List[Any]]
torch.export.dynamic_shapes.tree_flatten(tree: Any, is_leaf: Optional[Callable[[Any], bool]] = None) -> Tuple[List[Any], torch.utils._pytree.TreeSpec]
torch.export.dynamic_shapes.tree_map(func: Callable[..., Any], tree: Any, *rests: Any, is_leaf: Optional[Callable[[Any], bool]] = None) -> Any
torch.export.export(mod: torch.nn.modules.module.Module, args: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]] = None, *, dynamic_shapes: Union[Dict[str, Any], Tuple[Any], List[Any], NoneType] = None, strict: bool = True, preserve_module_call_signature: Tuple[str, ...] = ()) -> torch.export.exported_program.ExportedProgram
torch.export.exported_program.Any(*args, **kwds)
torch.export.exported_program.ArgumentSpec(*args, **kwargs)
torch.export.exported_program.Callable(*args, **kwargs)
torch.export.exported_program.ConstantArgument(name: str, value: Union[int, float, bool, str, NoneType]) -> None
torch.export.exported_program.CustomObjArgument(name: str, class_fqn: str) -> None
torch.export.exported_program.Dict(*args, **kwargs)
torch.export.exported_program.ExportGraphSignature(input_specs: List[torch.export.graph_signature.InputSpec], output_specs: List[torch.export.graph_signature.OutputSpec]) -> None
torch.export.exported_program.ExportedProgram(root: Union[torch.nn.modules.module.Module, Dict[str, Any]], graph: torch.fx.graph.Graph, graph_signature: torch.export.graph_signature.ExportGraphSignature, state_dict: Dict[str, Union[torch.Tensor, torch.nn.parameter.Parameter]], range_constraints: 'Dict[sympy.Symbol, Any]', module_call_graph: List[torch.export.exported_program.ModuleCallEntry], example_inputs: Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]] = None, verifier: Optional[Type[Any]] = None, tensor_constants: Optional[Dict[str, torch.Tensor]] = None, constants: Optional[Dict[str, Union[torch.Tensor, torch.ScriptObject]]] = None)
torch.export.exported_program.InputKind(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.export.exported_program.InputSpec(kind: torch.export.graph_signature.InputKind, arg: Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument], target: Optional[str], persistent: Optional[bool] = None) -> None
torch.export.exported_program.Iterator(*args, **kwargs)
torch.export.exported_program.List(*args, **kwargs)
torch.export.exported_program.ModuleCallEntry(fqn: str, signature: Optional[torch.export.exported_program.ModuleCallSignature] = None) -> None
torch.export.exported_program.ModuleCallSignature(inputs: List[Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument]], outputs: List[Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument]], in_spec: torch.utils._pytree.TreeSpec, out_spec: torch.utils._pytree.TreeSpec) -> None
torch.export.exported_program.Optional(*args, **kwds)
torch.export.exported_program.OutputKind(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.export.exported_program.OutputSpec(kind: torch.export.graph_signature.OutputKind, arg: Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument], target: Optional[str]) -> None
torch.export.exported_program.PassManager(passes=None, constraints=None, steps=None, run_checks_after_each_pass: bool = False, suppress_check_failures: bool = False)
torch.export.exported_program.PassResult(graph_module, modified)
torch.export.exported_program.PassType(*args, **kwargs)
torch.export.exported_program.SymIntArgument(name: str) -> None
torch.export.exported_program.TensorArgument(name: str) -> None
torch.export.exported_program.TokenArgument(name: str) -> None
torch.export.exported_program.Tuple(*args, **kwargs)
torch.export.exported_program.Type(*args, **kwargs)
torch.export.exported_program.Union(*args, **kwds)
torch.export.exported_program.compatibility(is_backward_compatible: bool)
torch.export.exported_program.first_call_function_nn_module_stack(graph: torch.fx.graph.Graph) -> Optional[Dict]
torch.export.exported_program.immutable_list(iterable=(), /)
torch.export.exported_program.insert_deferred_runtime_asserts(gm: torch.fx.graph_module.GraphModule, shape_env: Any, name: str, export: bool = False) -> None
torch.export.exported_program.is_equivalent(spec1: torch.utils._pytree.TreeSpec, spec2: torch.utils._pytree.TreeSpec, equivalence_fn: Callable[[Optional[type], Any, Optional[type], Any], bool]) -> bool
torch.export.exported_program.maybe_disable_fake_tensor_mode()
torch.export.exported_program.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.export.exported_program.reorder_kwargs(user_kwargs: Dict[str, Any], spec: torch.utils._pytree.TreeSpec) -> Dict[str, Any]
torch.export.graph_signature.ArgumentSpec(*args, **kwargs)
torch.export.graph_signature.Collection(*args, **kwargs)
torch.export.graph_signature.ConstantArgument(name: str, value: Union[int, float, bool, str, NoneType]) -> None
torch.export.graph_signature.CustomObjArgument(name: str, class_fqn: str) -> None
torch.export.graph_signature.Dict(*args, **kwargs)
torch.export.graph_signature.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.export.graph_signature.ExportBackwardSignature(gradients_to_parameters: Dict[str, str], gradients_to_user_inputs: Dict[str, str], loss_output: str) -> None
torch.export.graph_signature.ExportGraphSignature(input_specs: List[torch.export.graph_signature.InputSpec], output_specs: List[torch.export.graph_signature.OutputSpec]) -> None
torch.export.graph_signature.InputKind(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.export.graph_signature.InputSpec(kind: torch.export.graph_signature.InputKind, arg: Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument], target: Optional[str], persistent: Optional[bool] = None) -> None
torch.export.graph_signature.List(*args, **kwargs)
torch.export.graph_signature.Mapping(*args, **kwargs)
torch.export.graph_signature.Optional(*args, **kwds)
torch.export.graph_signature.OutputKind(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.export.graph_signature.OutputSpec(kind: torch.export.graph_signature.OutputKind, arg: Union[torch.export.graph_signature.TensorArgument, torch.export.graph_signature.SymIntArgument, torch.export.graph_signature.ConstantArgument, torch.export.graph_signature.CustomObjArgument, torch.export.graph_signature.TokenArgument], target: Optional[str]) -> None
torch.export.graph_signature.Set(*args, **kwargs)
torch.export.graph_signature.SymIntArgument(name: str) -> None
torch.export.graph_signature.TensorArgument(name: str) -> None
torch.export.graph_signature.TokenArgument(name: str) -> None
torch.export.graph_signature.Tuple(*args, **kwargs)
torch.export.graph_signature.Union(*args, **kwds)
torch.export.graph_signature.auto()
torch.export.load(f: Union[str, os.PathLike, _io.BytesIO], *, extra_files: Optional[Dict[str, Any]] = None, expected_opset_version: Optional[Dict[str, int]] = None) -> torch.export.exported_program.ExportedProgram
torch.export.register_dataclass(cls: Type[Any], *, serialized_type_name: Optional[str] = None) -> None
torch.export.save(ep: torch.export.exported_program.ExportedProgram, f: Union[str, os.PathLike, _io.BytesIO], *, extra_files: Optional[Dict[str, Any]] = None, opset_version: Optional[Dict[str, int]] = None) -> None
torch.export.unflatten(module: torch.export.exported_program.ExportedProgram, flat_args_adapter: Optional[torch.export.unflatten.FlatArgsAdapter] = None) -> torch.export.unflatten.UnflattenedModule
torch.from_dlpack(ext_tensor: Any) -> 'torch.Tensor'
torch.func.functional_call(module: 'torch.nn.Module', parameter_and_buffer_dicts: Union[Dict[str, torch.Tensor], Sequence[Dict[str, torch.Tensor]]], args: Union[Any, Tuple], kwargs: Optional[Dict[str, Any]] = None, *, tie_weights: bool = True, strict: bool = False)
torch.func.functionalize(func: Callable, *, remove: str = 'mutations') -> Callable
torch.func.grad(func: Callable, argnums: Union[int, Tuple[int, ...]] = 0, has_aux: bool = False) -> Callable
torch.func.grad_and_value(func: Callable, argnums: Union[int, Tuple[int, ...]] = 0, has_aux: bool = False) -> Callable
torch.func.hessian(func, argnums=0)
torch.func.jacfwd(func: Callable, argnums: Union[int, Tuple[int, ...]] = 0, has_aux: bool = False, *, randomness: str = 'error')
torch.func.jacrev(func: Callable, argnums: Union[int, Tuple[int]] = 0, *, has_aux=False, chunk_size: Optional[int] = None, _preallocate_and_copy=False)
torch.func.jvp(func: Callable, primals: Any, tangents: Any, *, strict: bool = False, has_aux: bool = False)
torch.func.linearize(func: Callable, *primals) -> Tuple[Any, Callable]
torch.func.replace_all_batch_norm_modules_(root: torch.nn.modules.module.Module) -> torch.nn.modules.module.Module
torch.func.stack_module_state(models: List[torch.nn.modules.module.Module]) -> Tuple[Dict[str, Any], Dict[str, Any]]
torch.func.vjp(func: Callable, *primals, has_aux: bool = False)
torch.func.vmap(func: Callable, in_dims: Union[int, Tuple] = 0, out_dims: Union[int, Tuple[int, ...]] = 0, randomness: str = 'error', *, chunk_size=None) -> Callable
torch.functional.Any(*args, **kwds)
torch.functional.List(*args, **kwargs)
torch.functional.Optional(*args, **kwds)
torch.functional.Sequence(*args, **kwargs)
torch.functional.Tuple(*args, **kwargs)
torch.functional.Union(*args, **kwds)
torch.functional.align_tensors(*tensors)
torch.functional.atleast_1d(*tensors)
torch.functional.atleast_2d(*tensors)
torch.functional.atleast_3d(*tensors)
torch.functional.block_diag(*tensors)
torch.functional.boolean_dispatch(arg_name, arg_index, default, if_true, if_false, module_name, func_name)
torch.functional.broadcast_shapes(*shapes)
torch.functional.broadcast_tensors(*tensors)
torch.functional.cartesian_prod(*tensors: torch.Tensor) -> torch.Tensor
torch.functional.cdist(x1, x2, p=2.0, compute_mode='use_mm_for_euclid_dist_if_necessary')
torch.functional.chain_matmul(*matrices, out=None)
torch.functional.einsum(*args: Any) -> torch.Tensor
torch.functional.handle_torch_function(public_api: Callable, relevant_args: Iterable[Any], *args, **kwargs) -> Any
torch.functional.lu(*args, **kwargs)
torch.functional.meshgrid(*tensors, indexing: Optional[str] = None) -> Tuple[torch.Tensor, ...]
torch.functional.norm(input, p: Union[float, str, NoneType] = 'fro', dim=None, keepdim=False, out=None, dtype=None)
torch.functional.overload(func)
torch.functional.pca_lowrank(A: torch.Tensor, q: Optional[int] = None, center: bool = True, niter: int = 2) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]
torch.functional.split(tensor: torch.Tensor, split_size_or_sections: Union[int, List[int]], dim: int = 0) -> Tuple[torch.Tensor, ...]
torch.functional.stft(input: torch.Tensor, n_fft: int, hop_length: Optional[int] = None, win_length: Optional[int] = None, window: Optional[torch.Tensor] = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Optional[bool] = None, return_complex: Optional[bool] = None) -> torch.Tensor
torch.functional.svd_lowrank(A: torch.Tensor, q: Optional[int] = 6, niter: Optional[int] = 2, M: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]
torch.functional.tensordot(a, b, dims=2, out: Optional[torch.Tensor] = None)
torch.functional.unique(*args, **kwargs)
torch.functional.unique_consecutive(*args, **kwargs)
torch.functional.unravel_index(indices: torch.Tensor, shape: Union[int, Sequence[int], torch.Size]) -> Tuple[torch.Tensor, ...]
torch.futures.Callable(*args, **kwargs)
torch.futures.Future(*, devices: 'Optional[List[Union[int, str, torch.device]]]' = None)
torch.futures.Generic()
torch.futures.List(*args, **kwargs)
torch.futures.Optional(*args, **kwds)
torch.futures.Type(*args, **kwargs)
torch.futures.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.futures.Union(*args, **kwds)
torch.futures.cast(typ, val)
torch.futures.collect_all(futures: 'List[Future]') -> 'Future[List[Future]]'
torch.futures.wait_all(futures: 'List[Future]') -> 'List'
torch.fx.CodeGen()
torch.fx.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.GraphModule(*args, **kwargs)
torch.fx.Interpreter(module: torch.nn.modules.module.Module, garbage_collect_values: bool = True, graph: Optional[torch.fx.graph.Graph] = None)
torch.fx.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.Proxy(node: torch.fx.node.Node, tracer: 'Optional[TracerBase]' = None)
torch.fx.ProxyableClassMeta(name, bases, attrs)
torch.fx.Tracer(autowrap_modules: Tuple[module] = (<module 'math' (built-in)>,), autowrap_functions: Tuple[Callable, ...] = (), param_shapes_constant: bool = False) -> None
torch.fx.Transformer(module)
torch.fx.experimental.const_fold.Callable(*args, **kwargs)
torch.fx.experimental.const_fold.Dict(*args, **kwargs)
torch.fx.experimental.const_fold.FoldedGraphModule(root: torch.nn.modules.module.Module, graph: torch.fx.graph.Graph, const_subgraph: Optional[torch.fx.graph.Graph] = None, fx_const_folded_attrs_name: Optional[str] = None, device_for_folded_attrs: str = 'cuda')
torch.fx.experimental.const_fold.Optional(*args, **kwds)
torch.fx.experimental.const_fold.Set(*args, **kwargs)
torch.fx.experimental.const_fold.Union(*args, **kwds)
torch.fx.experimental.const_fold.get_unique_attr_name_in_module(mod_traced: torch.fx.graph_module.GraphModule, name: str) -> str
torch.fx.experimental.const_fold.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.experimental.const_fold.split_const_subgraphs(module: Union[torch.nn.modules.module.Module, torch.fx.graph_module.GraphModule], skip_folding_node_fn: Optional[Callable[[torch.fx.node.Node], bool]] = None, device_for_folded_attrs: str = 'cpu') -> torch.fx.experimental.const_fold.FoldedGraphModule
torch.fx.experimental.const_fold.split_module(m: torch.fx.graph_module.GraphModule, root_m: torch.nn.modules.module.Module, split_callback: Callable[[torch.fx.node.Node], int], qualname_map: Optional[Dict[str, str]] = None, keep_original_order: Optional[bool] = False, keep_original_node_name: Optional[bool] = False)
torch.fx.experimental.proxy_tensor.Any(*args, **kwds)
torch.fx.experimental.proxy_tensor.BackwardState()
torch.fx.experimental.proxy_tensor.Callable(*args, **kwargs)
torch.fx.experimental.proxy_tensor.CapturedTraceback(tb, skip=0)
torch.fx.experimental.proxy_tensor.DecompositionInterpreter(module: torch.fx.graph_module.GraphModule, new_graph: torch.fx.graph.Graph, decomposition_table=None, **kwargs)
torch.fx.experimental.proxy_tensor.Dict(*args, **kwargs)
torch.fx.experimental.proxy_tensor.FakeScriptObject(wrapped_obj: Any, script_class_name: str)
torch.fx.experimental.proxy_tensor.FakeTensor(fake_mode, elem, device, constant=None, real_tensor=None)
torch.fx.experimental.proxy_tensor.FakeTensorMode(*, allow_fallback_kernels=True, allow_non_fake_inputs=False, shape_env=None, static_shapes=None, export=False)
torch.fx.experimental.proxy_tensor.GraphModule(*args, **kwargs)
torch.fx.experimental.proxy_tensor.List(*args, **kwargs)
torch.fx.experimental.proxy_tensor.Optional(*args, **kwds)
torch.fx.experimental.proxy_tensor.PreDispatchTorchFunctionMode(tracer)
torch.fx.experimental.proxy_tensor.Proxy(node: torch.fx.node.Node, tracer: 'Optional[TracerBase]' = None)
torch.fx.experimental.proxy_tensor.ProxySymDispatchMode(tracer)
torch.fx.experimental.proxy_tensor.ProxyTorchDispatchMode(tracer, tracing_mode, pre_dispatch=False, _allow_fake_constant=False, _error_on_data_dependent_ops=True)
torch.fx.experimental.proxy_tensor.PythonKeyTracer()
torch.fx.experimental.proxy_tensor.SymBool(node)
torch.fx.experimental.proxy_tensor.SymDispatchMode()
torch.fx.experimental.proxy_tensor.SymFloat(node)
torch.fx.experimental.proxy_tensor.SymInt(node)
torch.fx.experimental.proxy_tensor.SymNode(expr, shape_env, pytype, hint: Union[int, float, bool, NoneType], constant=None, fx_node=None)
torch.fx.experimental.proxy_tensor.TorchDispatchMode(_dispatch_key=None)
torch.fx.experimental.proxy_tensor.TorchFunctionMetadataMode(tracer)
torch.fx.experimental.proxy_tensor.TorchFunctionMode()
torch.fx.experimental.proxy_tensor.Tracer(autowrap_modules: Tuple[module] = (<module 'math' (built-in)>,), autowrap_functions: Tuple[Callable, ...] = (), param_shapes_constant: bool = False) -> None
torch.fx.experimental.proxy_tensor.Tuple(*args, **kwargs)
torch.fx.experimental.proxy_tensor.Union(*args, **kwds)
torch.fx.experimental.proxy_tensor.WeakIdKeyDictionary(dict=None, ref_type=<class 'torch.utils.weak.WeakIdRef'>)
torch.fx.experimental.proxy_tensor.WeakKeyDictionary(dict=None)
torch.fx.experimental.proxy_tensor.WeakTensorKeyDictionary(dict=None, ref_type=<class 'torch.utils.weak.WeakIdRef'>)
torch.fx.experimental.proxy_tensor.contextmanager(func)
torch.fx.experimental.proxy_tensor.count(fn)
torch.fx.experimental.proxy_tensor.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.experimental.proxy_tensor.decompose(decomposition_table)
torch.fx.experimental.proxy_tensor.disable_autocast_cache()
torch.fx.experimental.proxy_tensor.disable_proxy_modes_tracing()
torch.fx.experimental.proxy_tensor.dispatch_trace(root: Union[torch.nn.modules.module.Module, Callable], tracer: torch.fx._symbolic_trace.Tracer, concrete_args: Optional[Tuple[Any, ...]] = None) -> torch.fx.graph_module.GraphModule
torch.fx.experimental.proxy_tensor.extract_val(val)
torch.fx.experimental.proxy_tensor.fake_signature(fn, nargs)
torch.fx.experimental.proxy_tensor.fetch_object_proxy(tracer)
torch.fx.experimental.proxy_tensor.fetch_sym_proxy(tracer)
torch.fx.experimental.proxy_tensor.get_innermost_proxy_mode()
torch.fx.experimental.proxy_tensor.get_isolated_graphmodule(func, args, kwargs, tracing_mode='real')
torch.fx.experimental.proxy_tensor.get_proxy_slot(obj, tracer, default=<object object at 0x0000024A6192DE60>, transform=<function <lambda> at 0x0000024A63189CF0>)
torch.fx.experimental.proxy_tensor.get_torch_dispatch_modes()
torch.fx.experimental.proxy_tensor.has_proxy_slot(obj, tracer)
torch.fx.experimental.proxy_tensor.is_fake(x)
torch.fx.experimental.proxy_tensor.is_sym_node(node)
torch.fx.experimental.proxy_tensor.make_fx(f, decomposition_table=None, tracing_mode='real', _allow_non_fake_inputs=False, *, pre_dispatch=False, record_module_stack=False, _allow_fake_constant=False, _error_on_data_dependent_ops=True)
torch.fx.experimental.proxy_tensor.maybe_disable_fake_tensor_mode()
torch.fx.experimental.proxy_tensor.maybe_handle_decomp(proxy_mode, op, args, kwargs)
torch.fx.experimental.proxy_tensor.null_ctx_type(name, bases, namespace, **kwargs)
torch.fx.experimental.proxy_tensor.nullcontext(enter_result=None)
torch.fx.experimental.proxy_tensor.proxy_call(proxy_mode, func, pre_dispatch, args, kwargs)
torch.fx.experimental.proxy_tensor.set_meta(proxy, val)
torch.fx.experimental.proxy_tensor.set_original_aten_op(func)
torch.fx.experimental.proxy_tensor.set_proxy_slot(obj, tracer, proxy)
torch.fx.experimental.proxy_tensor.snapshot_fake(val)
torch.fx.experimental.proxy_tensor.thunkify(f, *args, **kwargs)
torch.fx.experimental.proxy_tensor.track_tensor(tensor, proxy, *, constant, tracer)
torch.fx.experimental.proxy_tensor.track_tensor_tree(inner_res, proxy_res, *, constant, tracer)
torch.fx.experimental.proxy_tensor.unset_fake_temporarily()
torch.fx.experimental.proxy_tensor.wrap_key(f, tensors, tracer, pre_dispatch: bool)
torch.fx.experimental.proxy_tensor.wrapper_and_args_for_make_fx(func, args, kwargs)
torch.fx.experimental.sym_node.Optional(*args, **kwds)
torch.fx.experimental.sym_node.SymBool(node)
torch.fx.experimental.sym_node.SymFloat(node)
torch.fx.experimental.sym_node.SymInt(node)
torch.fx.experimental.sym_node.SymNode(expr, shape_env, pytype, hint: Union[int, float, bool, NoneType], constant=None, fx_node=None)
torch.fx.experimental.sym_node.Type(*args, **kwargs)
torch.fx.experimental.sym_node.Union(*args, **kwds)
torch.fx.experimental.sym_node.handle_sym_dispatch(func, args, kwargs)
torch.fx.experimental.sym_node.is_channels_last_contiguous_2d(sizes, strides)
torch.fx.experimental.sym_node.is_channels_last_contiguous_3d(sizes, strides)
torch.fx.experimental.sym_node.is_channels_last_strides_2d(sizes, strides)
torch.fx.experimental.sym_node.is_channels_last_strides_3d(sizes, strides)
torch.fx.experimental.sym_node.is_contiguous(sizes, strides)
torch.fx.experimental.sym_node.is_non_overlapping_and_dense_indicator(sizes, strides)
torch.fx.experimental.sym_node.lru_cache(maxsize=128, typed=False)
torch.fx.experimental.sym_node.method_to_operator(method)
torch.fx.experimental.sym_node.sym_float(a)
torch.fx.experimental.sym_node.sym_function_mode()
torch.fx.experimental.sym_node.sym_ite(b, t, f)
torch.fx.experimental.sym_node.sym_max(a, b)
torch.fx.experimental.sym_node.sym_min(a, b)
torch.fx.experimental.sym_node.sym_not(a)
torch.fx.experimental.sym_node.sympy_is_channels_last_contiguous_2d(sizes, strides)
torch.fx.experimental.sym_node.sympy_is_channels_last_contiguous_3d(sizes, strides)
torch.fx.experimental.sym_node.sympy_is_channels_last_strides_2d(sizes, strides)
torch.fx.experimental.sym_node.sympy_is_channels_last_strides_3d(sizes, strides)
torch.fx.experimental.sym_node.sympy_is_channels_last_strides_generic(sizes, strides, dim_order)
torch.fx.experimental.sym_node.sympy_is_contiguous(sizes, strides)
torch.fx.experimental.sym_node.sympy_is_contiguous_generic(sizes, strides, dim_order)
torch.fx.experimental.sym_node.to_node(self, num)
torch.fx.experimental.sym_node.update_wrapper(wrapper, wrapped, assigned=('__module__', '__name__', '__qualname__', '__doc__', '__annotations__'), updated=('__dict__',))
torch.fx.experimental.sym_node.wrap_node(x)
torch.fx.graph.Any(*args, **kwds)
torch.fx.graph.Argument(*args, **kwargs)
torch.fx.graph.Callable(*args, **kwargs)
torch.fx.graph.CodeGen()
torch.fx.graph.Dict(*args, **kwargs)
torch.fx.graph.FrozenSet(*args, **kwargs)
torch.fx.graph.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.graph.Iterable(*args, **kwargs)
torch.fx.graph.List(*args, **kwargs)
torch.fx.graph.NamedTuple(typename, fields=None, /, **kwargs)
torch.fx.graph.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.graph.Optional(*args, **kwds)
torch.fx.graph.PythonCode(src: str, globals: Dict[str, Any], _lineno_map: Optional[Dict[int, Optional[int]]]) -> None
torch.fx.graph.Set(*args, **kwargs)
torch.fx.graph.Target(*args, **kwargs)
torch.fx.graph.TransformCodeFunc(*args, **kwargs)
torch.fx.graph.Tuple(*args, **kwargs)
torch.fx.graph.Type(*args, **kwargs)
torch.fx.graph.compatibility(is_backward_compatible: bool)
torch.fx.graph.contextmanager(func)
torch.fx.graph.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.graph.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.graph_module.Any(*args, **kwds)
torch.fx.graph_module.Callable(*args, **kwargs)
torch.fx.graph_module.Dict(*args, **kwargs)
torch.fx.graph_module.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.graph_module.GraphModule(*args, **kwargs)
torch.fx.graph_module.Importer()
torch.fx.graph_module.List(*args, **kwargs)
torch.fx.graph_module.Optional(*args, **kwds)
torch.fx.graph_module.PackageExporter(f: Union[str, pathlib.Path, BinaryIO], importer: Union[torch.package.importer.Importer, Sequence[torch.package.importer.Importer]] = <torch.package.importer._SysImporter object at 0x0000024A613327D0>, debug: bool = False)
torch.fx.graph_module.PackageImporter(file_or_buffer: Union[str, torch.PyTorchFileReader, os.PathLike, BinaryIO], module_allowed: Callable[[str], bool] = <function PackageImporter.<lambda> at 0x0000024A61368670>)
torch.fx.graph_module.Path(*args, **kwargs)
torch.fx.graph_module.PythonCode(src: str, globals: Dict[str, Any], _lineno_map: Optional[Dict[int, Optional[int]]]) -> None
torch.fx.graph_module.Set(*args, **kwargs)
torch.fx.graph_module.Type(*args, **kwargs)
torch.fx.graph_module.Union(*args, **kwds)
torch.fx.graph_module.compatibility(is_backward_compatible: bool)
torch.fx.graph_module.reduce_deploy_graph_module(importer: torch.package.package_importer.PackageImporter, body: Dict[Any, Any], import_block: str) -> torch.nn.modules.module.Module
torch.fx.graph_module.reduce_graph_module(body: Dict[Any, Any], import_block: str) -> torch.nn.modules.module.Module
torch.fx.graph_module.reduce_package_graph_module(importer: torch.package.package_importer.PackageImporter, body: Dict[Any, Any], generated_module_name: str) -> torch.nn.modules.module.Module
torch.fx.has_side_effect(fn: Callable) -> Callable
torch.fx.immutable_collections.Any(*args, **kwds)
torch.fx.immutable_collections.Context(*args, **kwds)
torch.fx.immutable_collections.Dict(*args, **kwargs)
torch.fx.immutable_collections.Iterable(*args, **kwargs)
torch.fx.immutable_collections.List(*args, **kwargs)
torch.fx.immutable_collections.Tuple(*args, **kwargs)
torch.fx.immutable_collections.compatibility(is_backward_compatible: bool)
torch.fx.immutable_collections.immutable_list(iterable=(), /)
torch.fx.immutable_collections.register_pytree_node(cls: Type[Any], flatten_fn: Callable[[Any], Tuple[List[Any], Any]], unflatten_fn: Callable[[Iterable[Any], Any], Any], *, serialized_type_name: Optional[str] = None, to_dumpable_context: Optional[Callable[[Any], Any]] = None, from_dumpable_context: Optional[Callable[[Any], Any]] = None, flatten_with_keys_fn: Optional[Callable[[Any], Tuple[List[Tuple[torch.utils._pytree.KeyEntry, Any]], Any]]] = None) -> None
torch.fx.interpreter.Any(*args, **kwds)
torch.fx.interpreter.Argument(*args, **kwargs)
torch.fx.interpreter.Dict(*args, **kwargs)
torch.fx.interpreter.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.interpreter.GraphModule(*args, **kwargs)
torch.fx.interpreter.Interpreter(module: torch.nn.modules.module.Module, garbage_collect_values: bool = True, graph: Optional[torch.fx.graph.Graph] = None)
torch.fx.interpreter.Iterator(*args, **kwargs)
torch.fx.interpreter.List(*args, **kwargs)
torch.fx.interpreter.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.interpreter.Optional(*args, **kwds)
torch.fx.interpreter.Proxy(node: torch.fx.node.Node, tracer: 'Optional[TracerBase]' = None)
torch.fx.interpreter.Target(*args, **kwargs)
torch.fx.interpreter.Tracer(autowrap_modules: Tuple[module] = (<module 'math' (built-in)>,), autowrap_functions: Tuple[Callable, ...] = (), param_shapes_constant: bool = False) -> None
torch.fx.interpreter.Transformer(module)
torch.fx.interpreter.Tuple(*args, **kwargs)
torch.fx.interpreter.Union(*args, **kwds)
torch.fx.interpreter.compatibility(is_backward_compatible: bool)
torch.fx.interpreter.contextmanager(func)
torch.fx.interpreter.map_aggregate(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.interpreter.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.node.Any(*args, **kwds)
torch.fx.node.ArgsKwargsPair(args: Tuple[Any, ...], kwargs: Dict[str, Any])
torch.fx.node.Argument(*args, **kwargs)
torch.fx.node.BaseArgumentTypes(*args, **kwargs)
torch.fx.node.Callable(*args, **kwargs)
torch.fx.node.Dict(*args, **kwargs)
torch.fx.node.List(*args, **kwargs)
torch.fx.node.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.node.Optional(*args, **kwds)
torch.fx.node.Set(*args, **kwargs)
torch.fx.node.Target(*args, **kwargs)
torch.fx.node.Tuple(*args, **kwargs)
torch.fx.node.Union(*args, **kwds)
torch.fx.node.compatibility(is_backward_compatible: bool)
torch.fx.node.has_side_effect(fn: Callable) -> Callable
torch.fx.node.immutable_list(iterable=(), /)
torch.fx.node.map_aggregate(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.node.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.node.normalize_function(target: Callable, args: Tuple[Any], kwargs: Optional[Dict[str, Any]] = None, arg_types: Optional[Tuple[Any]] = None, kwarg_types: Optional[Dict[str, Any]] = None, normalize_to_only_use_kwargs: bool = False) -> Optional[torch.fx.operator_schemas.ArgsKwargsPair]
torch.fx.node.normalize_module(root: torch.nn.modules.module.Module, target: str, args: Tuple[Any], kwargs: Optional[Dict[str, Any]] = None, normalize_to_only_use_kwargs: bool = False) -> Optional[torch.fx.operator_schemas.ArgsKwargsPair]
torch.fx.operator_schemas.Any(*args, **kwds)
torch.fx.operator_schemas.ArgsKwargsPair(args: Tuple[Any, ...], kwargs: Dict[str, Any])
torch.fx.operator_schemas.Callable(*args, **kwargs)
torch.fx.operator_schemas.Dict(*args, **kwargs)
torch.fx.operator_schemas.List(*args, **kwargs)
torch.fx.operator_schemas.NamedTuple(typename, fields=None, /, **kwargs)
torch.fx.operator_schemas.OpOverload(overloadpacket, op, op_dk, schema, tags)
torch.fx.operator_schemas.OpOverloadPacket(qualified_op_name, op_name, op, overload_names)
torch.fx.operator_schemas.Optional(*args, **kwds)
torch.fx.operator_schemas.Tuple(*args, **kwargs)
torch.fx.operator_schemas.cast(typ, val)
torch.fx.operator_schemas.check_for_mutable_operation(target: Callable, args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')])
torch.fx.operator_schemas.compatibility(is_backward_compatible: bool)
torch.fx.operator_schemas.create_type_hint(x)
torch.fx.operator_schemas.get_signature_for_torch_op(op: Callable, return_schemas: bool = False)
torch.fx.operator_schemas.normalize_function(target: Callable, args: Tuple[Any], kwargs: Optional[Dict[str, Any]] = None, arg_types: Optional[Tuple[Any]] = None, kwarg_types: Optional[Dict[str, Any]] = None, normalize_to_only_use_kwargs: bool = False) -> Optional[torch.fx.operator_schemas.ArgsKwargsPair]
torch.fx.operator_schemas.normalize_module(root: torch.nn.modules.module.Module, target: str, args: Tuple[Any], kwargs: Optional[Dict[str, Any]] = None, normalize_to_only_use_kwargs: bool = False) -> Optional[torch.fx.operator_schemas.ArgsKwargsPair]
torch.fx.operator_schemas.type_matches(signature_type: Any, argument_type: Any)
torch.fx.passes.graph_drawer.Any(*args, **kwds)
torch.fx.passes.graph_drawer.Dict(*args, **kwargs)
torch.fx.passes.graph_drawer.FxGraphDrawer(graph_module: torch.fx.graph_module.GraphModule, name: str, ignore_getattr: bool = False, ignore_parameters_and_buffers: bool = False, skip_node_names_in_args: bool = True, parse_stack_trace: bool = False, dot_graph_shape: Optional[str] = None)
torch.fx.passes.graph_drawer.Optional(*args, **kwds)
torch.fx.passes.graph_drawer.TensorMetadata(shape: torch.Size, dtype: torch.dtype, requires_grad: bool, stride: Tuple[int, ...], memory_format: Optional[torch.memory_format], is_quantized: bool, qparams: Dict[str, Any])
torch.fx.passes.graph_drawer.compatibility(is_backward_compatible: bool)
torch.fx.passes.graph_manipulation.Any(*args, **kwds)
torch.fx.passes.graph_manipulation.Dict(*args, **kwargs)
torch.fx.passes.graph_manipulation.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.passes.graph_manipulation.GraphModule(*args, **kwargs)
torch.fx.passes.graph_manipulation.List(*args, **kwargs)
torch.fx.passes.graph_manipulation.NamedTuple(typename, fields=None, /, **kwargs)
torch.fx.passes.graph_manipulation.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.passes.graph_manipulation.Optional(*args, **kwds)
torch.fx.passes.graph_manipulation.ShapeProp(gm, fake_mode=None)
torch.fx.passes.graph_manipulation.Target(*args, **kwargs)
torch.fx.passes.graph_manipulation.compatibility(is_backward_compatible: bool)
torch.fx.passes.graph_manipulation.get_size_of_all_nodes(fx_module: torch.fx.graph_module.GraphModule, args: Optional[List[torch.Tensor]] = None) -> None
torch.fx.passes.graph_manipulation.get_size_of_node(fx_module: torch.fx.graph_module.GraphModule, node: torch.fx.node.Node) -> torch.fx.passes.graph_manipulation.size_bytes
torch.fx.passes.graph_manipulation.get_tensor_meta(node: torch.fx.node.Node) -> Any
torch.fx.passes.graph_manipulation.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.passes.graph_manipulation.replace_target_nodes_with(fx_module: torch.fx.graph_module.GraphModule, old_op: str, old_target: Union[Callable[..., Any], str], new_op: str, new_target: Union[Callable[..., Any], str])
torch.fx.passes.graph_manipulation.size_bytes(output_size: int, total_size: int)
torch.fx.passes.infra.pass_base.GraphModule(*args, **kwargs)
torch.fx.passes.infra.pass_base.Optional(*args, **kwds)
torch.fx.passes.infra.pass_base.PassBase()
torch.fx.passes.infra.pass_base.PassResult(graph_module, modified)
torch.fx.passes.infra.pass_base.compatibility(is_backward_compatible: bool)
torch.fx.passes.infra.pass_base.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.fx.passes.infra.pass_manager.Callable(*args, **kwargs)
torch.fx.passes.infra.pass_manager.Dict(*args, **kwargs)
torch.fx.passes.infra.pass_manager.GraphModule(*args, **kwargs)
torch.fx.passes.infra.pass_manager.List(*args, **kwargs)
torch.fx.passes.infra.pass_manager.PassManager(passes=None, constraints=None, steps=None, run_checks_after_each_pass: bool = False, suppress_check_failures: bool = False)
torch.fx.passes.infra.pass_manager.PassResult(graph_module, modified)
torch.fx.passes.infra.pass_manager.Queue(maxsize=0)
torch.fx.passes.infra.pass_manager.compatibility(is_backward_compatible: bool)
torch.fx.passes.infra.pass_manager.pass_result_wrapper(fn: Callable) -> Callable
torch.fx.passes.infra.pass_manager.this_before_that_pass_constraint(this: Callable, that: Callable) -> Callable
torch.fx.passes.infra.pass_manager.wraps(wrapped, assigned=('__module__', '__name__', '__qualname__', '__doc__', '__annotations__'), updated=('__dict__',))
torch.fx.passes.net_min_base.Any(*args, **kwds)
torch.fx.passes.net_min_base.Callable(*args, **kwargs)
torch.fx.passes.net_min_base.Dict(*args, **kwargs)
torch.fx.passes.net_min_base.FxNetAccFusionsFinder(module: torch.fx.graph_module.GraphModule, acc_nodes: Set[torch.fx.node.Node])
torch.fx.passes.net_min_base.List(*args, **kwargs)
torch.fx.passes.net_min_base.Names(*args, **kwargs)
torch.fx.passes.net_min_base.NodeList(*args, **kwargs)
torch.fx.passes.net_min_base.NodeSet(*args, **kwargs)
torch.fx.passes.net_min_base.Optional(*args, **kwds)
torch.fx.passes.net_min_base.ShapeProp(gm, fake_mode=None)
torch.fx.passes.net_min_base.TensorOrTensors(*args, **kwargs)
torch.fx.passes.net_min_base.Tensors(*args, **kwargs)
torch.fx.passes.net_min_base.Tuple(*args, **kwargs)
torch.fx.passes.net_min_base.compatibility(is_backward_compatible: bool)
torch.fx.passes.net_min_base.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.passes.net_min_base.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.passes.net_min_base.split_by_tags(gm: torch.fx.graph_module.GraphModule, tags: List[str], return_fqn_mapping: bool = False, return_tuple: bool = False, GraphModuleCls: Type[torch.fx.graph_module.GraphModule] = <class 'torch.fx.graph_module.GraphModule'>) -> Union[torch.fx.graph_module.GraphModule, Tuple[torch.fx.graph_module.GraphModule, Dict[str, str]]]
torch.fx.passes.operator_support.IsNodeSupported(*args, **kwargs)
torch.fx.passes.operator_support.OpSupports()
torch.fx.passes.operator_support.OperatorSupport(support_dict: Optional[Mapping[str, Optional[Tuple[Sequence[Sequence[torch.dtype]], Dict[str, Sequence[torch.dtype]]]]]] = None)
torch.fx.passes.operator_support.OperatorSupportBase()
torch.fx.passes.operator_support.SupportDict(*args, **kwargs)
torch.fx.passes.operator_support.SupportedArgumentDTypes(*args, **kwargs)
torch.fx.passes.operator_support.TensorMetadata(shape: torch.Size, dtype: torch.dtype, requires_grad: bool, stride: Tuple[int, ...], memory_format: Optional[torch.memory_format], is_quantized: bool, qparams: Dict[str, Any])
torch.fx.passes.operator_support.any_chain(*op_support: torch.fx.passes.operator_support.OperatorSupportBase) -> torch.fx.passes.operator_support.OperatorSupportBase
torch.fx.passes.operator_support.chain(*op_support: torch.fx.passes.operator_support.OperatorSupportBase) -> torch.fx.passes.operator_support.OperatorSupportBase
torch.fx.passes.operator_support.compatibility(is_backward_compatible: bool)
torch.fx.passes.operator_support.create_op_support(is_node_supported: Callable[[Mapping[str, torch.nn.modules.module.Module], torch.fx.node.Node], bool]) -> torch.fx.passes.operator_support.OperatorSupportBase
torch.fx.passes.operator_support.get_node_target(submodules: Mapping[str, torch.nn.modules.module.Module], node: torch.fx.node.Node) -> str
torch.fx.passes.param_fetch.Any(*args, **kwds)
torch.fx.passes.param_fetch.Callable(*args, **kwargs)
torch.fx.passes.param_fetch.Dict(*args, **kwargs)
torch.fx.passes.param_fetch.GraphModule(*args, **kwargs)
torch.fx.passes.param_fetch.List(*args, **kwargs)
torch.fx.passes.param_fetch.Tuple(*args, **kwargs)
torch.fx.passes.param_fetch.Type(*args, **kwargs)
torch.fx.passes.param_fetch.compatibility(is_backward_compatible: bool)
torch.fx.passes.param_fetch.default_matching(name: str, target_version: int) -> str
torch.fx.passes.param_fetch.extract_attrs_for_lowering(mod: torch.nn.modules.module.Module) -> Dict[str, Any]
torch.fx.passes.param_fetch.lift_lowering_attrs_to_nodes(fx_module: torch.fx.graph_module.GraphModule) -> None
torch.fx.passes.reinplace.Dict(*args, **kwargs)
torch.fx.passes.reinplace.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.fx.passes.reinplace.FakeTensor(fake_mode, elem, device, constant=None, real_tensor=None)
torch.fx.passes.reinplace.FakeTensorMode(*, allow_fallback_kernels=True, allow_non_fake_inputs=False, shape_env=None, static_shapes=None, export=False)
torch.fx.passes.reinplace.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.passes.reinplace.Set(*args, **kwargs)
torch.fx.passes.reinplace.StorageWeakRef(storage)
torch.fx.passes.reinplace.compatibility(is_backward_compatible: bool)
torch.fx.passes.reinplace.reinplace(gm, *sample_args)
torch.fx.passes.reinplace.tree_map_only(__type_or_types_or_pred: Union[Type[Any], Tuple[Type[Any], ...], types.UnionType, Callable[[Any], bool]], func: Callable[[Any], Any], tree: Any, is_leaf: Optional[Callable[[Any], bool]] = None) -> Any
torch.fx.passes.runtime_assert.Any(*args, **kwds)
torch.fx.passes.runtime_assert.Dict(*args, **kwargs)
torch.fx.passes.runtime_assert.GraphModule(*args, **kwargs)
torch.fx.passes.runtime_assert.Optional(*args, **kwds)
torch.fx.passes.runtime_assert.Set(*args, **kwargs)
torch.fx.passes.runtime_assert.ShapeEnv(*args, **kwds)
torch.fx.passes.runtime_assert.SymNode(expr, shape_env, pytype, hint: Union[int, float, bool, NoneType], constant=None, fx_node=None)
torch.fx.passes.runtime_assert.compatibility(is_backward_compatible: bool)
torch.fx.passes.runtime_assert.insert_deferred_runtime_asserts(gm: torch.fx.graph_module.GraphModule, shape_env: Any, name: str, export: bool = False) -> None
torch.fx.passes.runtime_assert.lazy_format_graph_code(name, gm, maybe_id=None, **kwargs)
torch.fx.passes.shape_prop.Any(*args, **kwds)
torch.fx.passes.shape_prop.Dict(*args, **kwargs)
torch.fx.passes.shape_prop.NamedTuple(typename, fields=None, /, **kwargs)
torch.fx.passes.shape_prop.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.passes.shape_prop.Optional(*args, **kwds)
torch.fx.passes.shape_prop.ShapeProp(gm, fake_mode=None)
torch.fx.passes.shape_prop.TensorMetadata(shape: torch.Size, dtype: torch.dtype, requires_grad: bool, stride: Tuple[int, ...], memory_format: Optional[torch.memory_format], is_quantized: bool, qparams: Dict[str, Any])
torch.fx.passes.shape_prop.Tuple(*args, **kwargs)
torch.fx.passes.shape_prop.compatibility(is_backward_compatible: bool)
torch.fx.passes.shape_prop.detect_fake_mode(inputs: 'Any' = None)
torch.fx.passes.shape_prop.map_aggregate(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.passes.split_module.Any(*args, **kwds)
torch.fx.passes.split_module.Callable(*args, **kwargs)
torch.fx.passes.split_module.Dict(*args, **kwargs)
torch.fx.passes.split_module.GraphModule(*args, **kwargs)
torch.fx.passes.split_module.List(*args, **kwargs)
torch.fx.passes.split_module.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.passes.split_module.Optional(*args, **kwds)
torch.fx.passes.split_module.Partition(name: str)
torch.fx.passes.split_module.Set(*args, **kwargs)
torch.fx.passes.split_module.compatibility(is_backward_compatible: bool)
torch.fx.passes.split_module.split_module(m: torch.fx.graph_module.GraphModule, root_m: torch.nn.modules.module.Module, split_callback: Callable[[torch.fx.node.Node], int], qualname_map: Optional[Dict[str, str]] = None, keep_original_order: Optional[bool] = False, keep_original_node_name: Optional[bool] = False)
torch.fx.passes.split_utils.Component(graph: torch.fx.graph.Graph, order: int, name: str, input_placeholders: List = <factory>, orig_inputs: List = <factory>, orig_outputs: List = <factory>, getattr_maps: Dict[torch.fx.node.Node, torch.fx.node.Node] = <factory>, constructor_args: List[str] = <factory>, gm: Optional[torch.fx.graph_module.GraphModule] = None) -> None
torch.fx.passes.split_utils.Dict(*args, **kwargs)
torch.fx.passes.split_utils.HolderModule(d)
torch.fx.passes.split_utils.List(*args, **kwargs)
torch.fx.passes.split_utils.NodeList(*args, **kwargs)
torch.fx.passes.split_utils.Optional(*args, **kwds)
torch.fx.passes.split_utils.Tuple(*args, **kwargs)
torch.fx.passes.split_utils.Type(*args, **kwargs)
torch.fx.passes.split_utils.Union(*args, **kwds)
torch.fx.passes.split_utils.compatibility(is_backward_compatible: bool)
torch.fx.passes.split_utils.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.passes.split_utils.field(*, default=<dataclasses._MISSING_TYPE object at 0x0000024A38880250>, default_factory=<dataclasses._MISSING_TYPE object at 0x0000024A38880250>, init=True, repr=True, hash=None, compare=True, metadata=None, kw_only=<dataclasses._MISSING_TYPE object at 0x0000024A38880250>)
torch.fx.passes.split_utils.getattr_recursive(obj, name)
torch.fx.passes.split_utils.lift_subgraph_as_module(gm: torch.fx.graph_module.GraphModule, subgraph: torch.fx.graph.Graph, comp_name: str = '', class_name: str = 'GraphModule') -> Tuple[torch.fx.graph_module.GraphModule, Dict[str, str]]
torch.fx.passes.split_utils.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.passes.split_utils.setattr_recursive(obj, attr, value)
torch.fx.passes.split_utils.split_by_tags(gm: torch.fx.graph_module.GraphModule, tags: List[str], return_fqn_mapping: bool = False, return_tuple: bool = False, GraphModuleCls: Type[torch.fx.graph_module.GraphModule] = <class 'torch.fx.graph_module.GraphModule'>) -> Union[torch.fx.graph_module.GraphModule, Tuple[torch.fx.graph_module.GraphModule, Dict[str, str]]]
torch.fx.passes.splitter_base.Any(*args, **kwds)
torch.fx.passes.splitter_base.Dict(*args, **kwargs)
torch.fx.passes.splitter_base.FxGraphDrawer(graph_module: torch.fx.graph_module.GraphModule, name: str, ignore_getattr: bool = False, ignore_parameters_and_buffers: bool = False, skip_node_names_in_args: bool = True, parse_stack_trace: bool = False, dot_graph_shape: Optional[str] = None)
torch.fx.passes.splitter_base.FxNetAccFusionsFinder(module: torch.fx.graph_module.GraphModule, acc_nodes: Set[torch.fx.node.Node])
torch.fx.passes.splitter_base.FxNetAccNodesFinder(module: torch.fx.graph_module.GraphModule, operator_support: torch.fx.passes.operator_support.OperatorSupportBase, allow_non_tensor: bool)
torch.fx.passes.splitter_base.Iterable(*args, **kwargs)
torch.fx.passes.splitter_base.List(*args, **kwargs)
torch.fx.passes.splitter_base.NamedTuple(typename, fields=None, /, **kwargs)
torch.fx.passes.splitter_base.NodeList(*args, **kwargs)
torch.fx.passes.splitter_base.NodeSet(*args, **kwargs)
torch.fx.passes.splitter_base.OperatorSupportBase()
torch.fx.passes.splitter_base.Optional(*args, **kwds)
torch.fx.passes.splitter_base.Sequence(*args, **kwargs)
torch.fx.passes.splitter_base.ShapeProp(gm, fake_mode=None)
torch.fx.passes.splitter_base.SplitResult(split_module: torch.fx.graph_module.GraphModule, submodule_inputs: Dict[str, Any], non_acc_submodule_prefix: str)
torch.fx.passes.splitter_base.Subgraph(is_acc: bool, nodes: List[torch.fx.node.Node], device_ordinal: Optional[int] = None) -> None
torch.fx.passes.splitter_base.Tensors(*args, **kwargs)
torch.fx.passes.splitter_base.Tuple(*args, **kwargs)
torch.fx.passes.splitter_base.compatibility(is_backward_compatible: bool)
torch.fx.passes.splitter_base.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.passes.splitter_base.generate_inputs_for_submodules(model: torch.nn.modules.module.Module, inputs: Sequence[Any], target_submodules: Iterable[str], deepcopy: bool = False) -> Dict[str, Any]
torch.fx.passes.splitter_base.get_node_target(submodules: Mapping[str, torch.nn.modules.module.Module], node: torch.fx.node.Node) -> str
torch.fx.passes.splitter_base.get_size_of_node(fx_module: torch.fx.graph_module.GraphModule, node: torch.fx.node.Node) -> torch.fx.passes.graph_manipulation.size_bytes
torch.fx.passes.splitter_base.is_node_output_tensor(node: torch.fx.node.Node) -> bool
torch.fx.passes.splitter_base.map_arg(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[torch.fx.node.Node], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.passes.splitter_base.split_by_tags(gm: torch.fx.graph_module.GraphModule, tags: List[str], return_fqn_mapping: bool = False, return_tuple: bool = False, GraphModuleCls: Type[torch.fx.graph_module.GraphModule] = <class 'torch.fx.graph_module.GraphModule'>) -> Union[torch.fx.graph_module.GraphModule, Tuple[torch.fx.graph_module.GraphModule, Dict[str, str]]]
torch.fx.passes.tools_common.Any(*args, **kwds)
torch.fx.passes.tools_common.Dict(*args, **kwargs)
torch.fx.passes.tools_common.FxNetAccFusionsFinder(module: torch.fx.graph_module.GraphModule, acc_nodes: Set[torch.fx.node.Node])
torch.fx.passes.tools_common.List(*args, **kwargs)
torch.fx.passes.tools_common.Mapping(*args, **kwargs)
torch.fx.passes.tools_common.Names(*args, **kwargs)
torch.fx.passes.tools_common.NodeList(*args, **kwargs)
torch.fx.passes.tools_common.NodeSet(*args, **kwargs)
torch.fx.passes.tools_common.Optional(*args, **kwds)
torch.fx.passes.tools_common.Set(*args, **kwargs)
torch.fx.passes.tools_common.TensorOrTensors(*args, **kwargs)
torch.fx.passes.tools_common.Tensors(*args, **kwargs)
torch.fx.passes.tools_common.Tuple(*args, **kwargs)
torch.fx.passes.tools_common.Union(*args, **kwds)
torch.fx.passes.tools_common.compatibility(is_backward_compatible: bool)
torch.fx.passes.tools_common.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.passes.tools_common.get_acc_ops_name(k)
torch.fx.passes.tools_common.get_node_target(submodules: Mapping[str, torch.nn.modules.module.Module], node: torch.fx.node.Node) -> str
torch.fx.passes.tools_common.is_node_output_tensor(node: torch.fx.node.Node) -> bool
torch.fx.passes.tools_common.legalize_graph(gm: torch.fx.graph_module.GraphModule) -> torch.fx.graph_module.GraphModule
torch.fx.passes.utils.HolderModule(d)
torch.fx.passes.utils.common.Dict(*args, **kwargs)
torch.fx.passes.utils.common.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.passes.utils.common.GraphModule(*args, **kwargs)
torch.fx.passes.utils.common.HolderModule(d)
torch.fx.passes.utils.common.Module(*args, **kwargs) -> None
torch.fx.passes.utils.common.SubgraphMatcher(pattern: torch.fx.graph.Graph, match_output: bool = False, match_placeholder: bool = False, remove_overlapping_matches: bool = True, ignore_literals: bool = False) -> None
torch.fx.passes.utils.common.Tuple(*args, **kwargs)
torch.fx.passes.utils.common.compare_graphs(left: torch.fx.graph.Graph, right: torch.fx.graph.Graph) -> bool
torch.fx.passes.utils.common.compatibility(is_backward_compatible: bool)
torch.fx.passes.utils.common.lift_subgraph_as_module(gm: torch.fx.graph_module.GraphModule, subgraph: torch.fx.graph.Graph, comp_name: str = '', class_name: str = 'GraphModule') -> Tuple[torch.fx.graph_module.GraphModule, Dict[str, str]]
torch.fx.passes.utils.compare_graphs(left: torch.fx.graph.Graph, right: torch.fx.graph.Graph) -> bool
torch.fx.passes.utils.lift_subgraph_as_module(gm: torch.fx.graph_module.GraphModule, subgraph: torch.fx.graph.Graph, comp_name: str = '', class_name: str = 'GraphModule') -> Tuple[torch.fx.graph_module.GraphModule, Dict[str, str]]
torch.fx.passes.utils.matcher_utils.Any(*args, **kwds)
torch.fx.passes.utils.matcher_utils.Dict(*args, **kwargs)
torch.fx.passes.utils.matcher_utils.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.passes.utils.matcher_utils.InternalMatch(anchors: List[torch.fx.node.Node], nodes_map: Dict[torch.fx.node.Node, torch.fx.node.Node] = <factory>, placeholder_nodes: List[torch.fx.node.Node] = <factory>, returning_nodes: List[torch.fx.node.Node] = <factory>, name_node_map: Dict[str, torch.fx.node.Node] = <factory>) -> None
torch.fx.passes.utils.matcher_utils.List(*args, **kwargs)
torch.fx.passes.utils.matcher_utils.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.passes.utils.matcher_utils.Set(*args, **kwargs)
torch.fx.passes.utils.matcher_utils.SubgraphMatcher(pattern: torch.fx.graph.Graph, match_output: bool = False, match_placeholder: bool = False, remove_overlapping_matches: bool = True, ignore_literals: bool = False) -> None
torch.fx.passes.utils.matcher_utils.Tuple(*args, **kwargs)
torch.fx.passes.utils.matcher_utils.Union(*args, **kwds)
torch.fx.passes.utils.matcher_utils.compatibility(is_backward_compatible: bool)
torch.fx.passes.utils.matcher_utils.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.passes.utils.matcher_utils.field(*, default=<dataclasses._MISSING_TYPE object at 0x0000024A38880250>, default_factory=<dataclasses._MISSING_TYPE object at 0x0000024A38880250>, init=True, repr=True, hash=None, compare=True, metadata=None, kw_only=<dataclasses._MISSING_TYPE object at 0x0000024A38880250>)
torch.fx.proxy.Any(*args, **kwds)
torch.fx.proxy.Argument(*args, **kwargs)
torch.fx.proxy.Attribute(root: torch.fx.proxy.Proxy, attr: str)
torch.fx.proxy.Callable(*args, **kwargs)
torch.fx.proxy.CapturedTraceback(tb, skip=0)
torch.fx.proxy.Dict(*args, **kwargs)
torch.fx.proxy.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.proxy.GraphAppendingTracer(graph: torch.fx.graph.Graph)
torch.fx.proxy.Iterator(*args, **kwargs)
torch.fx.proxy.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.proxy.Optional(*args, **kwds)
torch.fx.proxy.OrderedDict(*args, **kwargs)
torch.fx.proxy.ParameterProxy(tracer: torch.fx.proxy.TracerBase, node: torch.fx.node.Node, name, param)
torch.fx.proxy.Proxy(node: torch.fx.node.Node, tracer: 'Optional[TracerBase]' = None)
torch.fx.proxy.Scope(module_path: str, module_type: Any)
torch.fx.proxy.ScopeContextManager(scope: torch.fx.proxy.Scope, current_scope: torch.fx.proxy.Scope)
torch.fx.proxy.Target(*args, **kwargs)
torch.fx.proxy.TracerBase()
torch.fx.proxy.Tuple(*args, **kwargs)
torch.fx.proxy.assert_fn(x)
torch.fx.proxy.check_for_mutable_operation(target: Callable, args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')])
torch.fx.proxy.compatibility(is_backward_compatible: bool)
torch.fx.proxy.fields(class_or_instance)
torch.fx.proxy.is_dataclass(obj)
torch.fx.proxy.map_aggregate(a: Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType], fn: Callable[[Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]], Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]]) -> Union[Tuple[Any, ...], List[Any], Dict[str, Any], slice, range, ForwardRef('Node'), str, int, float, bool, complex, torch.dtype, torch.Tensor, torch.device, torch.memory_format, torch.layout, torch._ops.OpOverload, NoneType]
torch.fx.replace_pattern(gm: torch.fx.graph_module.GraphModule, pattern: Union[Callable, torch.fx.graph_module.GraphModule], replacement: Union[Callable, torch.fx.graph_module.GraphModule]) -> List[torch.fx.subgraph_rewriter.Match]
torch.fx.subgraph_rewriter.Any(*args, **kwds)
torch.fx.subgraph_rewriter.Callable(*args, **kwargs)
torch.fx.subgraph_rewriter.Dict(*args, **kwargs)
torch.fx.subgraph_rewriter.Graph(owning_module: Optional[ForwardRef('GraphModule')] = None, tracer_cls: Optional[Type[ForwardRef('Tracer')]] = None, tracer_extras: Optional[Dict[str, Any]] = None)
torch.fx.subgraph_rewriter.GraphModule(*args, **kwargs)
torch.fx.subgraph_rewriter.List(*args, **kwargs)
torch.fx.subgraph_rewriter.Match(anchor: torch.fx.node.Node, nodes_map: Dict[torch.fx.node.Node, torch.fx.node.Node])
torch.fx.subgraph_rewriter.NamedTuple(typename, fields=None, /, **kwargs)
torch.fx.subgraph_rewriter.Node(graph: 'Graph', name: str, op: str, target: 'Target', args: Tuple[ForwardRef('Argument'), ...], kwargs: Dict[str, ForwardRef('Argument')], return_type: Optional[Any] = None) -> None
torch.fx.subgraph_rewriter.Optional(*args, **kwds)
torch.fx.subgraph_rewriter.ReplacedPatterns(anchor: torch.fx.node.Node, nodes_map: Dict[torch.fx.node.Node, torch.fx.node.Node], replacements: List[torch.fx.node.Node]) -> None
torch.fx.subgraph_rewriter.Set(*args, **kwargs)
torch.fx.subgraph_rewriter.Union(*args, **kwds)
torch.fx.subgraph_rewriter.compatibility(is_backward_compatible: bool)
torch.fx.subgraph_rewriter.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.fx.subgraph_rewriter.replace_pattern(gm: torch.fx.graph_module.GraphModule, pattern: Union[Callable, torch.fx.graph_module.GraphModule], replacement: Union[Callable, torch.fx.graph_module.GraphModule]) -> List[torch.fx.subgraph_rewriter.Match]
torch.fx.subgraph_rewriter.replace_pattern_with_filters(gm: torch.fx.graph_module.GraphModule, pattern: Union[Callable, torch.fx.graph.Graph, torch.fx.graph_module.GraphModule], replacement: Union[Callable, torch.fx.graph.Graph, torch.fx.graph_module.GraphModule], match_filters: Optional[List[Callable[[ForwardRef('InternalMatch'), torch.fx.graph.Graph, torch.fx.graph.Graph], bool]]] = None, ignore_literals: bool = False) -> List[torch.fx.subgraph_rewriter.ReplacedPatterns]
torch.fx.subgraph_rewriter.symbolic_trace(root: Union[torch.nn.modules.module.Module, Callable[..., Any]], concrete_args: Optional[Dict[str, Any]] = None) -> torch.fx.graph_module.GraphModule
torch.fx.symbolic_trace(root: Union[torch.nn.modules.module.Module, Callable[..., Any]], concrete_args: Optional[Dict[str, Any]] = None) -> torch.fx.graph_module.GraphModule
torch.fx.wrap(fn_or_name: Union[str, Callable])
torch.get_default_device() -> 'torch.device'
torch.get_deterministic_debug_mode() -> int
torch.get_device_module(device: Union[torch.device, str, NoneType] = None)
torch.get_file_path(*path_components: str) -> str
torch.get_float32_matmul_precision() -> str
torch.get_rng_state() -> torch.Tensor
torch.hub.Any(*args, **kwds)
torch.hub.Dict(*args, **kwargs)
torch.hub.HTTPError(url, code, msg, hdrs, fp)
torch.hub.MAP_LOCATION(*args, **kwargs)
torch.hub.Optional(*args, **kwds)
torch.hub.Path(*args, **kwargs)
torch.hub.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)
torch.hub.URLError(reason, filename=None)
torch.hub.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.hub.download_url_to_file(url: str, dst: str, hash_prefix: Optional[str] = None, progress: bool = True) -> None
torch.hub.get_dir()
torch.hub.help(github, model, force_reload=False, skip_validation=False, trust_repo=None)
torch.hub.list(github, force_reload=False, skip_validation=False, trust_repo=None, verbose=True)
torch.hub.load(repo_or_dir, model, *args, source='github', trust_repo=None, force_reload=False, verbose=True, skip_validation=False, **kwargs)
torch.hub.load_state_dict_from_url(url: str, model_dir: Optional[str] = None, map_location: Union[Callable[[torch.types.Storage, str], torch.types.Storage], torch.device, str, Dict[str, str], NoneType] = None, progress: bool = True, check_hash: bool = False, file_name: Optional[str] = None, weights_only: bool = False) -> Dict[str, Any]
torch.hub.set_dir(d)
torch.hub.urlopen(url, data=None, timeout=<object object at 0x0000024A37E94F00>, *, cafile=None, capath=None, cadefault=False, context=None)
torch.hub.urlparse(url, scheme='', allow_fragments=True)
torch.inference_mode(mode=True)
torch.initial_seed() -> int
torch.is_deterministic_algorithms_warn_only_enabled() -> bool
torch.is_storage(obj)
torch.is_tensor(obj)
torch.is_warn_always_enabled() -> bool
torch.jit.Attribute(value, type)
torch.jit.Final(*args, **kwds)
torch.jit.Future(*, devices: 'Optional[List[Union[int, str, torch.device]]]' = None)
torch.jit.Iterator(*args, **kwargs)
torch.jit.ONNXTracedModule(inner, strict=True, force_outplace=False, return_inputs=False, return_inputs_states=False)
torch.jit.RecursiveScriptClass(cpp_class)
torch.jit.RecursiveScriptModule(cpp_module)
torch.jit.ScriptModule()
torch.jit.TopLevelTracedModule(orig, id_set=None, _compilation_unit=None)
torch.jit.TracedModule(orig, id_set=None, _compilation_unit=None)
torch.jit.TracingCheckError(graph_diff_error, tensor_compare_error, extra_msg=None)
torch.jit.annotate(the_type, the_value)
torch.jit.annotations.Any(*args, **kwds)
torch.jit.annotations.Dict(*args, **kwargs)
torch.jit.annotations.EvalEnv(rcb)
torch.jit.annotations.Future(*, devices: 'Optional[List[Union[int, str, torch.device]]]' = None)
torch.jit.annotations.List(*args, **kwargs)
torch.jit.annotations.Module(name, members)
torch.jit.annotations.OpOverloadPacket(qualified_op_name, op_name, op, overload_names)
torch.jit.annotations.Optional(*args, **kwds)
torch.jit.annotations.Tuple(*args, **kwargs)
torch.jit.annotations.Type(*args, **kwargs)
torch.jit.annotations.Union(*args, **kwds)
torch.jit.annotations.ann_to_type(ann, loc, rcb=None)
torch.jit.annotations.check_fn(fn, loc)
torch.jit.annotations.dedent(text)
torch.jit.annotations.get_enum_value_type(e: Type[enum.Enum], loc)
torch.jit.annotations.get_param_names(fn, n_args)
torch.jit.annotations.get_signature(fn, rcb, loc, is_method)
torch.jit.annotations.get_source_lines_and_file(obj: Any, error_msg: Optional[str] = None) -> Tuple[List[str], int, Optional[str]]
torch.jit.annotations.get_type_line(source)
torch.jit.annotations.is_await(ann) -> bool
torch.jit.annotations.is_dict(ann) -> bool
torch.jit.annotations.is_function_or_method(the_callable)
torch.jit.annotations.is_future(ann) -> bool
torch.jit.annotations.is_ignored_fn(fn) -> bool
torch.jit.annotations.is_list(ann) -> bool
torch.jit.annotations.is_optional(ann)
torch.jit.annotations.is_tensor(ann)
torch.jit.annotations.is_tuple(ann) -> bool
torch.jit.annotations.is_union(ann)
torch.jit.annotations.is_vararg(the_callable)
torch.jit.annotations.parse_type_line(type_line, rcb, loc)
torch.jit.annotations.split_type_line(type_line)
torch.jit.annotations.try_ann_to_type(ann, loc, rcb=None)
torch.jit.annotations.try_real_annotations(fn, loc)
torch.jit.contextmanager(func)
torch.jit.enable_onednn_fusion(enabled: bool)
torch.jit.export(fn)
torch.jit.export_opnames(m)
torch.jit.fork(func, *args, **kwargs)
torch.jit.freeze(mod, preserved_attrs: Optional[List[str]] = None, optimize_numerics: bool = True)
torch.jit.frontend.Builder()
torch.jit.frontend.ExprBuilder()
torch.jit.frontend.FrontendError(source_range, msg)
torch.jit.frontend.FrontendTypeError(source_range, msg)
torch.jit.frontend.FunctionModifiers()
torch.jit.frontend.List(*args, **kwargs)
torch.jit.frontend.NotSupportedError(source_range, msg)
torch.jit.frontend.StmtBuilder()
torch.jit.frontend.Tuple(*args, **kwargs)
torch.jit.frontend.UnsupportedNodeError(ctx, offending_node, reason='')
torch.jit.frontend.WithItemBuilder()
torch.jit.frontend.build_class_def(ctx, py_def, methods, properties, self_name, assigns)
torch.jit.frontend.build_def(ctx, py_def, type_line, def_name, self_name=None, pdt_arg_types=None)
torch.jit.frontend.build_expr(ctx, node)
torch.jit.frontend.build_ignore_context_manager(ctx, stmt)
torch.jit.frontend.build_param(ctx, py_arg, self_name, kwarg_only, pdt_arg_type=None)
torch.jit.frontend.build_param_list(ctx, py_args, self_name, pdt_arg_types=None)
torch.jit.frontend.build_stmt(ctx, node)
torch.jit.frontend.build_stmts(ctx, stmts)
torch.jit.frontend.build_withitem(ctx, node)
torch.jit.frontend.build_withitems(ctx, items)
torch.jit.frontend.dedent(text)
torch.jit.frontend.find_before(ctx, pos, substr, offsets=(0, 0))
torch.jit.frontend.get_class_assigns(ctx, cls_ast)
torch.jit.frontend.get_class_properties(cls, self_name)
torch.jit.frontend.get_default_args(fn)
torch.jit.frontend.get_default_args_for_class(cls)
torch.jit.frontend.get_jit_class_def(cls, self_name)
torch.jit.frontend.get_jit_def(fn, def_name, self_name=None, is_classmethod=False)
torch.jit.frontend.get_qualified_name(func)
torch.jit.frontend.get_source_lines_and_file(obj: Any, error_msg: Optional[str] = None) -> Tuple[List[str], int, Optional[str]]
torch.jit.frontend.is_reserved_name(name)
torch.jit.frontend.is_static_fn(cls, fn) -> bool
torch.jit.frontend.is_torch_jit_ignore_context_manager(stmt)
torch.jit.frontend.make_source_context(*args)
torch.jit.frontend.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.jit.frontend.parse_def(fn)
torch.jit.frontend.should_drop(fn) -> bool
torch.jit.fuser(name)
torch.jit.ignore(drop=False, **kwargs)
torch.jit.interface(obj)
torch.jit.is_scripting() -> bool
torch.jit.is_tracing()
torch.jit.isinstance(obj, target_type)
torch.jit.jit_module_from_flatbuffer(f)
torch.jit.load(f, map_location=None, _extra_files=None, _restore_shapes=False)
torch.jit.onednn_fusion_enabled()
torch.jit.optimize_for_inference(mod: torch.jit._script.ScriptModule, other_methods: Optional[List[str]] = None) -> torch.jit._script.ScriptModule
torch.jit.optimized_execution(should_optimize)
torch.jit.run_frozen_optimizations(mod, optimize_numerics: bool = True, preserved_methods: Optional[List[str]] = None)
torch.jit.save(m, f, _extra_files=None)
torch.jit.save_jit_module_to_flatbuffer(m, f, _extra_files=None)
torch.jit.script(obj, optimize=None, _frames_up=0, _rcb=None, example_inputs: Union[List[Tuple], Dict[Callable, List[Tuple]], NoneType] = None)
torch.jit.script_if_tracing(fn)
torch.jit.script_method(fn)
torch.jit.set_fusion_strategy(strategy: List[Tuple[str, int]])
torch.jit.set_module(obj, mod)
torch.jit.strict_fusion()
torch.jit.trace(func, example_inputs=None, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-05, strict=True, _force_outplace=False, _module_class=None, _compilation_unit=<torch.jit.CompilationUnit object at 0x0000024A612C0930>, example_kwarg_inputs=None, _store_inputs=True)
torch.jit.trace_module(mod, inputs, optimize=None, check_trace=True, check_inputs=None, check_tolerance=1e-05, strict=True, _force_outplace=False, _module_class=None, _compilation_unit=<torch.jit.CompilationUnit object at 0x0000024A612C0930>, example_inputs_is_kwarg=False, _store_inputs=True)
torch.jit.unused(fn)
torch.jit.wait(future)
torch.layout()
torch.library.Any(*args, **kwds)
torch.library.Callable(*args, **kwargs)
torch.library.CustomOpDef(namespace: str, name: str, schema: str, fn: Callable) -> None
torch.library.Dict(*args, **kwargs)
torch.library.Library(ns, kind, dispatch_key='')
torch.library.List(*args, **kwargs)
torch.library.OpOverload(overloadpacket, op, op_dk, schema, tags)
torch.library.Optional(*args, **kwds)
torch.library.Sequence(*args, **kwargs)
torch.library.Set(*args, **kwargs)
torch.library.Tuple(*args, **kwargs)
torch.library.Union(*args, **kwds)
torch.library.custom_op(name: str, fn: Optional[Callable] = None, /, *, mutates_args: Iterable[str], device_types: Union[str, Sequence[str], NoneType] = None, schema: Optional[str] = None) -> Callable
torch.library.define(qualname, schema, *, lib=None, tags=())
torch.library.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.library.device_types_t(*args, **kwargs)
torch.library.fallthrough_kernel()
torch.library.get_ctx() -> 'torch._library.abstract_impl.AbstractImplCtx'
torch.library.impl(qualname, types, func=None, *, lib=None)
torch.library.impl_abstract(qualname, func=None, *, lib=None, _stacklevel=1)
torch.library.opcheck(op: Union[torch._ops.OpOverload, torch._ops.OpOverloadPacket, torch._library.custom_ops.CustomOpDef], args: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]] = None, *, test_utils: Union[str, Sequence[str]] = ('test_schema', 'test_autograd_registration', 'test_faketensor', 'test_aot_dispatch_dynamic'), raise_exception: bool = True) -> Dict[str, str]
torch.library.register_autograd(op: Union[str, ForwardRef('torch._ops.OpOverload'), ForwardRef('torch._library.custom_ops.CustomOpDef')], backward: Callable, /, *, setup_context: Optional[Callable] = None, lib=None) -> None
torch.library.register_fake(op: Union[str, ForwardRef('torch._ops.OpOverload'), ForwardRef('torch._library.custom_ops.CustomOpDef')], func: Optional[Callable] = None, /, *, lib: Optional[torch.library.Library] = None, _stacklevel: int = 1)
torch.library.register_kernel(op: Union[str, ForwardRef('torch._ops.OpOverload'), ForwardRef('torch._library.custom_ops.CustomOpDef')], device_types: Union[str, Sequence[str], NoneType], func: Optional[Callable] = None, /, *, lib: Optional[torch.library.Library] = None)
torch.load(f: Union[str, os.PathLike, BinaryIO, IO[bytes]], map_location: Union[Callable[[torch.types.Storage, str], torch.types.Storage], torch.device, str, Dict[str, str], NoneType] = None, pickle_module: Any = None, *, weights_only: Optional[bool] = None, mmap: Optional[bool] = None, **pickle_load_args: Any) -> Any
torch.lobpcg(A: torch.Tensor, k: Optional[int] = None, B: Optional[torch.Tensor] = None, X: Optional[torch.Tensor] = None, n: Optional[int] = None, iK: Optional[torch.Tensor] = None, niter: Optional[int] = None, tol: Optional[float] = None, largest: Optional[bool] = None, method: Optional[str] = None, tracker: None = None, ortho_iparams: Optional[Dict[str, int]] = None, ortho_fparams: Optional[Dict[str, float]] = None, ortho_bparams: Optional[Dict[str, bool]] = None) -> Tuple[torch.Tensor, torch.Tensor]
torch.lstsq(input: torch.Tensor, A: torch.Tensor, *, out=None) -> Tuple[torch.Tensor, torch.Tensor]
torch.lu(*args, **kwargs)
torch.manual_seed(seed) -> torch._C.Generator
torch.masked.MaskedTensor(data, mask, requires_grad=False)
torch.masked.amax(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[Tuple[int]] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.amin(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[Tuple[int]] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.argmax(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[int] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.argmin(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[int] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.as_masked_tensor(data, mask)
torch.masked.cumprod(input: torch.Tensor, dim: int, *, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.cumsum(input: torch.Tensor, dim: int, *, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.is_masked_tensor(a)
torch.masked.log_softmax(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: int, *, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.logaddexp(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], other: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], *, dtype: Optional[int] = None, input_mask: Optional[torch.Tensor] = None, other_mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.logsumexp(input: torch.Tensor, dim: Optional[Tuple[int]] = None, *, keepdim: bool = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.masked_tensor(data, mask, requires_grad=False)
torch.masked.maskedtensor.MaskedTensor(data, mask, requires_grad=False)
torch.masked.maskedtensor.binary.is_masked_tensor(a)
torch.masked.maskedtensor.core.MaskedTensor(data, mask, requires_grad=False)
torch.masked.maskedtensor.core.get_default_nowrap_functions() -> Set[Callable]
torch.masked.maskedtensor.core.is_masked_tensor(a)
torch.masked.maskedtensor.creation.MaskedTensor(data, mask, requires_grad=False)
torch.masked.maskedtensor.creation.as_masked_tensor(data, mask)
torch.masked.maskedtensor.creation.masked_tensor(data, mask, requires_grad=False)
torch.masked.maskedtensor.is_masked_tensor(a)
torch.masked.maskedtensor.reductions.as_masked_tensor(data, mask)
torch.masked.maskedtensor.reductions.is_masked_tensor(a)
torch.masked.maskedtensor.reductions.masked_tensor(data, mask, requires_grad=False)
torch.masked.mean(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[Tuple[int]] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.median(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: int = -1, *, keepdim: bool = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.norm(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], ord: Optional[float] = 2.0, dim: Optional[Tuple[int]] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.normalize(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], ord: float, dim: int, *, eps: float = 1e-12, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.prod(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[Tuple[int]] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.softmax(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: int, *, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.softmin(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: int, *, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.std(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[Tuple[int]] = None, unbiased: Optional[bool] = None, *, correction: Optional[int] = None, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.sum(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[Tuple[int]] = None, *, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.masked.var(input: Union[torch.Tensor, torch.masked.maskedtensor.core.MaskedTensor], dim: Optional[Tuple[int]] = None, unbiased: Optional[bool] = None, *, correction: Union[int, float, NoneType] = None, keepdim: Optional[bool] = False, dtype: Optional[int] = None, mask: Optional[torch.Tensor] = None) -> torch.Tensor
torch.matrix_rank(input, tol=None, symmetric=False, *, out=None) -> torch.Tensor
torch.memory_format()
torch.meshgrid(*tensors, indexing: Optional[str] = None) -> Tuple[torch.Tensor, ...]
torch.mps.Event(enable_timing=False)
torch.mps.Union(*args, **kwds)
torch.mps.current_allocated_memory() -> int
torch.mps.device_count() -> int
torch.mps.driver_allocated_memory() -> int
torch.mps.empty_cache() -> None
torch.mps.event.Event(enable_timing=False)
torch.mps.get_rng_state(device: Union[int, str, torch.device] = 'mps') -> torch.Tensor
torch.mps.manual_seed(seed: int) -> None
torch.mps.profiler.profile(mode: str = 'interval', wait_until_completed: bool = False)
torch.mps.profiler.start(mode: str = 'interval', wait_until_completed: bool = False) -> None
torch.mps.profiler.stop()
torch.mps.seed() -> None
torch.mps.set_per_process_memory_fraction(fraction) -> None
torch.mps.set_rng_state(new_state: torch.Tensor, device: Union[int, str, torch.device] = 'mps') -> None
torch.mps.synchronize() -> None
torch.mtia.Any(*args, **kwds)
torch.mtia.Callable(*args, **kwargs)
torch.mtia.Device(*args, **kwargs)
torch.mtia.Dict(*args, **kwargs)
torch.mtia.List(*args, **kwargs)
torch.mtia.Optional(*args, **kwds)
torch.mtia.StreamContext(stream: Optional[ForwardRef('torch.mtia.Stream')])
torch.mtia.Tuple(*args, **kwargs)
torch.mtia.Union(*args, **kwds)
torch.mtia.classproperty(func)
torch.mtia.current_device() -> int
torch.mtia.current_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.Stream
torch.mtia.default_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.Stream
torch.mtia.device(device: Any)
torch.mtia.device_count() -> int
torch.mtia.init()
torch.mtia.is_available() -> bool
torch.mtia.is_initialized()
torch.mtia.set_stream(stream: torch.Stream)
torch.mtia.stream(stream: Optional[ForwardRef('torch.mtia.Stream')]) -> torch.mtia.StreamContext
torch.mtia.synchronize() -> None
torch.nested.DType()
torch.nested.List(*args, **kwargs)
torch.nested.Optional(*args, **kwds)
torch.nested.SymInt(node)
torch.nested.Tuple(*args, **kwargs)
torch.nested.Union(*args, **kwds)
torch.nested.as_nested_tensor(ts: Union[torch.Tensor, List[torch.Tensor], Tuple[torch.Tensor, ...]], dtype: Optional[torch.dtype] = None, device: Optional[torch.device] = None, layout=None) -> torch.Tensor
torch.nested.narrow(tensor: torch.Tensor, dim: int, start: Union[int, torch.Tensor], length: Union[int, torch.Tensor], layout=torch.strided) -> torch.Tensor
torch.nested.nested_tensor(tensor_list, *, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False) -> torch.Tensor
torch.nested.nested_tensor_from_jagged(values: torch.Tensor, offsets: Optional[torch.Tensor] = None, lengths: Optional[torch.Tensor] = None, jagged_dim: Optional[int] = None) -> torch.Tensor
torch.nn.AdaptiveAvgPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.AdaptiveAvgPool2d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.AdaptiveAvgPool3d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.AdaptiveLogSoftmaxWithLoss(in_features: int, n_classes: int, cutoffs: Sequence[int], div_value: float = 4.0, head_bias: bool = False, device=None, dtype=None) -> None
torch.nn.AdaptiveMaxPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.AdaptiveMaxPool2d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.AdaptiveMaxPool3d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.AlphaDropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.AvgPool1d(kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = None, padding: Union[int, Tuple[int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True) -> None
torch.nn.AvgPool2d(kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int], NoneType] = None, padding: Union[int, Tuple[int, int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: Optional[int] = None) -> None
torch.nn.AvgPool3d(kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int], NoneType] = None, padding: Union[int, Tuple[int, int, int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: Optional[int] = None) -> None
torch.nn.BCELoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.BCEWithLogitsLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> None
torch.nn.BatchNorm1d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.BatchNorm2d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.BatchNorm3d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.Bilinear(in1_features: int, in2_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.CELU(alpha: float = 1.0, inplace: bool = False) -> None
torch.nn.CTCLoss(blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False)
torch.nn.ChannelShuffle(groups: int) -> None
torch.nn.CircularPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.CircularPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.CircularPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.ConstantPad1d(padding: Union[int, Tuple[int, int]], value: float)
torch.nn.ConstantPad2d(padding: Union[int, Tuple[int, int, int, int]], value: float) -> None
torch.nn.ConstantPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]], value: float) -> None
torch.nn.Container(*args, **kwargs)
torch.nn.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.ConvTranspose1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.ConvTranspose2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, output_padding: Union[int, Tuple[int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.ConvTranspose3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, output_padding: Union[int, Tuple[int, int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.CosineEmbeddingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.CosineSimilarity(dim: int = 1, eps: float = 1e-08) -> None
torch.nn.CrossEntropyLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None
torch.nn.CrossMapLRN2d(size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1) -> None
torch.nn.DataParallel(module: ~T, device_ids: Optional[Sequence[Union[int, torch.device]]] = None, output_device: Union[int, torch.device, NoneType] = None, dim: int = 0) -> None
torch.nn.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.Dropout1d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.Dropout2d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.Dropout3d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.ELU(alpha: float = 1.0, inplace: bool = False) -> None
torch.nn.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, _freeze: bool = False, device=None, dtype=None) -> None
torch.nn.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None, device=None, dtype=None) -> None
torch.nn.FeatureAlphaDropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.Flatten(start_dim: int = 1, end_dim: int = -1) -> None
torch.nn.Fold(output_size: Union[int, Tuple[int, ...]], kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1) -> None
torch.nn.FractionalMaxPool2d(kernel_size: Union[int, Tuple[int, int]], output_size: Union[int, Tuple[int, int], NoneType] = None, output_ratio: Union[float, Tuple[float, float], NoneType] = None, return_indices: bool = False, _random_samples=None) -> None
torch.nn.FractionalMaxPool3d(kernel_size: Union[int, Tuple[int, int, int]], output_size: Union[int, Tuple[int, int, int], NoneType] = None, output_ratio: Union[float, Tuple[float, float, float], NoneType] = None, return_indices: bool = False, _random_samples=None) -> None
torch.nn.GELU(approximate: str = 'none') -> None
torch.nn.GLU(dim: int = -1) -> None
torch.nn.GRU(*args, **kwargs)
torch.nn.GRUCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.GaussianNLLLoss(*, full: bool = False, eps: float = 1e-06, reduction: str = 'mean') -> None
torch.nn.GroupNorm(num_groups: int, num_channels: int, eps: float = 1e-05, affine: bool = True, device=None, dtype=None) -> None
torch.nn.Hardshrink(lambd: float = 0.5) -> None
torch.nn.Hardsigmoid(inplace: bool = False) -> None
torch.nn.Hardswish(inplace: bool = False) -> None
torch.nn.Hardtanh(min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False, min_value: Optional[float] = None, max_value: Optional[float] = None) -> None
torch.nn.HingeEmbeddingLoss(margin: float = 1.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.HuberLoss(reduction: str = 'mean', delta: float = 1.0) -> None
torch.nn.Identity(*args: Any, **kwargs: Any) -> None
torch.nn.InstanceNorm1d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.InstanceNorm2d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.InstanceNorm3d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.KLDivLoss(size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False) -> None
torch.nn.L1Loss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.LPPool1d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.LPPool2d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.LPPool3d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.LSTM(*args, **kwargs)
torch.nn.LSTMCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.LayerNorm(normalized_shape: Union[int, List[int], torch.Size], eps: float = 1e-05, elementwise_affine: bool = True, bias: bool = True, device=None, dtype=None) -> None
torch.nn.LazyBatchNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.LazyBatchNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.LazyBatchNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.LazyConv1d(out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.LazyConv2d(out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.LazyConv3d(out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.LazyConvTranspose1d(out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.LazyConvTranspose2d(out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, output_padding: Union[int, Tuple[int, int]] = 0, groups: int = 1, bias: bool = True, dilation: int = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.LazyConvTranspose3d(out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, output_padding: Union[int, Tuple[int, int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.LazyInstanceNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.LazyInstanceNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.LazyInstanceNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.LazyLinear(out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.LeakyReLU(negative_slope: float = 0.01, inplace: bool = False) -> None
torch.nn.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.LocalResponseNorm(size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1.0) -> None
torch.nn.LogSigmoid(*args, **kwargs) -> None
torch.nn.LogSoftmax(dim: Optional[int] = None) -> None
torch.nn.MSELoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.MarginRankingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.MaxPool1d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.MaxPool2d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.MaxPool3d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.MaxUnpool1d(kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int], NoneType] = None, padding: Union[int, Tuple[int]] = 0) -> None
torch.nn.MaxUnpool2d(kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int], NoneType] = None, padding: Union[int, Tuple[int, int]] = 0) -> None
torch.nn.MaxUnpool3d(kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int], NoneType] = None, padding: Union[int, Tuple[int, int, int]] = 0) -> None
torch.nn.Mish(inplace: bool = False)
torch.nn.Module(*args, **kwargs) -> None
torch.nn.ModuleDict(modules: Optional[Mapping[str, torch.nn.modules.module.Module]] = None) -> None
torch.nn.ModuleList(modules: Optional[Iterable[torch.nn.modules.module.Module]] = None) -> None
torch.nn.MultiLabelMarginLoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.MultiLabelSoftMarginLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.MultiMarginLoss(p: int = 1, margin: float = 1.0, weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None, batch_first=False, device=None, dtype=None) -> None
torch.nn.NLLLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean') -> None
torch.nn.NLLLoss2d(*args, **kwargs)
torch.nn.PReLU(num_parameters: int = 1, init: float = 0.25, device=None, dtype=None) -> None
torch.nn.PairwiseDistance(p: float = 2.0, eps: float = 1e-06, keepdim: bool = False) -> None
torch.nn.Parameter(data=None, requires_grad=True)
torch.nn.ParameterDict(parameters: Any = None) -> None
torch.nn.ParameterList(values: Optional[Iterable[Any]] = None) -> None
torch.nn.PixelShuffle(upscale_factor: int) -> None
torch.nn.PixelUnshuffle(downscale_factor: int) -> None
torch.nn.PoissonNLLLoss(log_input: bool = True, full: bool = False, size_average=None, eps: float = 1e-08, reduce=None, reduction: str = 'mean') -> None
torch.nn.RMSNorm(normalized_shape: Union[int, List[int], torch.Size], eps: Optional[float] = None, elementwise_affine: bool = True, device=None, dtype=None) -> None
torch.nn.RNN(*args, **kwargs)
torch.nn.RNNBase(mode: str, input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, proj_size: int = 0, device=None, dtype=None) -> None
torch.nn.RNNCell(input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = 'tanh', device=None, dtype=None) -> None
torch.nn.RNNCellBase(input_size: int, hidden_size: int, bias: bool, num_chunks: int, device=None, dtype=None) -> None
torch.nn.RReLU(lower: float = 0.125, upper: float = 0.3333333333333333, inplace: bool = False)
torch.nn.ReLU(inplace: bool = False)
torch.nn.ReLU6(inplace: bool = False)
torch.nn.ReflectionPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.ReflectionPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.ReflectionPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.ReplicationPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.ReplicationPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.ReplicationPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.SELU(inplace: bool = False) -> None
torch.nn.Sequential(*args)
torch.nn.SiLU(inplace: bool = False)
torch.nn.Sigmoid(*args, **kwargs) -> None
torch.nn.SmoothL1Loss(size_average=None, reduce=None, reduction: str = 'mean', beta: float = 1.0) -> None
torch.nn.SoftMarginLoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.Softmax(dim: Optional[int] = None) -> None
torch.nn.Softmax2d(*args, **kwargs) -> None
torch.nn.Softmin(dim: Optional[int] = None) -> None
torch.nn.Softplus(beta: float = 1.0, threshold: float = 20.0) -> None
torch.nn.Softshrink(lambd: float = 0.5) -> None
torch.nn.Softsign(*args, **kwargs) -> None
torch.nn.SyncBatchNorm(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, process_group: Optional[Any] = None, device=None, dtype=None) -> None
torch.nn.Tanh(*args, **kwargs) -> None
torch.nn.Tanhshrink(*args, **kwargs) -> None
torch.nn.Threshold(threshold: float, value: float, inplace: bool = False) -> None
torch.nn.Transformer(d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6, num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, custom_encoder: Optional[Any] = None, custom_decoder: Optional[Any] = None, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.TransformerDecoder(decoder_layer: 'TransformerDecoderLayer', num_layers: int, norm: Optional[torch.nn.modules.module.Module] = None) -> None
torch.nn.TransformerDecoderLayer(d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.TransformerEncoder(encoder_layer: 'TransformerEncoderLayer', num_layers: int, norm: Optional[torch.nn.modules.module.Module] = None, enable_nested_tensor: bool = True, mask_check: bool = True) -> None
torch.nn.TransformerEncoderLayer(d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.TripletMarginLoss(margin: float = 1.0, p: float = 2.0, eps: float = 1e-06, swap: bool = False, size_average=None, reduce=None, reduction: str = 'mean')
torch.nn.TripletMarginWithDistanceLoss(*, distance_function: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, margin: float = 1.0, swap: bool = False, reduction: str = 'mean')
torch.nn.Unflatten(dim: Union[int, str], unflattened_size: Union[torch.Size, List[int], Tuple[int, ...], Tuple[Tuple[str, int]]]) -> None
torch.nn.Unfold(kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1) -> None
torch.nn.UninitializedBuffer(requires_grad=False, device=None, dtype=None) -> None
torch.nn.UninitializedParameter(requires_grad=True, device=None, dtype=None) -> None
torch.nn.Upsample(size: Union[int, Tuple[int, ...], NoneType] = None, scale_factor: Union[float, Tuple[float, ...], NoneType] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> None
torch.nn.UpsamplingBilinear2d(size: Union[int, Tuple[int, int], NoneType] = None, scale_factor: Union[float, Tuple[float, float], NoneType] = None) -> None
torch.nn.UpsamplingNearest2d(size: Union[int, Tuple[int, int], NoneType] = None, scale_factor: Union[float, Tuple[float, float], NoneType] = None) -> None
torch.nn.ZeroPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.ZeroPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.ZeroPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.attention.List(*args, **kwargs)
torch.nn.attention.Union(*args, **kwds)
torch.nn.attention.can_use_efficient_attention(params: torch.backends.cuda._SDPAParams, debug: bool = False) -> bool
torch.nn.attention.can_use_flash_attention(params: torch.backends.cuda._SDPAParams, debug: bool = False) -> bool
torch.nn.attention.cudnn_sdp_enabled()
torch.nn.attention.enable_cudnn_sdp(enabled: bool)
torch.nn.attention.enable_flash_sdp(enabled: bool)
torch.nn.attention.enable_math_sdp(enabled: bool)
torch.nn.attention.enable_mem_efficient_sdp(enabled: bool)
torch.nn.attention.flash_sdp_enabled()
torch.nn.attention.math_sdp_enabled()
torch.nn.attention.mem_efficient_sdp_enabled()
torch.nn.attention.sdpa_kernel(backends: Union[List[torch.nn.attention._SDPBackend], torch.nn.attention._SDPBackend])
torch.nn.attention.warn(message, category=None, stacklevel=1, source=None)
torch.nn.common_types.Optional(*args, **kwds)
torch.nn.common_types.Tuple(*args, **kwargs)
torch.nn.common_types.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.nn.common_types.Union(*args, **kwds)
torch.nn.factory_kwargs(kwargs)
torch.nn.functional.Callable(*args, **kwargs)
torch.nn.functional.List(*args, **kwargs)
torch.nn.functional.Optional(*args, **kwds)
torch.nn.functional.Tuple(*args, **kwargs)
torch.nn.functional.Union(*args, **kwds)
torch.nn.functional.adaptive_avg_pool2d(input: torch.Tensor, output_size: None) -> torch.Tensor
torch.nn.functional.adaptive_avg_pool3d(input: torch.Tensor, output_size: None) -> torch.Tensor
torch.nn.functional.adaptive_max_pool1d(*args, **kwargs)
torch.nn.functional.adaptive_max_pool1d_with_indices(input: torch.Tensor, output_size: None, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.adaptive_max_pool2d(*args, **kwargs)
torch.nn.functional.adaptive_max_pool2d_with_indices(input: torch.Tensor, output_size: None, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.adaptive_max_pool3d(*args, **kwargs)
torch.nn.functional.adaptive_max_pool3d_with_indices(input: torch.Tensor, output_size: None, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.affine_grid(theta: torch.Tensor, size: List[int], align_corners: Optional[bool] = None) -> torch.Tensor
torch.nn.functional.alpha_dropout(input: torch.Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> torch.Tensor
torch.nn.functional.assert_int_or_pair(arg: List[int], arg_name: str, message: str) -> None
torch.nn.functional.batch_norm(input: torch.Tensor, running_mean: Optional[torch.Tensor], running_var: Optional[torch.Tensor], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, training: bool = False, momentum: float = 0.1, eps: float = 1e-05) -> torch.Tensor
torch.nn.functional.binary_cross_entropy(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.binary_cross_entropy_with_logits(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> torch.Tensor
torch.nn.functional.boolean_dispatch(arg_name, arg_index, default, if_true, if_false, module_name, func_name)
torch.nn.functional.celu(input: torch.Tensor, alpha: float = 1.0, inplace: bool = False) -> torch.Tensor
torch.nn.functional.cosine_embedding_loss(input1: torch.Tensor, input2: torch.Tensor, target: torch.Tensor, margin: float = 0, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.cross_entropy(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, ignore_index: int = -100, reduce: Optional[bool] = None, reduction: str = 'mean', label_smoothing: float = 0.0) -> torch.Tensor
torch.nn.functional.ctc_loss(log_probs: torch.Tensor, targets: torch.Tensor, input_lengths: torch.Tensor, target_lengths: torch.Tensor, blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False) -> torch.Tensor
torch.nn.functional.dropout(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor
torch.nn.functional.dropout1d(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor
torch.nn.functional.dropout2d(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor
torch.nn.functional.dropout3d(input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor
torch.nn.functional.elu(input: torch.Tensor, alpha: float = 1.0, inplace: bool = False) -> torch.Tensor
torch.nn.functional.embedding(input: torch.Tensor, weight: torch.Tensor, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False) -> torch.Tensor
torch.nn.functional.embedding_bag(input: torch.Tensor, weight: torch.Tensor, offsets: Optional[torch.Tensor] = None, max_norm: Optional[float] = None, norm_type: float = 2, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, per_sample_weights: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None) -> torch.Tensor
torch.nn.functional.feature_alpha_dropout(input: torch.Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> torch.Tensor
torch.nn.functional.fold(input: torch.Tensor, output_size: None, kernel_size: None, dilation: None = 1, padding: None = 0, stride: None = 1) -> torch.Tensor
torch.nn.functional.fractional_max_pool2d(*args, **kwargs)
torch.nn.functional.fractional_max_pool2d_with_indices(input: torch.Tensor, kernel_size: None, output_size: NoneType = None, output_ratio: NoneType = None, return_indices: bool = False, _random_samples: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.fractional_max_pool3d(*args, **kwargs)
torch.nn.functional.fractional_max_pool3d_with_indices(input: torch.Tensor, kernel_size: None, output_size: NoneType = None, output_ratio: NoneType = None, return_indices: bool = False, _random_samples: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.gaussian_nll_loss(input: torch.Tensor, target: torch.Tensor, var: torch.Tensor, full: bool = False, eps: float = 1e-06, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.glu(input: torch.Tensor, dim: int = -1) -> torch.Tensor
torch.nn.functional.grid_sample(input: torch.Tensor, grid: torch.Tensor, mode: str = 'bilinear', padding_mode: str = 'zeros', align_corners: Optional[bool] = None) -> torch.Tensor
torch.nn.functional.group_norm(input: torch.Tensor, num_groups: int, weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor
torch.nn.functional.gumbel_softmax(logits: torch.Tensor, tau: float = 1, hard: bool = False, eps: float = 1e-10, dim: int = -1) -> torch.Tensor
torch.nn.functional.handle_torch_function(public_api: Callable, relevant_args: Iterable[Any], *args, **kwargs) -> Any
torch.nn.functional.hardsigmoid(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.functional.hardswish(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.functional.hardtanh(input: torch.Tensor, min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False) -> torch.Tensor
torch.nn.functional.hinge_embedding_loss(input: torch.Tensor, target: torch.Tensor, margin: float = 1.0, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.huber_loss(input: torch.Tensor, target: torch.Tensor, reduction: str = 'mean', delta: float = 1.0) -> torch.Tensor
torch.nn.functional.instance_norm(input: torch.Tensor, running_mean: Optional[torch.Tensor] = None, running_var: Optional[torch.Tensor] = None, weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, use_input_stats: bool = True, momentum: float = 0.1, eps: float = 1e-05) -> torch.Tensor
torch.nn.functional.interpolate(input: torch.Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None, antialias: bool = False) -> torch.Tensor
torch.nn.functional.kl_div(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', log_target: bool = False) -> torch.Tensor
torch.nn.functional.l1_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.layer_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor
torch.nn.functional.leaky_relu(input: torch.Tensor, negative_slope: float = 0.01, inplace: bool = False) -> torch.Tensor
torch.nn.functional.local_response_norm(input: torch.Tensor, size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1.0) -> torch.Tensor
torch.nn.functional.log_softmax(input: torch.Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> torch.Tensor
torch.nn.functional.lp_pool1d(input: torch.Tensor, norm_type: Union[int, float], kernel_size: int, stride: NoneType = None, ceil_mode: bool = False) -> torch.Tensor
torch.nn.functional.lp_pool2d(input: torch.Tensor, norm_type: Union[int, float], kernel_size: None, stride: NoneType = None, ceil_mode: bool = False) -> torch.Tensor
torch.nn.functional.lp_pool3d(input: torch.Tensor, norm_type: Union[int, float], kernel_size: None, stride: NoneType = None, ceil_mode: bool = False) -> torch.Tensor
torch.nn.functional.margin_ranking_loss(input1: torch.Tensor, input2: torch.Tensor, target: torch.Tensor, margin: float = 0, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.max_pool1d(*args, **kwargs)
torch.nn.functional.max_pool1d_with_indices(input: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, dilation: None = 1, ceil_mode: bool = False, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.max_pool2d(*args, **kwargs)
torch.nn.functional.max_pool2d_with_indices(input: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, dilation: None = 1, ceil_mode: bool = False, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.max_pool3d(*args, **kwargs)
torch.nn.functional.max_pool3d_with_indices(input: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, dilation: None = 1, ceil_mode: bool = False, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.functional.max_unpool1d(input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None) -> torch.Tensor
torch.nn.functional.max_unpool2d(input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None) -> torch.Tensor
torch.nn.functional.max_unpool3d(input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None) -> torch.Tensor
torch.nn.functional.mish(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.functional.mse_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.multi_head_attention_forward(query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, embed_dim_to_check: int, num_heads: int, in_proj_weight: Optional[torch.Tensor], in_proj_bias: Optional[torch.Tensor], bias_k: Optional[torch.Tensor], bias_v: Optional[torch.Tensor], add_zero_attn: bool, dropout_p: float, out_proj_weight: torch.Tensor, out_proj_bias: Optional[torch.Tensor], training: bool = True, key_padding_mask: Optional[torch.Tensor] = None, need_weights: bool = True, attn_mask: Optional[torch.Tensor] = None, use_separate_proj_weight: bool = False, q_proj_weight: Optional[torch.Tensor] = None, k_proj_weight: Optional[torch.Tensor] = None, v_proj_weight: Optional[torch.Tensor] = None, static_k: Optional[torch.Tensor] = None, static_v: Optional[torch.Tensor] = None, average_attn_weights: bool = True, is_causal: bool = False) -> Tuple[torch.Tensor, Optional[torch.Tensor]]
torch.nn.functional.multi_margin_loss(input: torch.Tensor, target: torch.Tensor, p: int = 1, margin: float = 1.0, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.multilabel_margin_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.multilabel_soft_margin_loss(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.nll_loss(input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, ignore_index: int = -100, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.normalize(input: torch.Tensor, p: float = 2.0, dim: int = 1, eps: float = 1e-12, out: Optional[torch.Tensor] = None) -> torch.Tensor
torch.nn.functional.pad(input: torch.Tensor, pad: List[int], mode: str = 'constant', value: Optional[float] = None) -> torch.Tensor
torch.nn.functional.poisson_nll_loss(input: torch.Tensor, target: torch.Tensor, log_input: bool = True, full: bool = False, size_average: Optional[bool] = None, eps: float = 1e-08, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.functional.relu6(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.functional.rms_norm(input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, eps: Optional[float] = None) -> torch.Tensor
torch.nn.functional.rrelu(input: torch.Tensor, lower: float = 0.125, upper: float = 0.3333333333333333, training: bool = False, inplace: bool = False) -> torch.Tensor
torch.nn.functional.selu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.functional.sigmoid(input)
torch.nn.functional.silu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.functional.smooth_l1_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', beta: float = 1.0) -> torch.Tensor
torch.nn.functional.soft_margin_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.softmax(input: torch.Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> torch.Tensor
torch.nn.functional.softmin(input: torch.Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> torch.Tensor
torch.nn.functional.softsign(input)
torch.nn.functional.tanh(input)
torch.nn.functional.tanhshrink(input)
torch.nn.functional.threshold(input: torch.Tensor, threshold: float, value: float, inplace: bool = False) -> torch.Tensor
torch.nn.functional.triplet_margin_loss(anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor, margin: float = 1.0, p: float = 2, eps: float = 1e-06, swap: bool = False, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.triplet_margin_with_distance_loss(anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor, *, distance_function: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, margin: float = 1.0, swap: bool = False, reduction: str = 'mean') -> torch.Tensor
torch.nn.functional.unfold(input: torch.Tensor, kernel_size: None, dilation: None = 1, padding: None = 0, stride: None = 1) -> torch.Tensor
torch.nn.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.nn.functional.upsample_bilinear(input, size=None, scale_factor=None)
torch.nn.functional.upsample_nearest(input, size=None, scale_factor=None)
torch.nn.grad.conv1d_input(input_size, weight, grad_output, stride=1, padding=0, dilation=1, groups=1)
torch.nn.grad.conv1d_weight(input, weight_size, grad_output, stride=1, padding=0, dilation=1, groups=1)
torch.nn.grad.conv2d_input(input_size, weight, grad_output, stride=1, padding=0, dilation=1, groups=1)
torch.nn.grad.conv2d_weight(input, weight_size, grad_output, stride=1, padding=0, dilation=1, groups=1)
torch.nn.grad.conv3d_input(input_size, weight, grad_output, stride=1, padding=0, dilation=1, groups=1)
torch.nn.grad.conv3d_weight(input, weight_size, grad_output, stride=1, padding=0, dilation=1, groups=1)
torch.nn.init.calculate_gain(nonlinearity, param=None)
torch.nn.init.constant(*args, **kwargs)
torch.nn.init.constant_(tensor: torch.Tensor, val: float) -> torch.Tensor
torch.nn.init.dirac(*args, **kwargs)
torch.nn.init.dirac_(tensor, groups=1)
torch.nn.init.eye(*args, **kwargs)
torch.nn.init.eye_(tensor)
torch.nn.init.kaiming_normal(*args, **kwargs)
torch.nn.init.kaiming_normal_(tensor: torch.Tensor, a: float = 0, mode: str = 'fan_in', nonlinearity: str = 'leaky_relu', generator: Optional[torch._C.Generator] = None)
torch.nn.init.kaiming_uniform(*args, **kwargs)
torch.nn.init.kaiming_uniform_(tensor: torch.Tensor, a: float = 0, mode: str = 'fan_in', nonlinearity: str = 'leaky_relu', generator: Optional[torch._C.Generator] = None)
torch.nn.init.normal(*args, **kwargs)
torch.nn.init.normal_(tensor: torch.Tensor, mean: float = 0.0, std: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.init.ones_(tensor: torch.Tensor) -> torch.Tensor
torch.nn.init.orthogonal(*args, **kwargs)
torch.nn.init.orthogonal_(tensor, gain=1, generator: Optional[torch._C.Generator] = None)
torch.nn.init.sparse(*args, **kwargs)
torch.nn.init.sparse_(tensor, sparsity, std=0.01, generator: Optional[torch._C.Generator] = None)
torch.nn.init.trunc_normal_(tensor: torch.Tensor, mean: float = 0.0, std: float = 1.0, a: float = -2.0, b: float = 2.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.init.uniform(*args, **kwargs)
torch.nn.init.uniform_(tensor: torch.Tensor, a: float = 0.0, b: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.init.xavier_normal(*args, **kwargs)
torch.nn.init.xavier_normal_(tensor: torch.Tensor, gain: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.init.xavier_uniform(*args, **kwargs)
torch.nn.init.xavier_uniform_(tensor: torch.Tensor, gain: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.init.zeros_(tensor: torch.Tensor) -> torch.Tensor
torch.nn.intrinsic.BNReLU2d(batch_norm, relu)
torch.nn.intrinsic.BNReLU3d(batch_norm, relu)
torch.nn.intrinsic.ConvBn1d(conv, bn)
torch.nn.intrinsic.ConvBn2d(conv, bn)
torch.nn.intrinsic.ConvBn3d(conv, bn)
torch.nn.intrinsic.ConvBnReLU1d(conv, bn, relu)
torch.nn.intrinsic.ConvBnReLU2d(conv, bn, relu)
torch.nn.intrinsic.ConvBnReLU3d(conv, bn, relu)
torch.nn.intrinsic.ConvReLU1d(conv, relu)
torch.nn.intrinsic.ConvReLU2d(conv, relu)
torch.nn.intrinsic.ConvReLU3d(conv, relu)
torch.nn.intrinsic.LinearBn1d(linear, bn)
torch.nn.intrinsic.LinearReLU(linear, relu)
torch.nn.intrinsic.modules.BNReLU2d(batch_norm, relu)
torch.nn.intrinsic.modules.BNReLU3d(batch_norm, relu)
torch.nn.intrinsic.modules.ConvBn1d(conv, bn)
torch.nn.intrinsic.modules.ConvBn2d(conv, bn)
torch.nn.intrinsic.modules.ConvBn3d(conv, bn)
torch.nn.intrinsic.modules.ConvBnReLU1d(conv, bn, relu)
torch.nn.intrinsic.modules.ConvBnReLU2d(conv, bn, relu)
torch.nn.intrinsic.modules.ConvBnReLU3d(conv, bn, relu)
torch.nn.intrinsic.modules.ConvReLU1d(conv, relu)
torch.nn.intrinsic.modules.ConvReLU2d(conv, relu)
torch.nn.intrinsic.modules.ConvReLU3d(conv, relu)
torch.nn.intrinsic.modules.LinearBn1d(linear, bn)
torch.nn.intrinsic.modules.LinearReLU(linear, relu)
torch.nn.intrinsic.modules.fused.BNReLU2d(batch_norm, relu)
torch.nn.intrinsic.modules.fused.BNReLU3d(batch_norm, relu)
torch.nn.intrinsic.modules.fused.ConvBn1d(conv, bn)
torch.nn.intrinsic.modules.fused.ConvBn2d(conv, bn)
torch.nn.intrinsic.modules.fused.ConvBn3d(conv, bn)
torch.nn.intrinsic.modules.fused.ConvBnReLU1d(conv, bn, relu)
torch.nn.intrinsic.modules.fused.ConvBnReLU2d(conv, bn, relu)
torch.nn.intrinsic.modules.fused.ConvBnReLU3d(conv, bn, relu)
torch.nn.intrinsic.modules.fused.ConvReLU1d(conv, relu)
torch.nn.intrinsic.modules.fused.ConvReLU2d(conv, relu)
torch.nn.intrinsic.modules.fused.ConvReLU3d(conv, relu)
torch.nn.intrinsic.modules.fused.LinearBn1d(linear, bn)
torch.nn.intrinsic.modules.fused.LinearReLU(linear, relu)
torch.nn.intrinsic.qat.ConvBn1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.ConvBn2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.ConvBn3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.ConvBnReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.ConvBnReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.ConvBnReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.LinearBn1d(in_features, out_features, bias=True, eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.LinearReLU(in_features, out_features, bias=True, qconfig=None)
torch.nn.intrinsic.qat.freeze_bn_stats(mod)
torch.nn.intrinsic.qat.modules.ConvBn1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.ConvBn2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.ConvBn3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.ConvBnReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.ConvBnReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.ConvBnReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.modules.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.modules.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.modules.LinearBn1d(in_features, out_features, bias=True, eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.LinearReLU(in_features, out_features, bias=True, qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBn1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBn2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBn3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=None, padding_mode='zeros', eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.freeze_bn_stats(mod)
torch.nn.intrinsic.qat.modules.conv_fused.update_bn_stats(mod)
torch.nn.intrinsic.qat.modules.freeze_bn_stats(mod)
torch.nn.intrinsic.qat.modules.linear_fused.LinearBn1d(in_features, out_features, bias=True, eps=1e-05, momentum=0.1, freeze_bn=False, qconfig=None)
torch.nn.intrinsic.qat.modules.linear_relu.LinearReLU(in_features, out_features, bias=True, qconfig=None)
torch.nn.intrinsic.qat.modules.update_bn_stats(mod)
torch.nn.intrinsic.qat.update_bn_stats(mod)
torch.nn.intrinsic.quantized.BNReLU2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.intrinsic.quantized.BNReLU3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.intrinsic.quantized.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.nn.intrinsic.quantized.dynamic.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.nn.intrinsic.quantized.dynamic.modules.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.nn.intrinsic.quantized.dynamic.modules.linear_relu.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.nn.intrinsic.quantized.modules.BNReLU2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.BNReLU3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU(in_features, out_features, bias=True, dtype=torch.qint8)
torch.nn.modules.AdaptiveAvgPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.modules.AdaptiveAvgPool2d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.modules.AdaptiveAvgPool3d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.modules.AdaptiveLogSoftmaxWithLoss(in_features: int, n_classes: int, cutoffs: Sequence[int], div_value: float = 4.0, head_bias: bool = False, device=None, dtype=None) -> None
torch.nn.modules.AdaptiveMaxPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.modules.AdaptiveMaxPool2d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.modules.AdaptiveMaxPool3d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.modules.AlphaDropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.AvgPool1d(kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = None, padding: Union[int, Tuple[int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True) -> None
torch.nn.modules.AvgPool2d(kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int], NoneType] = None, padding: Union[int, Tuple[int, int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: Optional[int] = None) -> None
torch.nn.modules.AvgPool3d(kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int], NoneType] = None, padding: Union[int, Tuple[int, int, int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: Optional[int] = None) -> None
torch.nn.modules.BCELoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.BCEWithLogitsLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> None
torch.nn.modules.BatchNorm1d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.modules.BatchNorm2d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.modules.BatchNorm3d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.modules.Bilinear(in1_features: int, in2_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.CELU(alpha: float = 1.0, inplace: bool = False) -> None
torch.nn.modules.CTCLoss(blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False)
torch.nn.modules.ChannelShuffle(groups: int) -> None
torch.nn.modules.CircularPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.CircularPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.CircularPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.ConstantPad1d(padding: Union[int, Tuple[int, int]], value: float)
torch.nn.modules.ConstantPad2d(padding: Union[int, Tuple[int, int, int, int]], value: float) -> None
torch.nn.modules.ConstantPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]], value: float) -> None
torch.nn.modules.Container(*args, **kwargs)
torch.nn.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.ConvTranspose1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.ConvTranspose2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, output_padding: Union[int, Tuple[int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.ConvTranspose3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, output_padding: Union[int, Tuple[int, int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.CosineEmbeddingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.CosineSimilarity(dim: int = 1, eps: float = 1e-08) -> None
torch.nn.modules.CrossEntropyLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None
torch.nn.modules.CrossMapLRN2d(size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1) -> None
torch.nn.modules.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.Dropout1d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.Dropout2d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.Dropout3d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.ELU(alpha: float = 1.0, inplace: bool = False) -> None
torch.nn.modules.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, _freeze: bool = False, device=None, dtype=None) -> None
torch.nn.modules.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None, device=None, dtype=None) -> None
torch.nn.modules.FeatureAlphaDropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.Flatten(start_dim: int = 1, end_dim: int = -1) -> None
torch.nn.modules.Fold(output_size: Union[int, Tuple[int, ...]], kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1) -> None
torch.nn.modules.FractionalMaxPool2d(kernel_size: Union[int, Tuple[int, int]], output_size: Union[int, Tuple[int, int], NoneType] = None, output_ratio: Union[float, Tuple[float, float], NoneType] = None, return_indices: bool = False, _random_samples=None) -> None
torch.nn.modules.FractionalMaxPool3d(kernel_size: Union[int, Tuple[int, int, int]], output_size: Union[int, Tuple[int, int, int], NoneType] = None, output_ratio: Union[float, Tuple[float, float, float], NoneType] = None, return_indices: bool = False, _random_samples=None) -> None
torch.nn.modules.GELU(approximate: str = 'none') -> None
torch.nn.modules.GLU(dim: int = -1) -> None
torch.nn.modules.GRU(*args, **kwargs)
torch.nn.modules.GRUCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.GaussianNLLLoss(*, full: bool = False, eps: float = 1e-06, reduction: str = 'mean') -> None
torch.nn.modules.GroupNorm(num_groups: int, num_channels: int, eps: float = 1e-05, affine: bool = True, device=None, dtype=None) -> None
torch.nn.modules.Hardshrink(lambd: float = 0.5) -> None
torch.nn.modules.Hardsigmoid(inplace: bool = False) -> None
torch.nn.modules.Hardswish(inplace: bool = False) -> None
torch.nn.modules.Hardtanh(min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False, min_value: Optional[float] = None, max_value: Optional[float] = None) -> None
torch.nn.modules.HingeEmbeddingLoss(margin: float = 1.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.HuberLoss(reduction: str = 'mean', delta: float = 1.0) -> None
torch.nn.modules.Identity(*args: Any, **kwargs: Any) -> None
torch.nn.modules.InstanceNorm1d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.modules.InstanceNorm2d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.modules.InstanceNorm3d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.modules.KLDivLoss(size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False) -> None
torch.nn.modules.L1Loss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.LPPool1d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.modules.LPPool2d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.modules.LPPool3d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.modules.LSTM(*args, **kwargs)
torch.nn.modules.LSTMCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.LayerNorm(normalized_shape: Union[int, List[int], torch.Size], eps: float = 1e-05, elementwise_affine: bool = True, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.LazyBatchNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.LazyBatchNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.LazyBatchNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.LazyConv1d(out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.LazyConv2d(out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.LazyConv3d(out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.LazyConvTranspose1d(out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.LazyConvTranspose2d(out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, output_padding: Union[int, Tuple[int, int]] = 0, groups: int = 1, bias: bool = True, dilation: int = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.LazyConvTranspose3d(out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, output_padding: Union[int, Tuple[int, int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.LazyInstanceNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.LazyInstanceNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.LazyInstanceNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.LazyLinear(out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.LeakyReLU(negative_slope: float = 0.01, inplace: bool = False) -> None
torch.nn.modules.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.LocalResponseNorm(size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1.0) -> None
torch.nn.modules.LogSigmoid(*args, **kwargs) -> None
torch.nn.modules.LogSoftmax(dim: Optional[int] = None) -> None
torch.nn.modules.MSELoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.MarginRankingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.MaxPool1d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.modules.MaxPool2d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.modules.MaxPool3d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.modules.MaxUnpool1d(kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int], NoneType] = None, padding: Union[int, Tuple[int]] = 0) -> None
torch.nn.modules.MaxUnpool2d(kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int], NoneType] = None, padding: Union[int, Tuple[int, int]] = 0) -> None
torch.nn.modules.MaxUnpool3d(kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int], NoneType] = None, padding: Union[int, Tuple[int, int, int]] = 0) -> None
torch.nn.modules.Mish(inplace: bool = False)
torch.nn.modules.Module(*args, **kwargs) -> None
torch.nn.modules.ModuleDict(modules: Optional[Mapping[str, torch.nn.modules.module.Module]] = None) -> None
torch.nn.modules.ModuleList(modules: Optional[Iterable[torch.nn.modules.module.Module]] = None) -> None
torch.nn.modules.MultiLabelMarginLoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.MultiLabelSoftMarginLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.MultiMarginLoss(p: int = 1, margin: float = 1.0, weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None, batch_first=False, device=None, dtype=None) -> None
torch.nn.modules.NLLLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.NLLLoss2d(*args, **kwargs)
torch.nn.modules.PReLU(num_parameters: int = 1, init: float = 0.25, device=None, dtype=None) -> None
torch.nn.modules.PairwiseDistance(p: float = 2.0, eps: float = 1e-06, keepdim: bool = False) -> None
torch.nn.modules.ParameterDict(parameters: Any = None) -> None
torch.nn.modules.ParameterList(values: Optional[Iterable[Any]] = None) -> None
torch.nn.modules.PixelShuffle(upscale_factor: int) -> None
torch.nn.modules.PixelUnshuffle(downscale_factor: int) -> None
torch.nn.modules.PoissonNLLLoss(log_input: bool = True, full: bool = False, size_average=None, eps: float = 1e-08, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.RMSNorm(normalized_shape: Union[int, List[int], torch.Size], eps: Optional[float] = None, elementwise_affine: bool = True, device=None, dtype=None) -> None
torch.nn.modules.RNN(*args, **kwargs)
torch.nn.modules.RNNBase(mode: str, input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, proj_size: int = 0, device=None, dtype=None) -> None
torch.nn.modules.RNNCell(input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = 'tanh', device=None, dtype=None) -> None
torch.nn.modules.RNNCellBase(input_size: int, hidden_size: int, bias: bool, num_chunks: int, device=None, dtype=None) -> None
torch.nn.modules.RReLU(lower: float = 0.125, upper: float = 0.3333333333333333, inplace: bool = False)
torch.nn.modules.ReLU(inplace: bool = False)
torch.nn.modules.ReLU6(inplace: bool = False)
torch.nn.modules.ReflectionPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.ReflectionPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.ReflectionPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.ReplicationPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.ReplicationPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.ReplicationPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.SELU(inplace: bool = False) -> None
torch.nn.modules.Sequential(*args)
torch.nn.modules.SiLU(inplace: bool = False)
torch.nn.modules.Sigmoid(*args, **kwargs) -> None
torch.nn.modules.SmoothL1Loss(size_average=None, reduce=None, reduction: str = 'mean', beta: float = 1.0) -> None
torch.nn.modules.SoftMarginLoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.Softmax(dim: Optional[int] = None) -> None
torch.nn.modules.Softmax2d(*args, **kwargs) -> None
torch.nn.modules.Softmin(dim: Optional[int] = None) -> None
torch.nn.modules.Softplus(beta: float = 1.0, threshold: float = 20.0) -> None
torch.nn.modules.Softshrink(lambd: float = 0.5) -> None
torch.nn.modules.Softsign(*args, **kwargs) -> None
torch.nn.modules.SyncBatchNorm(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, process_group: Optional[Any] = None, device=None, dtype=None) -> None
torch.nn.modules.Tanh(*args, **kwargs) -> None
torch.nn.modules.Tanhshrink(*args, **kwargs) -> None
torch.nn.modules.Threshold(threshold: float, value: float, inplace: bool = False) -> None
torch.nn.modules.Transformer(d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6, num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, custom_encoder: Optional[Any] = None, custom_decoder: Optional[Any] = None, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.TransformerDecoder(decoder_layer: 'TransformerDecoderLayer', num_layers: int, norm: Optional[torch.nn.modules.module.Module] = None) -> None
torch.nn.modules.TransformerDecoderLayer(d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.TransformerEncoder(encoder_layer: 'TransformerEncoderLayer', num_layers: int, norm: Optional[torch.nn.modules.module.Module] = None, enable_nested_tensor: bool = True, mask_check: bool = True) -> None
torch.nn.modules.TransformerEncoderLayer(d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.TripletMarginLoss(margin: float = 1.0, p: float = 2.0, eps: float = 1e-06, swap: bool = False, size_average=None, reduce=None, reduction: str = 'mean')
torch.nn.modules.TripletMarginWithDistanceLoss(*, distance_function: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, margin: float = 1.0, swap: bool = False, reduction: str = 'mean')
torch.nn.modules.Unflatten(dim: Union[int, str], unflattened_size: Union[torch.Size, List[int], Tuple[int, ...], Tuple[Tuple[str, int]]]) -> None
torch.nn.modules.Unfold(kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1) -> None
torch.nn.modules.Upsample(size: Union[int, Tuple[int, ...], NoneType] = None, scale_factor: Union[float, Tuple[float, ...], NoneType] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> None
torch.nn.modules.UpsamplingBilinear2d(size: Union[int, Tuple[int, int], NoneType] = None, scale_factor: Union[float, Tuple[float, float], NoneType] = None) -> None
torch.nn.modules.UpsamplingNearest2d(size: Union[int, Tuple[int, int], NoneType] = None, scale_factor: Union[float, Tuple[float, float], NoneType] = None) -> None
torch.nn.modules.ZeroPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.ZeroPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.ZeroPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.activation.CELU(alpha: float = 1.0, inplace: bool = False) -> None
torch.nn.modules.activation.ELU(alpha: float = 1.0, inplace: bool = False) -> None
torch.nn.modules.activation.GELU(approximate: str = 'none') -> None
torch.nn.modules.activation.GLU(dim: int = -1) -> None
torch.nn.modules.activation.Hardshrink(lambd: float = 0.5) -> None
torch.nn.modules.activation.Hardsigmoid(inplace: bool = False) -> None
torch.nn.modules.activation.Hardswish(inplace: bool = False) -> None
torch.nn.modules.activation.Hardtanh(min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False, min_value: Optional[float] = None, max_value: Optional[float] = None) -> None
torch.nn.modules.activation.LeakyReLU(negative_slope: float = 0.01, inplace: bool = False) -> None
torch.nn.modules.activation.LogSigmoid(*args, **kwargs) -> None
torch.nn.modules.activation.LogSoftmax(dim: Optional[int] = None) -> None
torch.nn.modules.activation.Mish(inplace: bool = False)
torch.nn.modules.activation.Module(*args, **kwargs) -> None
torch.nn.modules.activation.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None, batch_first=False, device=None, dtype=None) -> None
torch.nn.modules.activation.NonDynamicallyQuantizableLinear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.activation.Optional(*args, **kwds)
torch.nn.modules.activation.PReLU(num_parameters: int = 1, init: float = 0.25, device=None, dtype=None) -> None
torch.nn.modules.activation.Parameter(data=None, requires_grad=True)
torch.nn.modules.activation.RReLU(lower: float = 0.125, upper: float = 0.3333333333333333, inplace: bool = False)
torch.nn.modules.activation.ReLU(inplace: bool = False)
torch.nn.modules.activation.ReLU6(inplace: bool = False)
torch.nn.modules.activation.SELU(inplace: bool = False) -> None
torch.nn.modules.activation.SiLU(inplace: bool = False)
torch.nn.modules.activation.Sigmoid(*args, **kwargs) -> None
torch.nn.modules.activation.Softmax(dim: Optional[int] = None) -> None
torch.nn.modules.activation.Softmax2d(*args, **kwargs) -> None
torch.nn.modules.activation.Softmin(dim: Optional[int] = None) -> None
torch.nn.modules.activation.Softplus(beta: float = 1.0, threshold: float = 20.0) -> None
torch.nn.modules.activation.Softshrink(lambd: float = 0.5) -> None
torch.nn.modules.activation.Softsign(*args, **kwargs) -> None
torch.nn.modules.activation.Tanh(*args, **kwargs) -> None
torch.nn.modules.activation.Tanhshrink(*args, **kwargs) -> None
torch.nn.modules.activation.Threshold(threshold: float, value: float, inplace: bool = False) -> None
torch.nn.modules.activation.Tuple(*args, **kwargs)
torch.nn.modules.activation.constant_(tensor: torch.Tensor, val: float) -> torch.Tensor
torch.nn.modules.activation.xavier_normal_(tensor: torch.Tensor, gain: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.modules.activation.xavier_uniform_(tensor: torch.Tensor, gain: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss(in_features: int, n_classes: int, cutoffs: Sequence[int], div_value: float = 4.0, head_bias: bool = False, device=None, dtype=None) -> None
torch.nn.modules.adaptive.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.adaptive.List(*args, **kwargs)
torch.nn.modules.adaptive.Module(*args, **kwargs) -> None
torch.nn.modules.adaptive.ModuleList(modules: Optional[Iterable[torch.nn.modules.module.Module]] = None) -> None
torch.nn.modules.adaptive.Sequence(*args, **kwargs)
torch.nn.modules.adaptive.Sequential(*args)
torch.nn.modules.adaptive.log_softmax(input: torch.Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> torch.Tensor
torch.nn.modules.adaptive.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.nn.modules.batchnorm.Any(*args, **kwds)
torch.nn.modules.batchnorm.BatchNorm1d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.BatchNorm2d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.BatchNorm3d(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.LazyBatchNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.LazyBatchNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.LazyBatchNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.LazyModuleMixin(*args, **kwargs)
torch.nn.modules.batchnorm.Module(*args, **kwargs) -> None
torch.nn.modules.batchnorm.Optional(*args, **kwds)
torch.nn.modules.batchnorm.Parameter(data=None, requires_grad=True)
torch.nn.modules.batchnorm.SyncBatchNorm(num_features: int, eps: float = 1e-05, momentum: Optional[float] = 0.1, affine: bool = True, track_running_stats: bool = True, process_group: Optional[Any] = None, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.UninitializedBuffer(requires_grad=False, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.UninitializedParameter(requires_grad=True, device=None, dtype=None) -> None
torch.nn.modules.batchnorm.sync_batch_norm(*args, **kwargs)
torch.nn.modules.channelshuffle.ChannelShuffle(groups: int) -> None
torch.nn.modules.channelshuffle.Module(*args, **kwargs) -> None
torch.nn.modules.container.Any(*args, **kwds)
torch.nn.modules.container.Container(*args, **kwargs)
torch.nn.modules.container.Dict(*args, **kwargs)
torch.nn.modules.container.Iterable(*args, **kwargs)
torch.nn.modules.container.Iterator(*args, **kwargs)
torch.nn.modules.container.Mapping(*args, **kwargs)
torch.nn.modules.container.Module(*args, **kwargs) -> None
torch.nn.modules.container.ModuleDict(modules: Optional[Mapping[str, torch.nn.modules.module.Module]] = None) -> None
torch.nn.modules.container.ModuleList(modules: Optional[Iterable[torch.nn.modules.module.Module]] = None) -> None
torch.nn.modules.container.Optional(*args, **kwds)
torch.nn.modules.container.Parameter(data=None, requires_grad=True)
torch.nn.modules.container.ParameterDict(parameters: Any = None) -> None
torch.nn.modules.container.ParameterList(values: Optional[Iterable[Any]] = None) -> None
torch.nn.modules.container.Self(*args, **kwds)
torch.nn.modules.container.Sequential(*args)
torch.nn.modules.container.Tuple(*args, **kwargs)
torch.nn.modules.container.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.nn.modules.container.Union(*args, **kwds)
torch.nn.modules.container.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.modules.container.overload(func)
torch.nn.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.ConvTranspose1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.ConvTranspose2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, output_padding: Union[int, Tuple[int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.ConvTranspose3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, output_padding: Union[int, Tuple[int, int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.LazyConv1d(out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.LazyConv2d(out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.LazyConv3d(out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.LazyConvTranspose1d(out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, output_padding: Union[int, Tuple[int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.LazyConvTranspose2d(out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[int, Tuple[int, int]] = 0, output_padding: Union[int, Tuple[int, int]] = 0, groups: int = 1, bias: bool = True, dilation: int = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.LazyConvTranspose3d(out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[int, Tuple[int, int, int]] = 0, output_padding: Union[int, Tuple[int, int, int]] = 0, groups: int = 1, bias: bool = True, dilation: Union[int, Tuple[int, int, int]] = 1, padding_mode: str = 'zeros', device=None, dtype=None) -> None
torch.nn.modules.conv.LazyModuleMixin(*args, **kwargs)
torch.nn.modules.conv.List(*args, **kwargs)
torch.nn.modules.conv.Module(*args, **kwargs) -> None
torch.nn.modules.conv.Optional(*args, **kwds)
torch.nn.modules.conv.Parameter(data=None, requires_grad=True)
torch.nn.modules.conv.Tuple(*args, **kwargs)
torch.nn.modules.conv.UninitializedParameter(requires_grad=True, device=None, dtype=None) -> None
torch.nn.modules.conv.Union(*args, **kwds)
torch.nn.modules.conv.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.modules.distance.CosineSimilarity(dim: int = 1, eps: float = 1e-08) -> None
torch.nn.modules.distance.Module(*args, **kwargs) -> None
torch.nn.modules.distance.PairwiseDistance(p: float = 2.0, eps: float = 1e-06, keepdim: bool = False) -> None
torch.nn.modules.dropout.AlphaDropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.dropout.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.dropout.Dropout1d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.dropout.Dropout2d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.dropout.Dropout3d(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.dropout.FeatureAlphaDropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.dropout.Module(*args, **kwargs) -> None
torch.nn.modules.flatten.Flatten(start_dim: int = 1, end_dim: int = -1) -> None
torch.nn.modules.flatten.Module(*args, **kwargs) -> None
torch.nn.modules.flatten.Tuple(*args, **kwargs)
torch.nn.modules.flatten.Unflatten(dim: Union[int, str], unflattened_size: Union[torch.Size, List[int], Tuple[int, ...], Tuple[Tuple[str, int]]]) -> None
torch.nn.modules.flatten.Union(*args, **kwds)
torch.nn.modules.fold.Fold(output_size: Union[int, Tuple[int, ...]], kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1) -> None
torch.nn.modules.fold.Module(*args, **kwargs) -> None
torch.nn.modules.fold.Unfold(kernel_size: Union[int, Tuple[int, ...]], dilation: Union[int, Tuple[int, ...]] = 1, padding: Union[int, Tuple[int, ...]] = 0, stride: Union[int, Tuple[int, ...]] = 1) -> None
torch.nn.modules.instancenorm.InstanceNorm1d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.modules.instancenorm.InstanceNorm2d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.modules.instancenorm.InstanceNorm3d(num_features: int, eps: float = 1e-05, momentum: float = 0.1, affine: bool = False, track_running_stats: bool = False, device=None, dtype=None) -> None
torch.nn.modules.instancenorm.LazyInstanceNorm1d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.instancenorm.LazyInstanceNorm2d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.instancenorm.LazyInstanceNorm3d(eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, device=None, dtype=None) -> None
torch.nn.modules.lazy.Any(*args, **kwds)
torch.nn.modules.lazy.LazyModuleMixin(*args, **kwargs)
torch.nn.modules.lazy.Optional(*args, **kwds)
torch.nn.modules.lazy.Protocol()
torch.nn.modules.lazy.Type(*args, **kwargs)
torch.nn.modules.lazy.is_lazy(param)
torch.nn.modules.linear.Any(*args, **kwds)
torch.nn.modules.linear.Bilinear(in1_features: int, in2_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.linear.Identity(*args: Any, **kwargs: Any) -> None
torch.nn.modules.linear.LazyLinear(out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.linear.LazyModuleMixin(*args, **kwargs)
torch.nn.modules.linear.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.linear.Module(*args, **kwargs) -> None
torch.nn.modules.linear.NonDynamicallyQuantizableLinear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.linear.Parameter(data=None, requires_grad=True)
torch.nn.modules.linear.UninitializedParameter(requires_grad=True, device=None, dtype=None) -> None
torch.nn.modules.loss.BCELoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.BCEWithLogitsLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> None
torch.nn.modules.loss.CTCLoss(blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False)
torch.nn.modules.loss.Callable(*args, **kwargs)
torch.nn.modules.loss.CosineEmbeddingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.CrossEntropyLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None
torch.nn.modules.loss.GaussianNLLLoss(*, full: bool = False, eps: float = 1e-06, reduction: str = 'mean') -> None
torch.nn.modules.loss.HingeEmbeddingLoss(margin: float = 1.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.HuberLoss(reduction: str = 'mean', delta: float = 1.0) -> None
torch.nn.modules.loss.KLDivLoss(size_average=None, reduce=None, reduction: str = 'mean', log_target: bool = False) -> None
torch.nn.modules.loss.L1Loss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.MSELoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.MarginRankingLoss(margin: float = 0.0, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.Module(*args, **kwargs) -> None
torch.nn.modules.loss.MultiLabelMarginLoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.MultiLabelSoftMarginLoss(weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.MultiMarginLoss(p: int = 1, margin: float = 1.0, weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.NLLLoss(weight: Optional[torch.Tensor] = None, size_average=None, ignore_index: int = -100, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.NLLLoss2d(*args, **kwargs)
torch.nn.modules.loss.Optional(*args, **kwds)
torch.nn.modules.loss.PairwiseDistance(p: float = 2.0, eps: float = 1e-06, keepdim: bool = False) -> None
torch.nn.modules.loss.PoissonNLLLoss(log_input: bool = True, full: bool = False, size_average=None, eps: float = 1e-08, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.SmoothL1Loss(size_average=None, reduce=None, reduction: str = 'mean', beta: float = 1.0) -> None
torch.nn.modules.loss.SoftMarginLoss(size_average=None, reduce=None, reduction: str = 'mean') -> None
torch.nn.modules.loss.TripletMarginLoss(margin: float = 1.0, p: float = 2.0, eps: float = 1e-06, swap: bool = False, size_average=None, reduce=None, reduction: str = 'mean')
torch.nn.modules.loss.TripletMarginWithDistanceLoss(*, distance_function: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, margin: float = 1.0, swap: bool = False, reduction: str = 'mean')
torch.nn.modules.loss.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.modules.module.Any(*args, **kwds)
torch.nn.modules.module.Callable(*args, **kwargs)
torch.nn.modules.module.DeviceLikeType(*args, **kwargs)
torch.nn.modules.module.Dict(*args, **kwargs)
torch.nn.modules.module.Iterator(*args, **kwargs)
torch.nn.modules.module.List(*args, **kwargs)
torch.nn.modules.module.Mapping(*args, **kwargs)
torch.nn.modules.module.Module(*args, **kwargs) -> None
torch.nn.modules.module.Optional(*args, **kwds)
torch.nn.modules.module.Parameter(data=None, requires_grad=True)
torch.nn.modules.module.RemovableHandle(hooks_dict: Any, *, extra_dict: Any = None) -> None
torch.nn.modules.module.Self(*args, **kwds)
torch.nn.modules.module.Set(*args, **kwargs)
torch.nn.modules.module.Tuple(*args, **kwargs)
torch.nn.modules.module.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.nn.modules.module.Union(*args, **kwds)
torch.nn.modules.module.dtype()
torch.nn.modules.module.is_traceable_wrapper_subclass(t)
torch.nn.modules.module.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.nn.modules.module.overload(func)
torch.nn.modules.module.register_module_backward_hook(hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.module.register_module_buffer_registration_hook(hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.module.register_module_forward_hook(hook: Callable[..., NoneType], *, always_call: bool = False) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.module.register_module_forward_pre_hook(hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.module.register_module_full_backward_hook(hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.module.register_module_full_backward_pre_hook(hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.module.register_module_module_registration_hook(hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.module.register_module_parameter_registration_hook(hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle
torch.nn.modules.normalization.CrossMapLRN2d(size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1) -> None
torch.nn.modules.normalization.GroupNorm(num_groups: int, num_channels: int, eps: float = 1e-05, affine: bool = True, device=None, dtype=None) -> None
torch.nn.modules.normalization.LayerNorm(normalized_shape: Union[int, List[int], torch.Size], eps: float = 1e-05, elementwise_affine: bool = True, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.normalization.List(*args, **kwargs)
torch.nn.modules.normalization.LocalResponseNorm(size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1.0) -> None
torch.nn.modules.normalization.Module(*args, **kwargs) -> None
torch.nn.modules.normalization.Optional(*args, **kwds)
torch.nn.modules.normalization.Parameter(data=None, requires_grad=True)
torch.nn.modules.normalization.RMSNorm(normalized_shape: Union[int, List[int], torch.Size], eps: Optional[float] = None, elementwise_affine: bool = True, device=None, dtype=None) -> None
torch.nn.modules.normalization.Size(iterable=(), /)
torch.nn.modules.normalization.Tuple(*args, **kwargs)
torch.nn.modules.normalization.Union(*args, **kwds)
torch.nn.modules.padding.CircularPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.padding.CircularPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.padding.CircularPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.padding.ConstantPad1d(padding: Union[int, Tuple[int, int]], value: float)
torch.nn.modules.padding.ConstantPad2d(padding: Union[int, Tuple[int, int, int, int]], value: float) -> None
torch.nn.modules.padding.ConstantPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]], value: float) -> None
torch.nn.modules.padding.Module(*args, **kwargs) -> None
torch.nn.modules.padding.ReflectionPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.padding.ReflectionPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.padding.ReflectionPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.padding.ReplicationPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.padding.ReplicationPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.padding.ReplicationPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.padding.Sequence(*args, **kwargs)
torch.nn.modules.padding.Tuple(*args, **kwargs)
torch.nn.modules.padding.ZeroPad1d(padding: Union[int, Tuple[int, int]]) -> None
torch.nn.modules.padding.ZeroPad2d(padding: Union[int, Tuple[int, int, int, int]]) -> None
torch.nn.modules.padding.ZeroPad3d(padding: Union[int, Tuple[int, int, int, int, int, int]]) -> None
torch.nn.modules.pixelshuffle.Module(*args, **kwargs) -> None
torch.nn.modules.pixelshuffle.PixelShuffle(upscale_factor: int) -> None
torch.nn.modules.pixelshuffle.PixelUnshuffle(downscale_factor: int) -> None
torch.nn.modules.pooling.AdaptiveAvgPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.modules.pooling.AdaptiveAvgPool2d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.modules.pooling.AdaptiveAvgPool3d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]]) -> None
torch.nn.modules.pooling.AdaptiveMaxPool1d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.modules.pooling.AdaptiveMaxPool2d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.modules.pooling.AdaptiveMaxPool3d(output_size: Union[int, NoneType, Tuple[Optional[int], ...]], return_indices: bool = False) -> None
torch.nn.modules.pooling.AvgPool1d(kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = None, padding: Union[int, Tuple[int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True) -> None
torch.nn.modules.pooling.AvgPool2d(kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int], NoneType] = None, padding: Union[int, Tuple[int, int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: Optional[int] = None) -> None
torch.nn.modules.pooling.AvgPool3d(kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int], NoneType] = None, padding: Union[int, Tuple[int, int, int]] = 0, ceil_mode: bool = False, count_include_pad: bool = True, divisor_override: Optional[int] = None) -> None
torch.nn.modules.pooling.FractionalMaxPool2d(kernel_size: Union[int, Tuple[int, int]], output_size: Union[int, Tuple[int, int], NoneType] = None, output_ratio: Union[float, Tuple[float, float], NoneType] = None, return_indices: bool = False, _random_samples=None) -> None
torch.nn.modules.pooling.FractionalMaxPool3d(kernel_size: Union[int, Tuple[int, int, int]], output_size: Union[int, Tuple[int, int, int], NoneType] = None, output_ratio: Union[float, Tuple[float, float, float], NoneType] = None, return_indices: bool = False, _random_samples=None) -> None
torch.nn.modules.pooling.LPPool1d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.modules.pooling.LPPool2d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.modules.pooling.LPPool3d(norm_type: float, kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, ceil_mode: bool = False) -> None
torch.nn.modules.pooling.List(*args, **kwargs)
torch.nn.modules.pooling.MaxPool1d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.modules.pooling.MaxPool2d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.modules.pooling.MaxPool3d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.modules.pooling.MaxUnpool1d(kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int], NoneType] = None, padding: Union[int, Tuple[int]] = 0) -> None
torch.nn.modules.pooling.MaxUnpool2d(kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int], NoneType] = None, padding: Union[int, Tuple[int, int]] = 0) -> None
torch.nn.modules.pooling.MaxUnpool3d(kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int], NoneType] = None, padding: Union[int, Tuple[int, int, int]] = 0) -> None
torch.nn.modules.pooling.Module(*args, **kwargs) -> None
torch.nn.modules.pooling.Optional(*args, **kwds)
torch.nn.modules.rnn.GRU(*args, **kwargs)
torch.nn.modules.rnn.GRUCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.rnn.LSTM(*args, **kwargs)
torch.nn.modules.rnn.LSTMCell(input_size: int, hidden_size: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.rnn.List(*args, **kwargs)
torch.nn.modules.rnn.Module(*args, **kwargs) -> None
torch.nn.modules.rnn.Optional(*args, **kwds)
torch.nn.modules.rnn.PackedSequence(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None)
torch.nn.modules.rnn.Parameter(data=None, requires_grad=True)
torch.nn.modules.rnn.RNN(*args, **kwargs)
torch.nn.modules.rnn.RNNBase(mode: str, input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, proj_size: int = 0, device=None, dtype=None) -> None
torch.nn.modules.rnn.RNNCell(input_size: int, hidden_size: int, bias: bool = True, nonlinearity: str = 'tanh', device=None, dtype=None) -> None
torch.nn.modules.rnn.RNNCellBase(input_size: int, hidden_size: int, bias: bool, num_chunks: int, device=None, dtype=None) -> None
torch.nn.modules.rnn.Tuple(*args, **kwargs)
torch.nn.modules.rnn.apply_permutation(tensor: torch.Tensor, permutation: torch.Tensor, dim: int = 1) -> torch.Tensor
torch.nn.modules.rnn.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.modules.rnn.overload(func)
torch.nn.modules.sparse.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, _freeze: bool = False, device=None, dtype=None) -> None
torch.nn.modules.sparse.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None, device=None, dtype=None) -> None
torch.nn.modules.sparse.Module(*args, **kwargs) -> None
torch.nn.modules.sparse.Optional(*args, **kwds)
torch.nn.modules.sparse.Parameter(data=None, requires_grad=True)
torch.nn.modules.transformer.Any(*args, **kwds)
torch.nn.modules.transformer.Callable(*args, **kwargs)
torch.nn.modules.transformer.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.modules.transformer.LayerNorm(normalized_shape: Union[int, List[int], torch.Size], eps: float = 1e-05, elementwise_affine: bool = True, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.transformer.Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.transformer.Module(*args, **kwargs) -> None
torch.nn.modules.transformer.ModuleList(modules: Optional[Iterable[torch.nn.modules.module.Module]] = None) -> None
torch.nn.modules.transformer.MultiheadAttention(embed_dim, num_heads, dropout=0.0, bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None, vdim=None, batch_first=False, device=None, dtype=None) -> None
torch.nn.modules.transformer.Optional(*args, **kwds)
torch.nn.modules.transformer.Transformer(d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6, num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, custom_encoder: Optional[Any] = None, custom_decoder: Optional[Any] = None, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.transformer.TransformerDecoder(decoder_layer: 'TransformerDecoderLayer', num_layers: int, norm: Optional[torch.nn.modules.module.Module] = None) -> None
torch.nn.modules.transformer.TransformerDecoderLayer(d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.transformer.TransformerEncoder(encoder_layer: 'TransformerEncoderLayer', num_layers: int, norm: Optional[torch.nn.modules.module.Module] = None, enable_nested_tensor: bool = True, mask_check: bool = True) -> None
torch.nn.modules.transformer.TransformerEncoderLayer(d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1, activation: Union[str, Callable[[torch.Tensor], torch.Tensor]] = <function relu at 0x0000024A6138E680>, layer_norm_eps: float = 1e-05, batch_first: bool = False, norm_first: bool = False, bias: bool = True, device=None, dtype=None) -> None
torch.nn.modules.transformer.Union(*args, **kwds)
torch.nn.modules.transformer.xavier_uniform_(tensor: torch.Tensor, gain: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor
torch.nn.modules.upsampling.Module(*args, **kwargs) -> None
torch.nn.modules.upsampling.Optional(*args, **kwds)
torch.nn.modules.upsampling.Upsample(size: Union[int, Tuple[int, ...], NoneType] = None, scale_factor: Union[float, Tuple[float, ...], NoneType] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None) -> None
torch.nn.modules.upsampling.UpsamplingBilinear2d(size: Union[int, Tuple[int, int], NoneType] = None, scale_factor: Union[float, Tuple[float, float], NoneType] = None) -> None
torch.nn.modules.upsampling.UpsamplingNearest2d(size: Union[int, Tuple[int, int], NoneType] = None, scale_factor: Union[float, Tuple[float, float], NoneType] = None) -> None
torch.nn.modules.utils.Any(*args, **kwds)
torch.nn.modules.utils.Dict(*args, **kwargs)
torch.nn.modules.utils.List(*args, **kwargs)
torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(state_dict: Dict[str, Any], prefix: str) -> None
torch.nn.parallel.DataParallel(module: ~T, device_ids: Optional[Sequence[Union[int, torch.device]]] = None, output_device: Union[int, torch.device, NoneType] = None, dim: int = 0) -> None
torch.nn.parallel.DistributedDataParallel(module, device_ids=None, output_device=None, dim=0, broadcast_buffers=True, process_group=None, bucket_cap_mb=None, find_unused_parameters=False, check_reduction=False, gradient_as_bucket_view=False, static_graph=False, delay_all_reduce_named_params=None, param_to_hook_all_reduce=None, mixed_precision: Optional[torch.nn.parallel.distributed._MixedPrecision] = None, device_mesh=None)
torch.nn.parallel.DistributedDataParallelCPU(*args, **kwargs)
torch.nn.parallel.comm.List(*args, **kwargs)
torch.nn.parallel.comm.broadcast(tensor, devices=None, *, out=None)
torch.nn.parallel.comm.broadcast_coalesced(tensors, devices, buffer_size=10485760)
torch.nn.parallel.comm.gather(tensors, dim=0, destination=None, *, out=None)
torch.nn.parallel.comm.reduce_add(inputs, destination=None)
torch.nn.parallel.comm.reduce_add_coalesced(inputs, destination=None, buffer_size=10485760)
torch.nn.parallel.comm.scatter(tensor, devices=None, chunk_sizes=None, dim=0, streams=None, *, out=None)
torch.nn.parallel.data_parallel(module: torch.nn.modules.module.Module, inputs: Any, device_ids: Optional[Sequence[Union[int, torch.device]]] = None, output_device: Union[int, torch.device, NoneType] = None, dim: int = 0, module_kwargs: Optional[Any] = None) -> torch.Tensor
torch.nn.parallel.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.parallel.distributed.Any(*args, **kwds)
torch.nn.parallel.distributed.Callable(*args, **kwargs)
torch.nn.parallel.distributed.DistributedDataParallel(module, device_ids=None, output_device=None, dim=0, broadcast_buffers=True, process_group=None, bucket_cap_mb=None, find_unused_parameters=False, check_reduction=False, gradient_as_bucket_view=False, static_graph=False, delay_all_reduce_named_params=None, param_to_hook_all_reduce=None, mixed_precision: Optional[torch.nn.parallel.distributed._MixedPrecision] = None, device_mesh=None)
torch.nn.parallel.distributed.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.nn.parallel.distributed.Function(*args, **kwargs)
torch.nn.parallel.distributed.Join(joinables: List[torch.distributed.algorithms.join.Joinable], enable: bool = True, throw_on_early_termination: bool = False, **kwargs)
torch.nn.parallel.distributed.JoinHook()
torch.nn.parallel.distributed.Joinable()
torch.nn.parallel.distributed.List(*args, **kwargs)
torch.nn.parallel.distributed.Module(*args, **kwargs) -> None
torch.nn.parallel.distributed.Optional(*args, **kwds)
torch.nn.parallel.distributed.Tuple(*args, **kwargs)
torch.nn.parallel.distributed.Type(*args, **kwargs)
torch.nn.parallel.distributed.auto()
torch.nn.parallel.distributed.contextmanager(func)
torch.nn.parallel.distributed.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.nn.parallel.distributed.fields(class_or_instance)
torch.nn.parallel.distributed.gather(outputs: Any, target_device: Union[int, torch.device], dim: int = 0) -> Any
torch.nn.parallel.distributed.is_dataclass(obj)
torch.nn.parallel.distributed.scatter_kwargs(inputs: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]], target_gpus: Sequence[Union[int, torch.device]], dim: int = 0) -> Tuple[Tuple[Any, ...], Tuple[Dict[str, Any], ...]]
torch.nn.parallel.distributed.tree_flatten(tree: Any, is_leaf: Optional[Callable[[Any], bool]] = None) -> Tuple[List[Any], torch.utils._pytree.TreeSpec]
torch.nn.parallel.distributed.tree_unflatten(leaves: Iterable[Any], treespec: torch.utils._pytree.TreeSpec) -> Any
torch.nn.parallel.gather(outputs: Any, target_device: Union[int, torch.device], dim: int = 0) -> Any
torch.nn.parallel.parallel_apply(modules: Sequence[torch.nn.modules.module.Module], inputs: Sequence[Any], kwargs_tup: Optional[Sequence[Dict[str, Any]]] = None, devices: Optional[Sequence[Union[int, torch.device, NoneType]]] = None) -> List[Any]
torch.nn.parallel.replicate(network: ~T, devices: Sequence[Union[int, torch.device]], detach: bool = False) -> List[~T]
torch.nn.parallel.scatter(inputs, target_gpus, dim=0)
torch.nn.parallel.scatter_gather.Any(*args, **kwds)
torch.nn.parallel.scatter_gather.Dict(*args, **kwargs)
torch.nn.parallel.scatter_gather.Gather(*args, **kwargs)
torch.nn.parallel.scatter_gather.List(*args, **kwargs)
torch.nn.parallel.scatter_gather.Optional(*args, **kwds)
torch.nn.parallel.scatter_gather.Scatter(*args, **kwargs)
torch.nn.parallel.scatter_gather.Sequence(*args, **kwargs)
torch.nn.parallel.scatter_gather.Tuple(*args, **kwargs)
torch.nn.parallel.scatter_gather.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.nn.parallel.scatter_gather.Union(*args, **kwds)
torch.nn.parallel.scatter_gather.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.parallel.scatter_gather.gather(outputs: Any, target_device: Union[int, torch.device], dim: int = 0) -> Any
torch.nn.parallel.scatter_gather.is_namedtuple(obj: Any) -> bool
torch.nn.parallel.scatter_gather.overload(func)
torch.nn.parallel.scatter_gather.scatter(inputs, target_gpus, dim=0)
torch.nn.parallel.scatter_gather.scatter_kwargs(inputs: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]], target_gpus: Sequence[Union[int, torch.device]], dim: int = 0) -> Tuple[Tuple[Any, ...], Tuple[Dict[str, Any], ...]]
torch.nn.parameter.Parameter(data=None, requires_grad=True)
torch.nn.parameter.UninitializedBuffer(requires_grad=False, device=None, dtype=None) -> None
torch.nn.parameter.UninitializedParameter(requires_grad=True, device=None, dtype=None) -> None
torch.nn.parameter.UninitializedTensorMixin()
torch.nn.parameter.is_lazy(param)
torch.nn.qat.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None, qconfig=None) -> None
torch.nn.qat.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None, include_last_offset=False, padding_idx=None, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.dynamic.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.dynamic.modules.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.dynamic.modules.linear.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None, qconfig=None) -> None
torch.nn.qat.modules.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None, include_last_offset=False, padding_idx=None, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[str, int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.conv.Conv2d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int]], stride: Union[int, Tuple[int, int]] = 1, padding: Union[str, int, Tuple[int, int]] = 0, dilation: Union[int, Tuple[int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.conv.Conv3d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int, int, int]], stride: Union[int, Tuple[int, int, int]] = 1, padding: Union[str, int, Tuple[int, int, int]] = 0, dilation: Union[int, Tuple[int, int, int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.embedding_ops.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None, device=None, dtype=None, qconfig=None) -> None
torch.nn.qat.modules.embedding_ops.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, mode='mean', sparse=False, _weight=None, include_last_offset=False, padding_idx=None, qconfig=None, device=None, dtype=None) -> None
torch.nn.qat.modules.linear.Linear(in_features, out_features, bias=True, qconfig=None, device=None, dtype=None) -> None
torch.nn.quantizable.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.nn.quantizable.LSTMCell(input_dim: int, hidden_dim: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.quantizable.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.nn.quantizable.modules.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.nn.quantizable.modules.LSTMCell(input_dim: int, hidden_dim: int, bias: bool = True, device=None, dtype=None) -> None
torch.nn.quantizable.modules.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None) -> None
torch.nn.quantized.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.quantized.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None)
torch.nn.quantized.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.DeQuantize(*args, **kwargs) -> None
torch.nn.quantized.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.quantized.ELU(scale, zero_point, alpha=1.0)
torch.nn.quantized.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, dtype=torch.quint8) -> None
torch.nn.quantized.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'sum', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, dtype=torch.quint8) -> None
torch.nn.quantized.FXFloatFunctional(*args, **kwargs) -> None
torch.nn.quantized.FloatFunctional()
torch.nn.quantized.GroupNorm(num_groups, num_channels, weight, bias, scale, zero_point, eps=1e-05, affine=True, device=None, dtype=None) -> None
torch.nn.quantized.Hardswish(scale, zero_point, device=None, dtype=None)
torch.nn.quantized.InstanceNorm1d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.InstanceNorm2d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.InstanceNorm3d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.LayerNorm(normalized_shape, weight, bias, scale, zero_point, eps=1e-05, elementwise_affine=True, device=None, dtype=None) -> None
torch.nn.quantized.LeakyReLU(scale: float, zero_point: int, negative_slope: float = 0.01, inplace: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.nn.quantized.MaxPool2d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.quantized.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.PReLU(output_scale: float, output_zero_point: int, num_parameters: int = 1) -> None
torch.nn.quantized.QFunctional()
torch.nn.quantized.Quantize(scale, zero_point, dtype, factory_kwargs=None)
torch.nn.quantized.ReLU6(inplace=False)
torch.nn.quantized.Sigmoid(output_scale: float, output_zero_point: int)
torch.nn.quantized.Softmax(dim=None, scale=1.0, zero_point=0)
torch.nn.quantized.dynamic.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, reduce_range=True)
torch.nn.quantized.dynamic.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.GRU(*args, **kwargs)
torch.nn.quantized.dynamic.GRUCell(input_size, hidden_size, bias=True, dtype=torch.qint8)
torch.nn.quantized.dynamic.LSTM(*args, **kwargs)
torch.nn.quantized.dynamic.LSTMCell(*args, **kwargs)
torch.nn.quantized.dynamic.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.nn.quantized.dynamic.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, reduce_range=True)
torch.nn.quantized.dynamic.modules.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.GRU(*args, **kwargs)
torch.nn.quantized.dynamic.modules.GRUCell(input_size, hidden_size, bias=True, dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.LSTM(*args, **kwargs)
torch.nn.quantized.dynamic.modules.LSTMCell(*args, **kwargs)
torch.nn.quantized.dynamic.modules.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None, reduce_range=True)
torch.nn.quantized.dynamic.modules.conv.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.conv.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.conv.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.conv.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.conv.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.dynamic.modules.linear.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.GRU(*args, **kwargs)
torch.nn.quantized.dynamic.modules.rnn.GRUCell(input_size, hidden_size, bias=True, dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.LSTM(*args, **kwargs)
torch.nn.quantized.dynamic.modules.rnn.LSTMCell(*args, **kwargs)
torch.nn.quantized.dynamic.modules.rnn.PackedParameter(param)
torch.nn.quantized.dynamic.modules.rnn.RNNBase(mode, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh', dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase(input_size, hidden_size, bias=True, num_chunks=4, dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.pack_weight_bias(qweight, bias, dtype)
torch.nn.quantized.functional.adaptive_avg_pool2d(input: torch.Tensor, output_size: None) -> torch.Tensor
torch.nn.quantized.functional.adaptive_avg_pool3d(input: torch.Tensor, output_size: None) -> torch.Tensor
torch.nn.quantized.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.nn.quantized.functional.avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)
torch.nn.quantized.functional.celu(input: torch.Tensor, scale: float, zero_point: int, alpha: float = 1.0) -> torch.Tensor
torch.nn.quantized.functional.clamp(input: torch.Tensor, min_: float, max_: float) -> torch.Tensor
torch.nn.quantized.functional.conv1d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)
torch.nn.quantized.functional.conv2d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)
torch.nn.quantized.functional.conv3d(input, weight, bias, stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', scale=1.0, zero_point=0, dtype=torch.quint8)
torch.nn.quantized.functional.elu(input: torch.Tensor, scale: float, zero_point: int, alpha: float = 1.0) -> torch.Tensor
torch.nn.quantized.functional.hardsigmoid(input: torch.Tensor, inplace: bool = False) -> torch.Tensor
torch.nn.quantized.functional.hardswish(input: torch.Tensor, scale: float, zero_point: int) -> torch.Tensor
torch.nn.quantized.functional.hardtanh(input: torch.Tensor, min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False) -> torch.Tensor
torch.nn.quantized.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.nn.quantized.functional.leaky_relu(input: torch.Tensor, negative_slope: float = 0.01, inplace: bool = False, scale: Optional[float] = None, zero_point: Optional[int] = None)
torch.nn.quantized.functional.linear(input: torch.Tensor, weight: torch.Tensor, bias: Optional[torch.Tensor] = None, scale: Optional[float] = None, zero_point: Optional[int] = None) -> torch.Tensor
torch.nn.quantized.functional.max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)
torch.nn.quantized.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)
torch.nn.quantized.functional.threshold(input: torch.Tensor, threshold: float, value: float) -> torch.Tensor
torch.nn.quantized.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)
torch.nn.quantized.functional.upsample_bilinear(input, size=None, scale_factor=None)
torch.nn.quantized.functional.upsample_nearest(input, size=None, scale_factor=None)
torch.nn.quantized.modules.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None) -> None
torch.nn.quantized.modules.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.quantized.modules.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None)
torch.nn.quantized.modules.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.DeQuantize(*args, **kwargs) -> None
torch.nn.quantized.modules.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.quantized.modules.ELU(scale, zero_point, alpha=1.0)
torch.nn.quantized.modules.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, dtype=torch.quint8) -> None
torch.nn.quantized.modules.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'sum', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, dtype=torch.quint8) -> None
torch.nn.quantized.modules.FXFloatFunctional(*args, **kwargs) -> None
torch.nn.quantized.modules.FloatFunctional()
torch.nn.quantized.modules.GroupNorm(num_groups, num_channels, weight, bias, scale, zero_point, eps=1e-05, affine=True, device=None, dtype=None) -> None
torch.nn.quantized.modules.Hardswish(scale, zero_point, device=None, dtype=None)
torch.nn.quantized.modules.InstanceNorm1d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.modules.InstanceNorm2d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.modules.InstanceNorm3d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.modules.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.modules.LayerNorm(normalized_shape, weight, bias, scale, zero_point, eps=1e-05, elementwise_affine=True, device=None, dtype=None) -> None
torch.nn.quantized.modules.LeakyReLU(scale: float, zero_point: int, negative_slope: float = 0.01, inplace: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.modules.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.nn.quantized.modules.MaxPool2d(kernel_size: Union[int, Tuple[int, ...]], stride: Union[int, Tuple[int, ...], NoneType] = None, padding: Union[int, Tuple[int, ...]] = 0, dilation: Union[int, Tuple[int, ...]] = 1, return_indices: bool = False, ceil_mode: bool = False) -> None
torch.nn.quantized.modules.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.modules.PReLU(output_scale: float, output_zero_point: int, num_parameters: int = 1) -> None
torch.nn.quantized.modules.QFunctional()
torch.nn.quantized.modules.Quantize(scale, zero_point, dtype, factory_kwargs=None)
torch.nn.quantized.modules.ReLU6(inplace=False)
torch.nn.quantized.modules.Sigmoid(output_scale: float, output_zero_point: int)
torch.nn.quantized.modules.Softmax(dim=None, scale=1.0, zero_point=0)
torch.nn.quantized.modules.activation.ELU(scale, zero_point, alpha=1.0)
torch.nn.quantized.modules.activation.Hardswish(scale, zero_point, device=None, dtype=None)
torch.nn.quantized.modules.activation.LeakyReLU(scale: float, zero_point: int, negative_slope: float = 0.01, inplace: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.modules.activation.MultiheadAttention(embed_dim: int, num_heads: int, dropout: float = 0.0, bias: bool = True, add_bias_kv: bool = False, add_zero_attn: bool = False, kdim: Optional[int] = None, vdim: Optional[int] = None, batch_first: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.modules.activation.PReLU(output_scale: float, output_zero_point: int, num_parameters: int = 1) -> None
torch.nn.quantized.modules.activation.ReLU6(inplace=False)
torch.nn.quantized.modules.activation.Sigmoid(output_scale: float, output_zero_point: int)
torch.nn.quantized.modules.activation.Softmax(dim=None, scale=1.0, zero_point=0)
torch.nn.quantized.modules.batchnorm.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None) -> None
torch.nn.quantized.modules.batchnorm.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, device=None, dtype=None)
torch.nn.quantized.modules.conv.Conv1d(in_channels: int, out_channels: int, kernel_size: Union[int, Tuple[int]], stride: Union[int, Tuple[int]] = 1, padding: Union[int, Tuple[int]] = 0, dilation: Union[int, Tuple[int]] = 1, groups: int = 1, bias: bool = True, padding_mode: str = 'zeros', device=None, dtype=None)
torch.nn.quantized.modules.conv.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.conv.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.conv.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.conv.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.conv.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros', device=None, dtype=None)
torch.nn.quantized.modules.dropout.Dropout(p: float = 0.5, inplace: bool = False) -> None
torch.nn.quantized.modules.embedding_ops.Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, dtype=torch.quint8) -> None
torch.nn.quantized.modules.embedding_ops.EmbeddingBag(num_embeddings: int, embedding_dim: int, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, mode: str = 'sum', sparse: bool = False, _weight: Optional[torch.Tensor] = None, include_last_offset: bool = False, dtype=torch.quint8) -> None
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams(num_embeddings, embedding_dim, dtype=torch.quint8)
torch.nn.quantized.modules.functional_modules.FXFloatFunctional(*args, **kwargs) -> None
torch.nn.quantized.modules.functional_modules.FloatFunctional()
torch.nn.quantized.modules.functional_modules.QFunctional()
torch.nn.quantized.modules.linear.Linear(in_features, out_features, bias_=True, dtype=torch.qint8)
torch.nn.quantized.modules.linear.LinearPackedParams(dtype=torch.qint8)
torch.nn.quantized.modules.normalization.GroupNorm(num_groups, num_channels, weight, bias, scale, zero_point, eps=1e-05, affine=True, device=None, dtype=None) -> None
torch.nn.quantized.modules.normalization.InstanceNorm1d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.modules.normalization.InstanceNorm2d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.modules.normalization.InstanceNorm3d(num_features, weight, bias, scale, zero_point, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False, device=None, dtype=None) -> None
torch.nn.quantized.modules.normalization.LayerNorm(normalized_shape, weight, bias, scale, zero_point, eps=1e-05, elementwise_affine=True, device=None, dtype=None) -> None
torch.nn.quantized.modules.rnn.LSTM(input_size: int, hidden_size: int, num_layers: int = 1, bias: bool = True, batch_first: bool = False, dropout: float = 0.0, bidirectional: bool = False, device=None, dtype=None) -> None
torch.nn.quantized.modules.utils.WeightedQuantizedModule(*args, **kwargs) -> None
torch.nn.utils.clip_grad.Dict(*args, **kwargs)
torch.nn.utils.clip_grad.Iterable(*args, **kwargs)
torch.nn.utils.clip_grad.List(*args, **kwargs)
torch.nn.utils.clip_grad.Optional(*args, **kwds)
torch.nn.utils.clip_grad.Tuple(*args, **kwargs)
torch.nn.utils.clip_grad.Union(*args, **kwds)
torch.nn.utils.clip_grad.cast(typ, val)
torch.nn.utils.clip_grad.clip_grad_norm(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], max_norm: float, norm_type: float = 2.0, error_if_nonfinite: bool = False, foreach: Optional[bool] = None) -> torch.Tensor
torch.nn.utils.clip_grad.clip_grad_norm_(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], max_norm: float, norm_type: float = 2.0, error_if_nonfinite: bool = False, foreach: Optional[bool] = None) -> torch.Tensor
torch.nn.utils.clip_grad.clip_grad_value_(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], clip_value: float, foreach: Optional[bool] = None) -> None
torch.nn.utils.clip_grad.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.utils.clip_grad_norm(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], max_norm: float, norm_type: float = 2.0, error_if_nonfinite: bool = False, foreach: Optional[bool] = None) -> torch.Tensor
torch.nn.utils.clip_grad_norm_(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], max_norm: float, norm_type: float = 2.0, error_if_nonfinite: bool = False, foreach: Optional[bool] = None) -> torch.Tensor
torch.nn.utils.clip_grad_value_(parameters: Union[torch.Tensor, Iterable[torch.Tensor]], clip_value: float, foreach: Optional[bool] = None) -> None
torch.nn.utils.convert_conv2d_weight_memory_format(module, memory_format)
torch.nn.utils.convert_conv3d_weight_memory_format(module, memory_format)
torch.nn.utils.convert_parameters.Iterable(*args, **kwargs)
torch.nn.utils.convert_parameters.Optional(*args, **kwds)
torch.nn.utils.convert_parameters.parameters_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor
torch.nn.utils.convert_parameters.vector_to_parameters(vec: torch.Tensor, parameters: Iterable[torch.Tensor]) -> None
torch.nn.utils.fuse_conv_bn_eval(conv: 'ConvT', bn: 'torch.nn.modules.batchnorm._BatchNorm', transpose: 'bool' = False) -> 'ConvT'
torch.nn.utils.fuse_conv_bn_weights(conv_w: 'torch.Tensor', conv_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'Optional[torch.Tensor]', bn_b: 'Optional[torch.Tensor]', transpose: 'bool' = False) -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.nn.utils.fuse_linear_bn_eval(linear: 'LinearT', bn: 'torch.nn.modules.batchnorm._BatchNorm') -> 'LinearT'
torch.nn.utils.fuse_linear_bn_weights(linear_w: 'torch.Tensor', linear_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'torch.Tensor', bn_b: 'torch.Tensor') -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.nn.utils.fusion.Optional(*args, **kwds)
torch.nn.utils.fusion.Tuple(*args, **kwargs)
torch.nn.utils.fusion.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.nn.utils.fusion.fuse_conv_bn_eval(conv: 'ConvT', bn: 'torch.nn.modules.batchnorm._BatchNorm', transpose: 'bool' = False) -> 'ConvT'
torch.nn.utils.fusion.fuse_conv_bn_weights(conv_w: 'torch.Tensor', conv_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'Optional[torch.Tensor]', bn_b: 'Optional[torch.Tensor]', transpose: 'bool' = False) -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.nn.utils.fusion.fuse_linear_bn_eval(linear: 'LinearT', bn: 'torch.nn.modules.batchnorm._BatchNorm') -> 'LinearT'
torch.nn.utils.fusion.fuse_linear_bn_weights(linear_w: 'torch.Tensor', linear_b: 'Optional[torch.Tensor]', bn_rm: 'torch.Tensor', bn_rv: 'torch.Tensor', bn_eps: 'float', bn_w: 'torch.Tensor', bn_b: 'torch.Tensor') -> 'Tuple[torch.nn.Parameter, torch.nn.Parameter]'
torch.nn.utils.init.skip_init(module_cls, *args, **kwargs)
torch.nn.utils.memory_format.convert_conv2d_weight_memory_format(module, memory_format)
torch.nn.utils.memory_format.convert_conv3d_weight_memory_format(module, memory_format)
torch.nn.utils.parameters_to_vector(parameters: Iterable[torch.Tensor]) -> torch.Tensor
torch.nn.utils.parametrizations.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.nn.utils.parametrizations.Module(*args, **kwargs) -> None
torch.nn.utils.parametrizations.Optional(*args, **kwds)
torch.nn.utils.parametrizations.auto()
torch.nn.utils.parametrizations.orthogonal(module: torch.nn.modules.module.Module, name: str = 'weight', orthogonal_map: Optional[str] = None, *, use_trivialization: bool = True) -> torch.nn.modules.module.Module
torch.nn.utils.parametrizations.spectral_norm(module: torch.nn.modules.module.Module, name: str = 'weight', n_power_iterations: int = 1, eps: float = 1e-12, dim: Optional[int] = None) -> torch.nn.modules.module.Module
torch.nn.utils.parametrizations.weight_norm(module: torch.nn.modules.module.Module, name: str = 'weight', dim: int = 0)
torch.nn.utils.parametrize.Dict(*args, **kwargs)
torch.nn.utils.parametrize.Module(*args, **kwargs) -> None
torch.nn.utils.parametrize.ModuleDict(modules: Optional[Mapping[str, torch.nn.modules.module.Module]] = None) -> None
torch.nn.utils.parametrize.ModuleList(modules: Optional[Iterable[torch.nn.modules.module.Module]] = None) -> None
torch.nn.utils.parametrize.Optional(*args, **kwds)
torch.nn.utils.parametrize.Parameter(data=None, requires_grad=True)
torch.nn.utils.parametrize.ParametrizationList(modules: Sequence[torch.nn.modules.module.Module], original: Union[torch.Tensor, torch.nn.parameter.Parameter], unsafe: bool = False) -> None
torch.nn.utils.parametrize.Sequence(*args, **kwargs)
torch.nn.utils.parametrize.Tuple(*args, **kwargs)
torch.nn.utils.parametrize.Union(*args, **kwds)
torch.nn.utils.parametrize.cached()
torch.nn.utils.parametrize.contextmanager(func)
torch.nn.utils.parametrize.deepcopy(x, memo=None, _nil=[])
torch.nn.utils.parametrize.get_swap_module_params_on_conversion() -> bool
torch.nn.utils.parametrize.is_parametrized(module: torch.nn.modules.module.Module, tensor_name: Optional[str] = None) -> bool
torch.nn.utils.parametrize.is_traceable_wrapper_subclass(t)
torch.nn.utils.parametrize.register_parametrization(module: torch.nn.modules.module.Module, tensor_name: str, parametrization: torch.nn.modules.module.Module, *, unsafe: bool = False) -> torch.nn.modules.module.Module
torch.nn.utils.parametrize.remove_parametrizations(module: torch.nn.modules.module.Module, tensor_name: str, leave_parametrized: bool = True) -> torch.nn.modules.module.Module
torch.nn.utils.parametrize.transfer_parametrizations_and_params(from_module: torch.nn.modules.module.Module, to_module: torch.nn.modules.module.Module, tensor_name: Optional[str] = None) -> torch.nn.modules.module.Module
torch.nn.utils.parametrize.type_before_parametrizations(module: torch.nn.modules.module.Module) -> type
torch.nn.utils.remove_spectral_norm(module: ~T_module, name: str = 'weight') -> ~T_module
torch.nn.utils.remove_weight_norm(module: ~T_module, name: str = 'weight') -> ~T_module
torch.nn.utils.rnn.Iterable(*args, **kwargs)
torch.nn.utils.rnn.List(*args, **kwargs)
torch.nn.utils.rnn.NamedTuple(typename, fields=None, /, **kwargs)
torch.nn.utils.rnn.Optional(*args, **kwds)
torch.nn.utils.rnn.PackedSequence(data, batch_sizes=None, sorted_indices=None, unsorted_indices=None)
torch.nn.utils.rnn.PackedSequence_(data: torch.Tensor, batch_sizes: torch.Tensor, sorted_indices: Optional[torch.Tensor], unsorted_indices: Optional[torch.Tensor])
torch.nn.utils.rnn.Tuple(*args, **kwargs)
torch.nn.utils.rnn.Union(*args, **kwds)
torch.nn.utils.rnn.bind(optional, fn)
torch.nn.utils.rnn.invert_permutation(permutation: Optional[torch.Tensor]) -> Optional[torch.Tensor]
torch.nn.utils.rnn.pack_padded_sequence(input: torch.Tensor, lengths: torch.Tensor, batch_first: bool = False, enforce_sorted: bool = True) -> torch.nn.utils.rnn.PackedSequence
torch.nn.utils.rnn.pack_sequence(sequences: List[torch.Tensor], enforce_sorted: bool = True) -> torch.nn.utils.rnn.PackedSequence
torch.nn.utils.rnn.pad_packed_sequence(sequence: torch.nn.utils.rnn.PackedSequence, batch_first: bool = False, padding_value: float = 0.0, total_length: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]
torch.nn.utils.rnn.pad_sequence(sequences: Union[torch.Tensor, List[torch.Tensor]], batch_first: bool = False, padding_value: float = 0.0) -> torch.Tensor
torch.nn.utils.rnn.unpack_sequence(packed_sequences: torch.nn.utils.rnn.PackedSequence) -> List[torch.Tensor]
torch.nn.utils.rnn.unpad_sequence(padded_sequences: torch.Tensor, lengths: torch.Tensor, batch_first: bool = False) -> List[torch.Tensor]
torch.nn.utils.skip_init(module_cls, *args, **kwargs)
torch.nn.utils.spectral_norm(module: ~T_module, name: str = 'weight', n_power_iterations: int = 1, eps: float = 1e-12, dim: Optional[int] = None) -> ~T_module
torch.nn.utils.stateless.Any(*args, **kwds)
torch.nn.utils.stateless.Dict(*args, **kwargs)
torch.nn.utils.stateless.Iterator(*args, **kwargs)
torch.nn.utils.stateless.NamedMemberAccessor(module: 'torch.nn.Module') -> None
torch.nn.utils.stateless.Optional(*args, **kwds)
torch.nn.utils.stateless.Set(*args, **kwargs)
torch.nn.utils.stateless.Tuple(*args, **kwargs)
torch.nn.utils.stateless.Union(*args, **kwds)
torch.nn.utils.stateless.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.nn.utils.stateless.functional_call(module: 'torch.nn.Module', parameters_and_buffers: Dict[str, torch.Tensor], args: Union[Any, Tuple], kwargs: Optional[Dict[str, Any]] = None, *, tie_weights: bool = True, strict: bool = False)
torch.nn.utils.vector_to_parameters(vec: torch.Tensor, parameters: Iterable[torch.Tensor]) -> None
torch.nn.utils.weight_norm(module: ~T_module, name: str = 'weight', dim: int = 0) -> ~T_module
torch.no_grad() -> None
torch.norm(input, p: Union[float, str, NoneType] = 'fro', dim=None, keepdim=False, out=None, dtype=None)
torch.optim.ASGD(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.01, lambd: float = 0.0001, alpha: float = 0.75, t0: float = 1000000.0, weight_decay: float = 0, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False, capturable: bool = False)
torch.optim.Adadelta(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 1.0, rho: float = 0.9, eps: float = 1e-06, weight_decay: float = 0, foreach: Optional[bool] = None, *, capturable: bool = False, maximize: bool = False, differentiable: bool = False)
torch.optim.Adagrad(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.01, lr_decay: float = 0, weight_decay: float = 0, initial_accumulator_value: float = 0, eps: float = 1e-10, foreach: Optional[bool] = None, *, maximize: bool = False, differentiable: bool = False, fused: Optional[bool] = None)
torch.optim.Adam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, amsgrad: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False, fused: Optional[bool] = None)
torch.optim.AdamW(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0.01, amsgrad: bool = False, *, maximize: bool = False, foreach: Optional[bool] = None, capturable: bool = False, differentiable: bool = False, fused: Optional[bool] = None)
torch.optim.Adamax(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.002, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, foreach: Optional[bool] = None, *, maximize: bool = False, differentiable: bool = False, capturable: bool = False)
torch.optim.LBFGS(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 1, max_iter: int = 20, max_eval: Optional[int] = None, tolerance_grad: float = 1e-07, tolerance_change: float = 1e-09, history_size: int = 100, line_search_fn: Optional[str] = None)
torch.optim.NAdam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.002, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, momentum_decay: float = 0.004, decoupled_weight_decay: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False)
torch.optim.Optimizer(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], defaults: Dict[str, Any]) -> None
torch.optim.RAdam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, decoupled_weight_decay: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False)
torch.optim.RMSprop(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.01, alpha: float = 0.99, eps: float = 1e-08, weight_decay: float = 0, momentum: float = 0, centered=False, capturable=False, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False)
torch.optim.Rprop(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.01, etas: Tuple[float, float] = (0.5, 1.2), step_sizes: Tuple[float, float] = (1e-06, 50), *, capturable: bool = False, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False)
torch.optim.SGD(params, lr: float = 0.001, momentum: float = 0, dampening: float = 0, weight_decay: float = 0, nesterov=False, *, maximize: bool = False, foreach: Optional[bool] = None, differentiable: bool = False, fused: Optional[bool] = None)
torch.optim.SparseAdam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: float = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, maximize: bool = False)
torch.optim.lr_scheduler.Any(*args, **kwds)
torch.optim.lr_scheduler.Callable(*args, **kwargs)
torch.optim.lr_scheduler.ChainedScheduler(schedulers: Sequence[torch.optim.lr_scheduler.LRScheduler], optimizer: Optional[torch.optim.optimizer.Optimizer] = None)
torch.optim.lr_scheduler.ConstantLR(optimizer: torch.optim.optimizer.Optimizer, factor=0.3333333333333333, total_iters=5, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.CosineAnnealingLR(optimizer: torch.optim.optimizer.Optimizer, T_max: int, eta_min=0, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer: torch.optim.optimizer.Optimizer, T_0: int, T_mult=1, eta_min=0, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.Counter(iterable=None, /, **kwds)
torch.optim.lr_scheduler.CyclicLR(optimizer: torch.optim.optimizer.Optimizer, base_lr: Union[float, List[float]], max_lr: Union[float, List[float]], step_size_up=2000, step_size_down: Optional[int] = None, mode: Literal['triangular', 'triangular2', 'exp_range'] = 'triangular', gamma=1.0, scale_fn: Optional[Callable[[float], float]] = None, scale_mode: Literal['cycle', 'iterations'] = 'cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.Dict(*args, **kwargs)
torch.optim.lr_scheduler.ExponentialLR(optimizer: torch.optim.optimizer.Optimizer, gamma: float, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.Iterable(*args, **kwargs)
torch.optim.lr_scheduler.LRScheduler(optimizer: torch.optim.optimizer.Optimizer, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.LambdaLR(optimizer: torch.optim.optimizer.Optimizer, lr_lambda: Union[Callable[[int], float], List[Callable[[int], float]]], last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.LinearLR(optimizer: torch.optim.optimizer.Optimizer, start_factor=0.3333333333333333, end_factor=1.0, total_iters=5, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.List(*args, **kwargs)
torch.optim.lr_scheduler.Literal(*args, **kwds)
torch.optim.lr_scheduler.MultiStepLR(optimizer: torch.optim.optimizer.Optimizer, milestones: Iterable[int], gamma=0.1, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.MultiplicativeLR(optimizer: torch.optim.optimizer.Optimizer, lr_lambda: Union[Callable[[int], float], List[Callable[[int], float]]], last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.OneCycleLR(optimizer: torch.optim.optimizer.Optimizer, max_lr: Union[float, List[float]], total_steps: Optional[int] = None, epochs: Optional[int] = None, steps_per_epoch: Optional[int] = None, pct_start=0.3, anneal_strategy: Literal['cos', 'linear'] = 'cos', cycle_momentum=True, base_momentum: Union[float, List[float]] = 0.85, max_momentum: Union[float, List[float]] = 0.95, div_factor=25.0, final_div_factor=10000.0, three_phase=False, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.Optimizer(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], defaults: Dict[str, Any]) -> None
torch.optim.lr_scheduler.Optional(*args, **kwds)
torch.optim.lr_scheduler.PolynomialLR(optimizer: torch.optim.optimizer.Optimizer, total_iters=5, power=1.0, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer: torch.optim.optimizer.Optimizer, mode: Literal['min', 'max'] = 'min', factor=0.1, patience=10, threshold=0.0001, threshold_mode: Literal['rel', 'abs'] = 'rel', cooldown=0, min_lr: Union[List[float], float] = 0, eps=1e-08, verbose='deprecated')
torch.optim.lr_scheduler.Sequence(*args, **kwargs)
torch.optim.lr_scheduler.SequentialLR(optimizer: torch.optim.optimizer.Optimizer, schedulers: List[torch.optim.lr_scheduler.LRScheduler], milestones: List[int], last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.StepLR(optimizer: torch.optim.optimizer.Optimizer, step_size: int, gamma=0.1, last_epoch=-1, verbose='deprecated')
torch.optim.lr_scheduler.SupportsFloat(*args, **kwargs)
torch.optim.lr_scheduler.TypedDict(typename, fields=None, /, *, total=True, **kwargs)
torch.optim.lr_scheduler.Union(*args, **kwds)
torch.optim.lr_scheduler.bisect_right(a, x, lo=0, hi=None, *, key=None)
torch.optim.lr_scheduler.cast(typ, val)
torch.optim.swa_utils.Any(*args, **kwds)
torch.optim.swa_utils.AveragedModel(model: torch.nn.modules.module.Module, device: Union[int, torch.device, NoneType] = None, avg_fn: Optional[Callable[[torch.Tensor, torch.Tensor, Union[torch.Tensor, int]], torch.Tensor]] = None, multi_avg_fn: Optional[Callable[[Union[Tuple[torch.Tensor, ...], List[torch.Tensor]], Union[Tuple[torch.Tensor, ...], List[torch.Tensor]], Union[torch.Tensor, int]], NoneType]] = None, use_buffers=False)
torch.optim.swa_utils.Callable(*args, **kwargs)
torch.optim.swa_utils.Iterable(*args, **kwargs)
torch.optim.swa_utils.LRScheduler(optimizer: torch.optim.optimizer.Optimizer, last_epoch=-1, verbose='deprecated')
torch.optim.swa_utils.List(*args, **kwargs)
torch.optim.swa_utils.Literal(*args, **kwds)
torch.optim.swa_utils.Module(*args, **kwargs) -> None
torch.optim.swa_utils.Optimizer(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], defaults: Dict[str, Any]) -> None
torch.optim.swa_utils.Optional(*args, **kwds)
torch.optim.swa_utils.PARAM_LIST(*args, **kwargs)
torch.optim.swa_utils.SWALR(optimizer: torch.optim.optimizer.Optimizer, swa_lr: float, anneal_epochs=10, anneal_strategy: Literal['cos', 'linear'] = 'cos', last_epoch=-1)
torch.optim.swa_utils.Tuple(*args, **kwargs)
torch.optim.swa_utils.Union(*args, **kwds)
torch.optim.swa_utils.deepcopy(x, memo=None, _nil=[])
torch.optim.swa_utils.get_ema_avg_fn(decay=0.999)
torch.optim.swa_utils.get_ema_multi_avg_fn(decay=0.999)
torch.optim.swa_utils.get_swa_avg_fn()
torch.optim.swa_utils.get_swa_multi_avg_fn()
torch.optim.swa_utils.update_bn(loader: Iterable[Any], model: torch.nn.modules.module.Module, device: Union[int, torch.device, NoneType] = None)
torch.overrides.Any(*args, **kwds)
torch.overrides.BaseTorchFunctionMode()
torch.overrides.Callable(*args, **kwargs)
torch.overrides.Dict(*args, **kwargs)
torch.overrides.Iterable(*args, **kwargs)
torch.overrides.List(*args, **kwargs)
torch.overrides.Set(*args, **kwargs)
torch.overrides.TorchFunctionMode()
torch.overrides.Tuple(*args, **kwargs)
torch.overrides.Type(*args, **kwargs)
torch.overrides.enable_reentrant_dispatch()
torch.overrides.get_default_nowrap_functions() -> Set[Callable]
torch.overrides.get_ignored_functions() -> Set[Callable]
torch.overrides.get_overridable_functions() -> Dict[Any, List[Callable]]
torch.overrides.get_testing_overrides() -> Dict[Callable, Callable]
torch.overrides.handle_torch_function(public_api: Callable, relevant_args: Iterable[Any], *args, **kwargs) -> Any
torch.overrides.is_tensor_like(inp)
torch.overrides.is_tensor_method_or_property(func: Callable) -> bool
torch.overrides.resolve_name(f)
torch.overrides.wrap_torch_function(dispatcher: Callable)
torch.overrides.wraps(wrapped, assigned=('__module__', '__name__', '__qualname__', '__doc__', '__annotations__'), updated=('__dict__',))
torch.package.Directory(name: str, is_dir: bool)
torch.package.GlobGroup(include: Union[str, Iterable[str]], *, exclude: Union[str, Iterable[str]] = (), separator: str = '.')
torch.package.Importer()
torch.package.OrderedImporter(*args)
torch.package.PackageExporter(f: Union[str, pathlib.Path, BinaryIO], importer: Union[torch.package.importer.Importer, Sequence[torch.package.importer.Importer]] = <torch.package.importer._SysImporter object at 0x0000024A613327D0>, debug: bool = False)
torch.package.PackageImporter(file_or_buffer: Union[str, torch.PyTorchFileReader, os.PathLike, BinaryIO], module_allowed: Callable[[str], bool] = <function PackageImporter.<lambda> at 0x0000024A61368670>)
torch.package.PackagingError(dependency_graph: torch.package._digraph.DiGraph, debug=False)
torch.package.analyze.find_first_use_of_broken_modules(exc: torch.package.package_exporter.PackagingError) -> Dict[str, List[str]]
torch.package.analyze.is_from_package.Any(*args, **kwds)
torch.package.analyze.is_from_package.ModuleType(name, doc=None)
torch.package.analyze.is_from_package.is_from_package(obj: Any) -> bool
torch.package.analyze.is_from_package.is_mangled(name: str) -> bool
torch.package.analyze.trace_dependencies(callable: Callable[[Any], Any], inputs: Iterable[Tuple[Any, ...]]) -> List[str]
torch.package.file_structure_representation.Dict(*args, **kwargs)
torch.package.file_structure_representation.Directory(name: str, is_dir: bool)
torch.package.file_structure_representation.GlobGroup(include: Union[str, Iterable[str]], *, exclude: Union[str, Iterable[str]] = (), separator: str = '.')
torch.package.file_structure_representation.GlobPattern(*args, **kwargs)
torch.package.file_structure_representation.List(*args, **kwargs)
torch.package.find_file_dependencies.List(*args, **kwargs)
torch.package.find_file_dependencies.Optional(*args, **kwds)
torch.package.find_file_dependencies.Tuple(*args, **kwargs)
torch.package.find_file_dependencies.find_files_source_depends_on(src: str, package: str) -> List[Tuple[str, Optional[str]]]
torch.package.glob_group.GlobGroup(include: Union[str, Iterable[str]], *, exclude: Union[str, Iterable[str]] = (), separator: str = '.')
torch.package.glob_group.GlobPattern(*args, **kwargs)
torch.package.glob_group.Iterable(*args, **kwargs)
torch.package.glob_group.Union(*args, **kwds)
torch.package.importer.ABC()
torch.package.importer.Any(*args, **kwds)
torch.package.importer.Dict(*args, **kwargs)
torch.package.importer.Importer()
torch.package.importer.List(*args, **kwargs)
torch.package.importer.ModuleType(name, doc=None)
torch.package.importer.Optional(*args, **kwds)
torch.package.importer.OrderedImporter(*args)
torch.package.importer.Tuple(*args, **kwargs)
torch.package.importer.abstractmethod(funcobj)
torch.package.importer.demangle(name: str) -> str
torch.package.importer.get_mangle_prefix(name: str) -> str
torch.package.importer.is_mangled(name: str) -> bool
torch.package.is_from_package(obj: Any) -> bool
torch.package.package_exporter.ActionHook(*args, **kwargs)
torch.package.package_exporter.Any(*args, **kwds)
torch.package.package_exporter.BinaryIO()
torch.package.package_exporter.Callable(*args, **kwargs)
torch.package.package_exporter.DefaultDict(*args, **kwargs)
torch.package.package_exporter.DiGraph()
torch.package.package_exporter.Dict(*args, **kwargs)
torch.package.package_exporter.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.package.package_exporter.GlobGroup(include: Union[str, Iterable[str]], *, exclude: Union[str, Iterable[str]] = (), separator: str = '.')
torch.package.package_exporter.GlobPattern(*args, **kwargs)
torch.package.package_exporter.Importer()
torch.package.package_exporter.List(*args, **kwargs)
torch.package.package_exporter.Optional(*args, **kwds)
torch.package.package_exporter.OrderedImporter(*args)
torch.package.package_exporter.PackageExporter(f: Union[str, pathlib.Path, BinaryIO], importer: Union[torch.package.importer.Importer, Sequence[torch.package.importer.Importer]] = <torch.package.importer._SysImporter object at 0x0000024A613327D0>, debug: bool = False)
torch.package.package_exporter.PackagingError(dependency_graph: torch.package._digraph.DiGraph, debug=False)
torch.package.package_exporter.PackagingErrorReason(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.package.package_exporter.Path(*args, **kwargs)
torch.package.package_exporter.RemovableHandle(hooks_dict: Any, *, extra_dict: Any = None) -> None
torch.package.package_exporter.Sequence(*args, **kwargs)
torch.package.package_exporter.Set(*args, **kwargs)
torch.package.package_exporter.SourceFileLoader(fullname, path)
torch.package.package_exporter.Storage()
torch.package.package_exporter.Union(*args, **kwds)
torch.package.package_exporter.cast(typ, val)
torch.package.package_exporter.create_pickler(data_buf, importer, protocol=4)
torch.package.package_exporter.dataclass(cls=None, /, *, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False, match_args=True, kw_only=False, slots=False)
torch.package.package_exporter.demangle(name: str) -> str
torch.package.package_exporter.find_files_source_depends_on(src: str, package: str) -> List[Tuple[str, Optional[str]]]
torch.package.package_exporter.is_mangled(name: str) -> bool
torch.package.package_exporter.is_stdlib_module(module: str) -> bool
torch.package.package_exporter.location_tag(storage: Union[torch.types.Storage, torch.storage.TypedStorage, torch.storage.UntypedStorage])
torch.package.package_exporter.normalize_storage_type(storage_type)
torch.package.package_importer.Any(*args, **kwds)
torch.package.package_importer.BinaryIO()
torch.package.package_importer.Callable(*args, **kwargs)
torch.package.package_importer.Dict(*args, **kwargs)
torch.package.package_importer.Directory(name: str, is_dir: bool)
torch.package.package_importer.DirectoryReader(directory)
torch.package.package_importer.Importer()
torch.package.package_importer.Iterable(*args, **kwargs)
torch.package.package_importer.List(*args, **kwargs)
torch.package.package_importer.Optional(*args, **kwds)
torch.package.package_importer.PackageImporter(file_or_buffer: Union[str, torch.PyTorchFileReader, os.PathLike, BinaryIO], module_allowed: Callable[[str], bool] = <function PackageImporter.<lambda> at 0x0000024A61368670>)
torch.package.package_importer.PackageMangler()
torch.package.package_importer.PackageUnpickler(importer: torch.package.importer.Importer, *args, **kwargs)
torch.package.package_importer.Union(*args, **kwds)
torch.package.package_importer.WeakValueDictionary(other=(), /, **kw)
torch.package.package_importer.cast(typ, val)
torch.package.package_importer.contextmanager(func)
torch.package.package_importer.demangle(name: str) -> str
torch.pca_lowrank(A: torch.Tensor, q: Optional[int] = None, center: bool = True, niter: int = 2) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]
torch.prepare_multiprocessing_environment(path: str) -> None
torch.profiler.ExecutionTraceObserver()
torch.profiler.KinetoStepTracker()
torch.profiler.ProfilerAction(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.profiler.itt.contextmanager(func)
torch.profiler.itt.is_available()
torch.profiler.itt.mark(msg)
torch.profiler.itt.range(msg, *args, **kwargs)
torch.profiler.itt.range_pop()
torch.profiler.itt.range_push(msg)
torch.profiler.profile(*, activities: Optional[Iterable[torch._C._profiler.ProfilerActivity]] = None, schedule: Optional[Callable[[int], torch.profiler.profiler.ProfilerAction]] = None, on_trace_ready: Optional[Callable[..., Any]] = None, record_shapes: bool = False, profile_memory: bool = False, with_stack: bool = False, with_flops: bool = False, with_modules: bool = False, experimental_config: Optional[torch._C._profiler._ExperimentalConfig] = None, execution_trace_observer: Optional[torch.profiler.profiler._ITraceObserver] = None, use_cuda: Optional[bool] = None)
torch.profiler.profiler.ABC()
torch.profiler.profiler.Any(*args, **kwds)
torch.profiler.profiler.Callable(*args, **kwargs)
torch.profiler.profiler.Dict(*args, **kwargs)
torch.profiler.profiler.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.profiler.profiler.ExecutionTraceObserver()
torch.profiler.profiler.Iterable(*args, **kwargs)
torch.profiler.profiler.List(*args, **kwargs)
torch.profiler.profiler.MemoryProfile(result: torch._C._autograd._ProfilerResult) -> None
torch.profiler.profiler.MemoryProfileTimeline(memory_profile)
torch.profiler.profiler.Optional(*args, **kwds)
torch.profiler.profiler.ProfilerAction(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.profiler.profiler.Self(*args, **kwds)
torch.profiler.profiler.Tuple(*args, **kwargs)
torch.profiler.profiler.abstractmethod(funcobj)
torch.profiler.profiler.profile(*, activities: Optional[Iterable[torch._C._profiler.ProfilerActivity]] = None, schedule: Optional[Callable[[int], torch.profiler.profiler.ProfilerAction]] = None, on_trace_ready: Optional[Callable[..., Any]] = None, record_shapes: bool = False, profile_memory: bool = False, with_stack: bool = False, with_flops: bool = False, with_modules: bool = False, experimental_config: Optional[torch._C._profiler._ExperimentalConfig] = None, execution_trace_observer: Optional[torch.profiler.profiler._ITraceObserver] = None, use_cuda: Optional[bool] = None)
torch.profiler.profiler.schedule(*, wait: int, warmup: int, active: int, repeat: int = 0, skip_first: int = 0) -> Callable
torch.profiler.profiler.supported_activities()
torch.profiler.profiler.tensorboard_trace_handler(dir_name: str, worker_name: Optional[str] = None, use_gzip: bool = False)
torch.profiler.profiler.warn(message, category=None, stacklevel=1, source=None)
torch.profiler.record_function(name: str, args: Optional[str] = None)
torch.profiler.register_optimizer_step_post_hook(hook: Callable[[ForwardRef('Optimizer'), Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle
torch.profiler.schedule(*, wait: int, warmup: int, active: int, repeat: int = 0, skip_first: int = 0) -> Callable
torch.profiler.supported_activities()
torch.profiler.tensorboard_trace_handler(dir_name: str, worker_name: Optional[str] = None, use_gzip: bool = False)
torch.py_float(x=0, /)
torch.qscheme()
torch.quantization.ABC()
torch.quantization.DeQuantStub(qconfig=None)
torch.quantization.FakeQuantize(observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=None, quant_max=None, is_dynamic=False, **observer_kwargs)
torch.quantization.FakeQuantizeBase()
torch.quantization.FixedQParamsFakeQuantize(observer)
torch.quantization.FusedMovingAvgObsFakeQuantize(observer: Any = <class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min: int = 0, quant_max: int = 255, **observer_kwargs: Any) -> None
torch.quantization.HistogramObserver(bins: int = 2048, upsample_rate: int = 128, dtype: torch.dtype = torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.MinMaxObserver(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01, ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.NoopObserver(dtype=torch.float16, custom_op_name='') -> None
torch.quantization.ObserverBase(dtype, is_dynamic=False)
torch.quantization.PerChannelMinMaxObserver(ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.PlaceholderObserver(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.quantization.QConfig(activation, weight)
torch.quantization.QConfigAny(*args, **kwargs)
torch.quantization.QConfigDynamic(activation=<class 'torch.nn.modules.linear.Identity'>, weight=<class 'torch.nn.modules.linear.Identity'>)
torch.quantization.QuantStub(qconfig=None)
torch.quantization.QuantType(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.quantization.QuantWrapper(module)
torch.quantization.RecordingObserver(dtype=torch.quint8)
torch.quantization.add_quant_dequant(module)
torch.quantization.convert(module, mapping=None, inplace=False, remove_qconfig=True, is_reference=False, convert_custom_config_dict=None, use_precomputed_fake_quant=False)
torch.quantization.convert_dynamic_jit(model, inplace=False, debug=False, preserved_attrs=None)
torch.quantization.convert_jit(model, inplace=False, debug=False, preserved_attrs=None)
torch.quantization.default_debug_observer(dtype=torch.quint8)
torch.quantization.default_dynamic_quant_observer(*args, **keywords)
torch.quantization.default_eval_fn(model, calib_data)
torch.quantization.default_fake_quant(*args, **keywords)
torch.quantization.default_fixed_qparams_range_0to1_fake_quant(*args, **keywords)
torch.quantization.default_fixed_qparams_range_neg1to1_fake_quant(*args, **keywords)
torch.quantization.default_float_qparams_observer(*args, **keywords)
torch.quantization.default_fused_act_fake_quant(*args, **keywords)
torch.quantization.default_fused_per_channel_wt_fake_quant(*args, **keywords)
torch.quantization.default_fused_wt_fake_quant(*args, **keywords)
torch.quantization.default_histogram_fake_quant(*args, **keywords)
torch.quantization.default_histogram_observer(*args, **keywords)
torch.quantization.default_observer(*args, **keywords)
torch.quantization.default_per_channel_weight_fake_quant(*args, **keywords)
torch.quantization.default_per_channel_weight_observer(*args, **keywords)
torch.quantization.default_placeholder_observer(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.quantization.default_weight_fake_quant(*args, **keywords)
torch.quantization.default_weight_observer(*args, **keywords)
torch.quantization.disable_fake_quant(mod)
torch.quantization.disable_observer(mod)
torch.quantization.enable_fake_quant(mod)
torch.quantization.enable_observer(mod)
torch.quantization.fake_quantize.FakeQuantize(observer=<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=None, quant_max=None, is_dynamic=False, **observer_kwargs)
torch.quantization.fake_quantize.FakeQuantizeBase()
torch.quantization.fake_quantize.FixedQParamsFakeQuantize(observer)
torch.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize(observer: Any = <class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min: int = 0, quant_max: int = 255, **observer_kwargs: Any) -> None
torch.quantization.fake_quantize.default_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_fixed_qparams_range_0to1_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_fixed_qparams_range_neg1to1_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_fused_act_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_fused_wt_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_histogram_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_per_channel_weight_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.default_weight_fake_quant(*args, **keywords)
torch.quantization.fake_quantize.disable_fake_quant(mod)
torch.quantization.fake_quantize.disable_observer(mod)
torch.quantization.fake_quantize.enable_fake_quant(mod)
torch.quantization.fake_quantize.enable_observer(mod)
torch.quantization.fuse_conv_bn(is_qat, conv, bn)
torch.quantization.fuse_conv_bn_jit(model, inplace=False)
torch.quantization.fuse_conv_bn_relu(is_qat, conv, bn, relu)
torch.quantization.fuse_linear_bn(is_qat, linear, bn)
torch.quantization.fuse_modules(model, modules_to_fuse, inplace=False, fuser_func=<function fuse_known_modules at 0x0000024A61D5B1C0>, fuse_custom_config_dict=None)
torch.quantization.fuser_method_mappings.fuse_conv_bn(is_qat, conv, bn)
torch.quantization.fuser_method_mappings.fuse_conv_bn_relu(is_qat, conv, bn, relu)
torch.quantization.fuser_method_mappings.fuse_linear_bn(is_qat, linear, bn)
torch.quantization.fuser_method_mappings.get_fuser_method(op_list, additional_fuser_method_mapping=None)
torch.quantization.get_default_compare_output_module_list() -> Set[Callable]
torch.quantization.get_default_dynamic_quant_module_mappings() -> Dict[Callable, Any]
torch.quantization.get_default_float_to_quantized_operator_mappings() -> Dict[Union[Callable, str], Callable]
torch.quantization.get_default_qat_module_mappings() -> Dict[Callable, Any]
torch.quantization.get_default_qat_qconfig(backend='x86', version=1)
torch.quantization.get_default_qconfig(backend='x86', version=0)
torch.quantization.get_default_qconfig_propagation_list() -> Set[Callable]
torch.quantization.get_default_static_quant_module_mappings() -> Dict[Callable, Any]
torch.quantization.get_dynamic_quant_module_class(float_module_class: Callable, additional_dynamic_quant_mapping: Optional[Dict[Callable, Any]] = None) -> Any
torch.quantization.get_fuser_method(op_list, additional_fuser_method_mapping=None)
torch.quantization.get_observer_state_dict(mod)
torch.quantization.get_quantized_operator(float_op: Union[Callable, str]) -> Callable
torch.quantization.get_static_quant_module_class(float_module_class: Callable, additional_static_quant_mapping: Optional[Dict[Callable, Any]] = None, is_reference: bool = False) -> Any
torch.quantization.load_observer_state_dict(mod, obs_dict)
torch.quantization.no_observer_set() -> Set[Any]
torch.quantization.observer.ABC()
torch.quantization.observer.HistogramObserver(bins: int = 2048, upsample_rate: int = 128, dtype: torch.dtype = torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.observer.MinMaxObserver(dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.observer.MovingAverageMinMaxObserver(averaging_constant=0.01, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.observer.MovingAveragePerChannelMinMaxObserver(averaging_constant=0.01, ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.observer.NoopObserver(dtype=torch.float16, custom_op_name='') -> None
torch.quantization.observer.ObserverBase(dtype, is_dynamic=False)
torch.quantization.observer.PerChannelMinMaxObserver(ch_axis=0, dtype=torch.quint8, qscheme=torch.per_channel_affine, reduce_range=False, quant_min=None, quant_max=None, factory_kwargs=None, eps=1.1920928955078125e-07, is_dynamic=False, **kwargs) -> None
torch.quantization.observer.PlaceholderObserver(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.quantization.observer.RecordingObserver(dtype=torch.quint8)
torch.quantization.observer.default_debug_observer(dtype=torch.quint8)
torch.quantization.observer.default_dynamic_quant_observer(*args, **keywords)
torch.quantization.observer.default_float_qparams_observer(*args, **keywords)
torch.quantization.observer.default_histogram_observer(*args, **keywords)
torch.quantization.observer.default_observer(*args, **keywords)
torch.quantization.observer.default_per_channel_weight_observer(*args, **keywords)
torch.quantization.observer.default_placeholder_observer(dtype=torch.float32, custom_op_name='', compute_dtype=None, quant_min=None, quant_max=None, qscheme=None, eps=None, is_dynamic=False) -> None
torch.quantization.observer.default_weight_observer(*args, **keywords)
torch.quantization.observer.get_observer_state_dict(mod)
torch.quantization.observer.load_observer_state_dict(mod, obs_dict)
torch.quantization.prepare(model, inplace=False, allow_list=None, observer_non_leaf_module_list=None, prepare_custom_config_dict=None)
torch.quantization.prepare_dynamic_jit(model, qconfig_dict, inplace=False)
torch.quantization.prepare_jit(model, qconfig_dict, inplace=False)
torch.quantization.prepare_qat(model, mapping=None, inplace=False)
torch.quantization.propagate_qconfig_(module, qconfig_dict=None, prepare_custom_config_dict=None)
torch.quantization.qconfig.QConfig(activation, weight)
torch.quantization.qconfig.QConfigAny(*args, **kwargs)
torch.quantization.qconfig.QConfigDynamic(activation=<class 'torch.nn.modules.linear.Identity'>, weight=<class 'torch.nn.modules.linear.Identity'>)
torch.quantization.qconfig.get_default_qat_qconfig(backend='x86', version=1)
torch.quantization.qconfig.get_default_qconfig(backend='x86', version=0)
torch.quantization.qconfig.qconfig_equals(q1: typing.Optional[torch.ao.quantization.qconfig.QConfig], q2: typing.Optional[torch.ao.quantization.qconfig.QConfig])
torch.quantization.qconfig_equals(q1: typing.Optional[torch.ao.quantization.qconfig.QConfig], q2: typing.Optional[torch.ao.quantization.qconfig.QConfig])
torch.quantization.quant_type.QuantType(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.quantization.quantization_mappings.get_default_compare_output_module_list() -> Set[Callable]
torch.quantization.quantization_mappings.get_default_dynamic_quant_module_mappings() -> Dict[Callable, Any]
torch.quantization.quantization_mappings.get_default_float_to_quantized_operator_mappings() -> Dict[Union[Callable, str], Callable]
torch.quantization.quantization_mappings.get_default_qat_module_mappings() -> Dict[Callable, Any]
torch.quantization.quantization_mappings.get_default_qconfig_propagation_list() -> Set[Callable]
torch.quantization.quantization_mappings.get_default_static_quant_module_mappings() -> Dict[Callable, Any]
torch.quantization.quantization_mappings.get_dynamic_quant_module_class(float_module_class: Callable, additional_dynamic_quant_mapping: Optional[Dict[Callable, Any]] = None) -> Any
torch.quantization.quantization_mappings.get_quantized_operator(float_op: Union[Callable, str]) -> Callable
torch.quantization.quantization_mappings.get_static_quant_module_class(float_module_class: Callable, additional_static_quant_mapping: Optional[Dict[Callable, Any]] = None, is_reference: bool = False) -> Any
torch.quantization.quantization_mappings.no_observer_set() -> Set[Any]
torch.quantization.quantize(model, run_fn, run_args, mapping=None, inplace=False)
torch.quantization.quantize_dynamic(model, qconfig_spec=None, dtype=torch.qint8, mapping=None, inplace=False)
torch.quantization.quantize_dynamic_jit(model, qconfig_dict, inplace=False, debug=False)
torch.quantization.quantize_jit(model, qconfig_dict, run_fn, run_args, inplace=False, debug=False)
torch.quantization.quantize_qat(model, run_fn, run_args, inplace=False)
torch.quantization.script_qconfig(qconfig)
torch.quantization.script_qconfig_dict(qconfig_dict)
torch.quantization.stubs.DeQuantStub(qconfig=None)
torch.quantization.stubs.QuantStub(qconfig=None)
torch.quantization.stubs.QuantWrapper(module)
torch.quantization.swap_module(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant=False)
torch.quantized_gru(*args, **kwargs)
torch.quantized_lstm(*args, **kwargs)
torch.quasirandom.Optional(*args, **kwds)
torch.quasirandom.SobolEngine(dimension, scramble=False, seed=None)
torch.return_types.SequenceKey(idx: int) -> None
torch.return_types.aminmax(iterable=(), /)
torch.return_types.aminmax_out(iterable=(), /)
torch.return_types.cummax(iterable=(), /)
torch.return_types.cummax_out(iterable=(), /)
torch.return_types.cummin(iterable=(), /)
torch.return_types.cummin_out(iterable=(), /)
torch.return_types.frexp(iterable=(), /)
torch.return_types.frexp_out(iterable=(), /)
torch.return_types.geqrf(iterable=(), /)
torch.return_types.geqrf_out(iterable=(), /)
torch.return_types.histogram(iterable=(), /)
torch.return_types.histogram_out(iterable=(), /)
torch.return_types.histogramdd(iterable=(), /)
torch.return_types.kthvalue(iterable=(), /)
torch.return_types.kthvalue_out(iterable=(), /)
torch.return_types.linalg_cholesky_ex(iterable=(), /)
torch.return_types.linalg_cholesky_ex_out(iterable=(), /)
torch.return_types.linalg_eig(iterable=(), /)
torch.return_types.linalg_eig_out(iterable=(), /)
torch.return_types.linalg_eigh(iterable=(), /)
torch.return_types.linalg_eigh_out(iterable=(), /)
torch.return_types.linalg_inv_ex(iterable=(), /)
torch.return_types.linalg_inv_ex_out(iterable=(), /)
torch.return_types.linalg_ldl_factor(iterable=(), /)
torch.return_types.linalg_ldl_factor_ex(iterable=(), /)
torch.return_types.linalg_ldl_factor_ex_out(iterable=(), /)
torch.return_types.linalg_ldl_factor_out(iterable=(), /)
torch.return_types.linalg_lstsq(iterable=(), /)
torch.return_types.linalg_lstsq_out(iterable=(), /)
torch.return_types.linalg_lu(iterable=(), /)
torch.return_types.linalg_lu_factor(iterable=(), /)
torch.return_types.linalg_lu_factor_ex(iterable=(), /)
torch.return_types.linalg_lu_factor_ex_out(iterable=(), /)
torch.return_types.linalg_lu_factor_out(iterable=(), /)
torch.return_types.linalg_lu_out(iterable=(), /)
torch.return_types.linalg_qr(iterable=(), /)
torch.return_types.linalg_qr_out(iterable=(), /)
torch.return_types.linalg_slogdet(iterable=(), /)
torch.return_types.linalg_slogdet_out(iterable=(), /)
torch.return_types.linalg_solve_ex(iterable=(), /)
torch.return_types.linalg_solve_ex_out(iterable=(), /)
torch.return_types.linalg_svd(iterable=(), /)
torch.return_types.linalg_svd_out(iterable=(), /)
torch.return_types.lu_unpack(iterable=(), /)
torch.return_types.lu_unpack_out(iterable=(), /)
torch.return_types.max(iterable=(), /)
torch.return_types.max_out(iterable=(), /)
torch.return_types.median(iterable=(), /)
torch.return_types.median_out(iterable=(), /)
torch.return_types.min(iterable=(), /)
torch.return_types.min_out(iterable=(), /)
torch.return_types.mode(iterable=(), /)
torch.return_types.mode_out(iterable=(), /)
torch.return_types.nanmedian(iterable=(), /)
torch.return_types.nanmedian_out(iterable=(), /)
torch.return_types.pytree_register_structseq(cls)
torch.return_types.qr(iterable=(), /)
torch.return_types.qr_out(iterable=(), /)
torch.return_types.register_pytree_node(cls: Type[Any], flatten_fn: Callable[[Any], Tuple[List[Any], Any]], unflatten_fn: Callable[[Iterable[Any], Any], Any], *, serialized_type_name: Optional[str] = None, to_dumpable_context: Optional[Callable[[Any], Any]] = None, from_dumpable_context: Optional[Callable[[Any], Any]] = None, flatten_with_keys_fn: Optional[Callable[[Any], Tuple[List[Tuple[torch.utils._pytree.KeyEntry, Any]], Any]]] = None) -> None
torch.return_types.slogdet(iterable=(), /)
torch.return_types.slogdet_out(iterable=(), /)
torch.return_types.sort(iterable=(), /)
torch.return_types.sort_out(iterable=(), /)
torch.return_types.svd(iterable=(), /)
torch.return_types.svd_out(iterable=(), /)
torch.return_types.topk(iterable=(), /)
torch.return_types.topk_out(iterable=(), /)
torch.return_types.triangular_solve(iterable=(), /)
torch.return_types.triangular_solve_out(iterable=(), /)
torch.save(obj: object, f: Union[str, os.PathLike, BinaryIO, IO[bytes]], pickle_module: Any = <module 'pickle' from 'C:\\Users\\Hung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py'>, pickle_protocol: int = 2, _use_new_zipfile_serialization: bool = True, _disable_byteorder_record: bool = False) -> None
torch.seed() -> int
torch.serialization.Any(*args, **kwds)
torch.serialization.BinaryIO()
torch.serialization.Callable(*args, **kwargs)
torch.serialization.Dict(*args, **kwargs)
torch.serialization.Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.serialization.FILE_LIKE(*args, **kwargs)
torch.serialization.IO()
torch.serialization.List(*args, **kwargs)
torch.serialization.LoadEndianness(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.serialization.MAP_LOCATION(*args, **kwargs)
torch.serialization.Optional(*args, **kwds)
torch.serialization.STORAGE(*args, **kwargs)
torch.serialization.Storage()
torch.serialization.StorageType(name)
torch.serialization.Tuple(*args, **kwargs)
torch.serialization.Type(*args, **kwargs)
torch.serialization.TypeAlias(*args, **kwds)
torch.serialization.TypeGuard(*args, **kwds)
torch.serialization.Union(*args, **kwds)
torch.serialization.add_safe_globals(safe_globals: List[Any]) -> None
torch.serialization.cast(typ, val)
torch.serialization.check_module_version_greater_or_equal(module, req_version_tuple, error_if_malformed=True)
torch.serialization.clear_safe_globals() -> None
torch.serialization.closing(thing)
torch.serialization.contextmanager(func)
torch.serialization.default_restore_location(storage, location)
torch.serialization.get_default_load_endianness() -> Optional[torch.serialization.LoadEndianness]
torch.serialization.get_default_mmap_options() -> int
torch.serialization.get_safe_globals() -> List[Any]
torch.serialization.get_source_lines_and_file(obj: Any, error_msg: Optional[str] = None) -> Tuple[List[str], int, Optional[str]]
torch.serialization.load(f: Union[str, os.PathLike, BinaryIO, IO[bytes]], map_location: Union[Callable[[torch.types.Storage, str], torch.types.Storage], torch.device, str, Dict[str, str], NoneType] = None, pickle_module: Any = None, *, weights_only: Optional[bool] = None, mmap: Optional[bool] = None, **pickle_load_args: Any) -> Any
torch.serialization.location_tag(storage: Union[torch.types.Storage, torch.storage.TypedStorage, torch.storage.UntypedStorage])
torch.serialization.mkdtemp()
torch.serialization.normalize_storage_type(storage_type)
torch.serialization.register_package(priority: int, tagger: Callable[[Union[torch.types.Storage, torch.storage.TypedStorage, torch.storage.UntypedStorage]], Optional[str]], deserializer: Callable[[Union[torch.types.Storage, torch.storage.TypedStorage, torch.storage.UntypedStorage], str], Union[torch.types.Storage, torch.storage.TypedStorage, torch.storage.UntypedStorage, NoneType]])
torch.serialization.save(obj: object, f: Union[str, os.PathLike, BinaryIO, IO[bytes]], pickle_module: Any = <module 'pickle' from 'C:\\Users\\Hung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py'>, pickle_protocol: int = 2, _use_new_zipfile_serialization: bool = True, _disable_byteorder_record: bool = False) -> None
torch.serialization.set_default_load_endianness(endianness)
torch.serialization.set_default_mmap_options(flags: int)
torch.serialization.storage_to_tensor_type(storage)
torch.serialization.validate_cuda_device(location)
torch.serialization.validate_hpu_device(location)
torch.set_default_device(device)
torch.set_default_dtype(d)
torch.set_default_tensor_type(t)
torch.set_deterministic_debug_mode(debug_mode: Union[int, str]) -> None
torch.set_float32_matmul_precision(precision: str) -> None
torch.set_grad_enabled(mode: bool) -> None
torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)
torch.set_rng_state(new_state: torch.Tensor) -> None
torch.set_warn_always(b: bool) -> None
torch.solve(input: torch.Tensor, A: torch.Tensor, *, out=None) -> Tuple[torch.Tensor, torch.Tensor]
torch.sparse.Any(*args, **kwds)
torch.sparse.DimOrDims(*args, **kwargs)
torch.sparse.List(*args, **kwargs)
torch.sparse.Optional(*args, **kwds)
torch.sparse.SparseSemiStructuredTensor(shape: torch.Size, packed: Optional[torch.Tensor], meta: Optional[torch.Tensor], packed_t: Optional[torch.Tensor], meta_t: Optional[torch.Tensor], compressed_swizzled_bitmask: Optional[torch.Tensor], fuse_transpose_cusparselt: bool = False, alg_id_cusparselt: int = 0, requires_grad: bool = False)
torch.sparse.SparseSemiStructuredTensorCUSPARSELT(shape: torch.Size, packed: Optional[torch.Tensor], meta: Optional[torch.Tensor], packed_t: Optional[torch.Tensor], meta_t: Optional[torch.Tensor], compressed_swizzled_bitmask: Optional[torch.Tensor], fuse_transpose_cusparselt: bool = False, alg_id_cusparselt: int = 0, requires_grad: bool = False)
torch.sparse.SparseSemiStructuredTensorCUTLASS(shape: torch.Size, packed: Optional[torch.Tensor], meta: Optional[torch.Tensor], packed_t: Optional[torch.Tensor], meta_t: Optional[torch.Tensor], compressed_swizzled_bitmask: Optional[torch.Tensor], fuse_transpose_cusparselt: bool = False, alg_id_cusparselt: int = 0, requires_grad: bool = False)
torch.sparse.Tuple(*args, **kwargs)
torch.sparse.Union(*args, **kwds)
torch.sparse.as_sparse_gradcheck(gradcheck)
torch.sparse.check_sparse_tensor_invariants(enable=True)
torch.sparse.semi_structured.Any(*args, **kwds)
torch.sparse.semi_structured.Callable(*args, **kwargs)
torch.sparse.semi_structured.Dict(*args, **kwargs)
torch.sparse.semi_structured.List(*args, **kwargs)
torch.sparse.semi_structured.Optional(*args, **kwds)
torch.sparse.semi_structured.SparseSemiStructuredTensor(shape: torch.Size, packed: Optional[torch.Tensor], meta: Optional[torch.Tensor], packed_t: Optional[torch.Tensor], meta_t: Optional[torch.Tensor], compressed_swizzled_bitmask: Optional[torch.Tensor], fuse_transpose_cusparselt: bool = False, alg_id_cusparselt: int = 0, requires_grad: bool = False)
torch.sparse.semi_structured.SparseSemiStructuredTensorCUSPARSELT(shape: torch.Size, packed: Optional[torch.Tensor], meta: Optional[torch.Tensor], packed_t: Optional[torch.Tensor], meta_t: Optional[torch.Tensor], compressed_swizzled_bitmask: Optional[torch.Tensor], fuse_transpose_cusparselt: bool = False, alg_id_cusparselt: int = 0, requires_grad: bool = False)
torch.sparse.semi_structured.SparseSemiStructuredTensorCUTLASS(shape: torch.Size, packed: Optional[torch.Tensor], meta: Optional[torch.Tensor], packed_t: Optional[torch.Tensor], meta_t: Optional[torch.Tensor], compressed_swizzled_bitmask: Optional[torch.Tensor], fuse_transpose_cusparselt: bool = False, alg_id_cusparselt: int = 0, requires_grad: bool = False)
torch.sparse.semi_structured.Tuple(*args, **kwargs)
torch.sparse.semi_structured.fallback_dispatcher(func, types, args, kwargs)
torch.sparse.semi_structured.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.sparse.semi_structured.semi_sparse_addmm(func, types, args=(), kwargs=None) -> torch.Tensor
torch.sparse.semi_structured.semi_sparse_detach(func, types, args, kwargs) -> torch.Tensor
torch.sparse.semi_structured.semi_sparse_indices(func, types, args=(), kwargs=None) -> torch.Tensor
torch.sparse.semi_structured.semi_sparse_linear(func, types, args=(), kwargs=None) -> torch.Tensor
torch.sparse.semi_structured.semi_sparse_mm(func, types, args=(), kwargs=None) -> torch.Tensor
torch.sparse.semi_structured.semi_sparse_t(func, types, args=(), kwargs=None) -> torch.Tensor
torch.sparse.semi_structured.semi_sparse_values(func, types, args=(), kwargs=None) -> torch.Tensor
torch.sparse.semi_structured.semi_sparse_view(func, types, args=(), kwargs=None) -> torch.Tensor
torch.sparse.semi_structured.sparse_semi_structured_from_dense_cutlass(dense)
torch.sparse.semi_structured.sparse_semi_structured_to_dense_cutlass(sparse, meta_reordered)
torch.sparse.semi_structured.to_sparse_semi_structured(original_tensor: torch.Tensor, transposed: bool = False) -> torch.sparse.semi_structured.SparseSemiStructuredTensor
torch.sparse.sum(input: torch.Tensor, dim: Optional[Tuple[int]] = None, dtype: Optional[int] = None) -> torch.Tensor
torch.sparse.to_sparse_semi_structured(original_tensor: torch.Tensor, transposed: bool = False) -> torch.sparse.semi_structured.SparseSemiStructuredTensor
torch.split(tensor: torch.Tensor, split_size_or_sections: Union[int, List[int]], dim: int = 0) -> Tuple[torch.Tensor, ...]
torch.stft(input: torch.Tensor, n_fft: int, hop_length: Optional[int] = None, win_length: Optional[int] = None, window: Optional[torch.Tensor] = None, center: bool = True, pad_mode: str = 'reflect', normalized: bool = False, onesided: Optional[bool] = None, return_complex: Optional[bool] = None) -> torch.Tensor
torch.storage.Any(*args, **kwds)
torch.storage.Storage()
torch.storage.Type(*args, **kwargs)
torch.storage.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.storage.TypedStorage(*args, wrap_storage=None, dtype=None, device=None, _internal=False)
torch.storage.Union(*args, **kwds)
torch.storage.UntypedStorage(*args, **kwargs)
torch.storage.cast(typ, val)
torch.storage.lru_cache(maxsize=128, typed=False)
torch.svd_lowrank(A: torch.Tensor, q: Optional[int] = 6, niter: Optional[int] = 2, M: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]
torch.sym_float(a)
torch.sym_int(a)
torch.sym_ite(b, t, f)
torch.sym_max(a, b)
torch.sym_min(a, b)
torch.sym_not(a)
torch.sym_sqrt(a)
torch.symeig(input, eigenvectors=False, upper=True, *, out=None) -> Tuple[torch.Tensor, torch.Tensor]
torch.tensordot(a, b, dims=2, out: Optional[torch.Tensor] = None)
torch.torch_version.Any(*args, **kwds)
torch.torch_version.Iterable(*args, **kwargs)
torch.torch_version.Version(version: str) -> None
torch.typename(o)
torch.unique(*args, **kwargs)
torch.unique_consecutive(*args, **kwargs)
torch.unravel_index(indices: torch.Tensor, shape: Union[int, Sequence[int], torch.Size]) -> Tuple[torch.Tensor, ...]
torch.use_deterministic_algorithms(mode: bool, *, warn_only: bool = False) -> None
torch.utils.ThroughputBenchmark(module)
torch.utils.backcompat.Warning(setter, getter)
torch.utils.backend_registration.List(*args, **kwargs)
torch.utils.backend_registration.Optional(*args, **kwds)
torch.utils.backend_registration.Union(*args, **kwds)
torch.utils.backend_registration.generate_methods_for_privateuse1_backend(for_tensor: bool = True, for_module: bool = True, for_packed_sequence: bool = True, for_storage: bool = False, unsupported_dtype: Optional[List[torch.dtype]] = None) -> None
torch.utils.backend_registration.handle_torch_function(public_api: Callable, relevant_args: Iterable[Any], *args, **kwargs) -> Any
torch.utils.backend_registration.rename_privateuse1_backend(backend_name: str) -> None
torch.utils.collect_env.SystemEnv(torch_version, is_debug_build, cuda_compiled_version, gcc_version, clang_version, cmake_version, os, libc_version, python_version, python_platform, is_cuda_available, cuda_runtime_version, cuda_module_loading, nvidia_driver_version, nvidia_gpu_models, cudnn_version, pip_version, pip_packages, conda_packages, hip_compiled_version, hip_runtime_version, miopen_runtime_version, caching_allocator_config, is_xnnpack_available, cpu_info)
torch.utils.collect_env.check_release_file(run_lambda)
torch.utils.collect_env.get_cachingallocator_config()
torch.utils.collect_env.get_clang_version(run_lambda)
torch.utils.collect_env.get_cmake_version(run_lambda)
torch.utils.collect_env.get_conda_packages(run_lambda, patterns=None)
torch.utils.collect_env.get_cpu_info(run_lambda)
torch.utils.collect_env.get_cuda_module_loading_config()
torch.utils.collect_env.get_cudnn_version(run_lambda)
torch.utils.collect_env.get_env_info()
torch.utils.collect_env.get_gcc_version(run_lambda)
torch.utils.collect_env.get_gpu_info(run_lambda)
torch.utils.collect_env.get_libc_version()
torch.utils.collect_env.get_lsb_version(run_lambda)
torch.utils.collect_env.get_mac_version(run_lambda)
torch.utils.collect_env.get_nvidia_driver_version(run_lambda)
torch.utils.collect_env.get_nvidia_smi()
torch.utils.collect_env.get_os(run_lambda)
torch.utils.collect_env.get_pip_packages(run_lambda, patterns=None)
torch.utils.collect_env.get_platform()
torch.utils.collect_env.get_pretty_env_info()
torch.utils.collect_env.get_python_platform()
torch.utils.collect_env.get_running_cuda_version(run_lambda)
torch.utils.collect_env.get_windows_version(run_lambda)
torch.utils.collect_env.is_xnnpack_available()
torch.utils.collect_env.main()
torch.utils.collect_env.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.utils.collect_env.pretty_str(envinfo)
torch.utils.collect_env.run(command)
torch.utils.collect_env.run_and_parse_first_match(run_lambda, command, regex)
torch.utils.collect_env.run_and_read_all(run_lambda, command)
torch.utils.collect_env.run_and_return_first_line(run_lambda, command)
torch.utils.cpp_backtrace.get_cpp_backtrace(frames_to_skip=0, maximum_number_of_frames=64) -> str
torch.utils.data.BatchSampler(sampler: Union[torch.utils.data.sampler.Sampler[int], Iterable[int]], batch_size: int, drop_last: bool) -> None
torch.utils.data.ChainDataset(datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None
torch.utils.data.ConcatDataset(datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None
torch.utils.data.DFIterDataPipe()
torch.utils.data.DataChunk(items)
torch.utils.data.DataLoader(dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')
torch.utils.data.Dataset()
torch.utils.data.DistributedSampler(dataset: torch.utils.data.dataset.Dataset, num_replicas: Optional[int] = None, rank: Optional[int] = None, shuffle: bool = True, seed: int = 0, drop_last: bool = False) -> None
torch.utils.data.IterDataPipe()
torch.utils.data.IterableDataset()
torch.utils.data.MapDataPipe()
torch.utils.data.RandomSampler(data_source: Sized, replacement: bool = False, num_samples: Optional[int] = None, generator=None) -> None
torch.utils.data.Sampler(data_source: Optional[Sized] = None) -> None
torch.utils.data.SequentialSampler(data_source: Sized) -> None
torch.utils.data.StackDataset(*args: torch.utils.data.dataset.Dataset[+T_co], **kwargs: torch.utils.data.dataset.Dataset[+T_co]) -> None
torch.utils.data.Subset(dataset: torch.utils.data.dataset.Dataset[+T_co], indices: Sequence[int]) -> None
torch.utils.data.SubsetRandomSampler(indices: Sequence[int], generator=None) -> None
torch.utils.data.TensorDataset(*tensors: torch.Tensor) -> None
torch.utils.data.WeightedRandomSampler(weights: Sequence[float], num_samples: int, replacement: bool = True, generator=None) -> None
torch.utils.data.argument_validation(f)
torch.utils.data.dataloader.Any(*args, **kwds)
torch.utils.data.dataloader.BatchSampler(sampler: Union[torch.utils.data.sampler.Sampler[int], Iterable[int]], batch_size: int, drop_last: bool) -> None
torch.utils.data.dataloader.Callable(*args, **kwargs)
torch.utils.data.dataloader.DataLoader(dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Optional[int] = 1, shuffle: Optional[bool] = None, sampler: Union[torch.utils.data.sampler.Sampler, Iterable, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[List], Iterable[List], NoneType] = None, num_workers: int = 0, collate_fn: Optional[Callable[[List[~T]], Any]] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Optional[Callable[[int], NoneType]] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: Optional[int] = None, persistent_workers: bool = False, pin_memory_device: str = '')
torch.utils.data.dataloader.Dataset()
torch.utils.data.dataloader.ExceptionWrapper(exc_info=None, where='in background')
torch.utils.data.dataloader.Generic()
torch.utils.data.dataloader.IterDataPipe()
torch.utils.data.dataloader.Iterable(*args, **kwargs)
torch.utils.data.dataloader.IterableDataset()
torch.utils.data.dataloader.List(*args, **kwargs)
torch.utils.data.dataloader.MapDataPipe()
torch.utils.data.dataloader.Optional(*args, **kwds)
torch.utils.data.dataloader.RandomSampler(data_source: Sized, replacement: bool = False, num_samples: Optional[int] = None, generator=None) -> None
torch.utils.data.dataloader.Sampler(data_source: Optional[Sized] = None) -> None
torch.utils.data.dataloader.SequentialSampler(data_source: Sized) -> None
torch.utils.data.dataloader.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.dataloader.Union(*args, **kwds)
torch.utils.data.dataloader.default_collate(batch)
torch.utils.data.dataloader.default_convert(data)
torch.utils.data.dataloader.get_worker_info() -> Optional[torch.utils.data._utils.worker.WorkerInfo]
torch.utils.data.datapipes.dataframe.CaptureDataFrame(schema_df=None)
torch.utils.data.datapipes.dataframe.DFIterDataPipe()
torch.utils.data.datapipes.dataframe.DataFramesAsTuplesPipe(source_datapipe)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.Any(*args, **kwds)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.Optional(*args, **kwds)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.PandasWrapper()
torch.utils.data.datapipes.dataframe.dataframe_wrapper.concat(buffer)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.create_dataframe(data, columns=None)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.default_wrapper()
torch.utils.data.datapipes.dataframe.dataframe_wrapper.get_columns(data)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.get_df_wrapper()
torch.utils.data.datapipes.dataframe.dataframe_wrapper.get_item(data, idx)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.get_len(df)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.is_column(data)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.is_dataframe(data)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.iterate(data)
torch.utils.data.datapipes.dataframe.dataframe_wrapper.set_df_wrapper(wrapper)
torch.utils.data.datapipes.dataframe.dataframes.Any(*args, **kwds)
torch.utils.data.datapipes.dataframe.dataframes.Capture(schema_df=None)
torch.utils.data.datapipes.dataframe.dataframes.CaptureA(ctx=None, **kwargs)
torch.utils.data.datapipes.dataframe.dataframes.CaptureAdd(left, right, ctx)
torch.utils.data.datapipes.dataframe.dataframes.CaptureCall(callable, ctx=None, **kwargs)
torch.utils.data.datapipes.dataframe.dataframes.CaptureControl()
torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrame(schema_df=None)
torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrameWithDataPipeOps(schema_df=None)
torch.utils.data.datapipes.dataframe.dataframes.CaptureF(ctx=None, **kwargs)
torch.utils.data.datapipes.dataframe.dataframes.CaptureGetAttr(src, name, ctx)
torch.utils.data.datapipes.dataframe.dataframes.CaptureGetItem(left, key, ctx)
torch.utils.data.datapipes.dataframe.dataframes.CaptureInitial(schema_df=None)
torch.utils.data.datapipes.dataframe.dataframes.CaptureLikeMock(name)
torch.utils.data.datapipes.dataframe.dataframes.CaptureMul(left, right, ctx)
torch.utils.data.datapipes.dataframe.dataframes.CaptureSetItem(left, key, value, ctx)
torch.utils.data.datapipes.dataframe.dataframes.CaptureSub(left, right, ctx)
torch.utils.data.datapipes.dataframe.dataframes.CaptureVariable(value, ctx)
torch.utils.data.datapipes.dataframe.dataframes.CaptureVariableAssign(ctx=None, **kwargs)
torch.utils.data.datapipes.dataframe.dataframes.DFIterDataPipe()
torch.utils.data.datapipes.dataframe.dataframes.DataChunkDF(items)
torch.utils.data.datapipes.dataframe.dataframes.DataFrameTracedOps(source_datapipe, output_var)
torch.utils.data.datapipes.dataframe.dataframes.DataFrameTracer(source_datapipe, schema_df=None)
torch.utils.data.datapipes.dataframe.dataframes.Dict(*args, **kwargs)
torch.utils.data.datapipes.dataframe.dataframes.IterDataPipe()
torch.utils.data.datapipes.dataframe.dataframes.List(*args, **kwargs)
torch.utils.data.datapipes.dataframe.dataframes.Optional(*args, **kwds)
torch.utils.data.datapipes.dataframe.dataframes.disable_capture()
torch.utils.data.datapipes.dataframe.dataframes.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.dataframe.dataframes.get_val(capture)
torch.utils.data.datapipes.dataframe.datapipes.ConcatDataFramesPipe(source_datapipe, batch=3)
torch.utils.data.datapipes.dataframe.datapipes.DFIterDataPipe()
torch.utils.data.datapipes.dataframe.datapipes.DataFramesAsTuplesPipe(source_datapipe)
torch.utils.data.datapipes.dataframe.datapipes.ExampleAggregateAsDataFrames(source_datapipe, dataframe_size=10, columns=None)
torch.utils.data.datapipes.dataframe.datapipes.FilterDataFramesPipe(source_datapipe, filter_fn)
torch.utils.data.datapipes.dataframe.datapipes.IterDataPipe()
torch.utils.data.datapipes.dataframe.datapipes.PerRowDataFramesPipe(source_datapipe)
torch.utils.data.datapipes.dataframe.datapipes.ShuffleDataFramesPipe(source_datapipe)
torch.utils.data.datapipes.dataframe.datapipes.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.dataframe.structures.DataChunk(items)
torch.utils.data.datapipes.dataframe.structures.DataChunkDF(items)
torch.utils.data.datapipes.datapipe.Callable(*args, **kwargs)
torch.utils.data.datapipes.datapipe.DFIterDataPipe()
torch.utils.data.datapipes.datapipe.DataChunk(items)
torch.utils.data.datapipes.datapipe.Dataset()
torch.utils.data.datapipes.datapipe.Dict(*args, **kwargs)
torch.utils.data.datapipes.datapipe.Generic()
torch.utils.data.datapipes.datapipe.IterDataPipe()
torch.utils.data.datapipes.datapipe.IterableDataset()
torch.utils.data.datapipes.datapipe.Iterator(*args, **kwargs)
torch.utils.data.datapipes.datapipe.MapDataPipe()
torch.utils.data.datapipes.datapipe.Optional(*args, **kwds)
torch.utils.data.datapipes.datapipe.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.datapipe.import_dill()
torch.utils.data.datapipes.iter.Batcher(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, batch_size: int, drop_last: bool = False, wrapper_class=<class 'torch.utils.data.datapipes.datapipe.DataChunk'>) -> None
torch.utils.data.datapipes.iter.Collator(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, conversion: Union[Callable[..., Any], Dict[Union[str, Any], Union[Callable, Any]], NoneType] = <function default_collate at 0x0000024A61A6D120>, collate_fn: Optional[Callable] = None) -> None
torch.utils.data.datapipes.iter.Concater(*datapipes: torch.utils.data.datapipes.datapipe.IterDataPipe)
torch.utils.data.datapipes.iter.Demultiplexer(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, num_instances: int, classifier_fn: Callable[[+T_co], Optional[int]], drop_none: bool = False, buffer_size: int = 1000)
torch.utils.data.datapipes.iter.FileLister(root: Union[str, Sequence[str], torch.utils.data.datapipes.datapipe.IterDataPipe] = '.', masks: Union[str, List[str]] = '', *, recursive: bool = False, abspath: bool = False, non_deterministic: bool = False, length: int = -1) -> None
torch.utils.data.datapipes.iter.FileOpener(datapipe: Iterable[str], mode: str = 'r', encoding: Optional[str] = None, length: int = -1)
torch.utils.data.datapipes.iter.Filter(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, filter_fn: Callable, input_col=None) -> None
torch.utils.data.datapipes.iter.Forker(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, num_instances: int, buffer_size: int = 1000, copy: Optional[Literal['shallow', 'deep']] = None)
torch.utils.data.datapipes.iter.Grouper(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, group_key_fn: Callable[[+T_co], Any], *, keep_key: bool = False, buffer_size: int = 10000, group_size: Optional[int] = None, guaranteed_group_size: Optional[int] = None, drop_remaining: bool = False)
torch.utils.data.datapipes.iter.IterableWrapper(iterable, deepcopy=True)
torch.utils.data.datapipes.iter.Mapper(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, fn: Callable, input_col=None, output_col=None) -> None
torch.utils.data.datapipes.iter.Multiplexer(*datapipes)
torch.utils.data.datapipes.iter.RoutedDecoder(datapipe: Iterable[Tuple[str, io.BufferedIOBase]], *handlers: Callable, key_fn: Callable = <function extension_extract_fn at 0x0000024A61ABC4C0>) -> None
torch.utils.data.datapipes.iter.Sampler(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, sampler: Type[torch.utils.data.sampler.Sampler] = <class 'torch.utils.data.sampler.SequentialSampler'>, sampler_args: Optional[Tuple] = None, sampler_kwargs: Optional[Dict] = None) -> None
torch.utils.data.datapipes.iter.ShardingFilter(source_datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, sharding_group_filter=None)
torch.utils.data.datapipes.iter.Shuffler(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, *, buffer_size: int = 10000, unbatch_level: int = 0) -> None
torch.utils.data.datapipes.iter.StreamReader(datapipe, chunk=None)
torch.utils.data.datapipes.iter.UnBatcher(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, unbatch_level: int = 1)
torch.utils.data.datapipes.iter.Zipper(*datapipes: torch.utils.data.datapipes.datapipe.IterDataPipe)
torch.utils.data.datapipes.iter.callable.Any(*args, **kwds)
torch.utils.data.datapipes.iter.callable.Callable(*args, **kwargs)
torch.utils.data.datapipes.iter.callable.CollatorIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, conversion: Union[Callable[..., Any], Dict[Union[str, Any], Union[Callable, Any]], NoneType] = <function default_collate at 0x0000024A61A6D120>, collate_fn: Optional[Callable] = None) -> None
torch.utils.data.datapipes.iter.callable.Dict(*args, **kwargs)
torch.utils.data.datapipes.iter.callable.IterDataPipe()
torch.utils.data.datapipes.iter.callable.Iterator(*args, **kwargs)
torch.utils.data.datapipes.iter.callable.List(*args, **kwargs)
torch.utils.data.datapipes.iter.callable.MapperIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, fn: Callable, input_col=None, output_col=None) -> None
torch.utils.data.datapipes.iter.callable.Optional(*args, **kwds)
torch.utils.data.datapipes.iter.callable.Sized(*args, **kwargs)
torch.utils.data.datapipes.iter.callable.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.iter.callable.Union(*args, **kwds)
torch.utils.data.datapipes.iter.callable.default_collate(batch)
torch.utils.data.datapipes.iter.callable.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.callable.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
torch.utils.data.datapipes.iter.callable.validate_input_col(fn: Callable, input_col: Union[int, tuple, list, NoneType])
torch.utils.data.datapipes.iter.combinatorics.Dict(*args, **kwargs)
torch.utils.data.datapipes.iter.combinatorics.IterDataPipe()
torch.utils.data.datapipes.iter.combinatorics.Iterator(*args, **kwargs)
torch.utils.data.datapipes.iter.combinatorics.List(*args, **kwargs)
torch.utils.data.datapipes.iter.combinatorics.Optional(*args, **kwds)
torch.utils.data.datapipes.iter.combinatorics.Sampler(data_source: Optional[Sized] = None) -> None
torch.utils.data.datapipes.iter.combinatorics.SamplerIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, sampler: Type[torch.utils.data.sampler.Sampler] = <class 'torch.utils.data.sampler.SequentialSampler'>, sampler_args: Optional[Tuple] = None, sampler_kwargs: Optional[Dict] = None) -> None
torch.utils.data.datapipes.iter.combinatorics.SequentialSampler(data_source: Sized) -> None
torch.utils.data.datapipes.iter.combinatorics.ShufflerIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, *, buffer_size: int = 10000, unbatch_level: int = 0) -> None
torch.utils.data.datapipes.iter.combinatorics.Sized(*args, **kwargs)
torch.utils.data.datapipes.iter.combinatorics.Tuple(*args, **kwargs)
torch.utils.data.datapipes.iter.combinatorics.Type(*args, **kwargs)
torch.utils.data.datapipes.iter.combinatorics.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.iter.combinatorics.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.combining.ABC()
torch.utils.data.datapipes.iter.combining.Any(*args, **kwds)
torch.utils.data.datapipes.iter.combining.Callable(*args, **kwargs)
torch.utils.data.datapipes.iter.combining.ConcaterIterDataPipe(*datapipes: torch.utils.data.datapipes.datapipe.IterDataPipe)
torch.utils.data.datapipes.iter.combining.DemultiplexerIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, num_instances: int, classifier_fn: Callable[[+T_co], Optional[int]], drop_none: bool = False, buffer_size: int = 1000)
torch.utils.data.datapipes.iter.combining.Deque(*args, **kwargs)
torch.utils.data.datapipes.iter.combining.ForkerIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, num_instances: int, buffer_size: int = 1000, copy: Optional[Literal['shallow', 'deep']] = None)
torch.utils.data.datapipes.iter.combining.IterDataPipe()
torch.utils.data.datapipes.iter.combining.Iterator(*args, **kwargs)
torch.utils.data.datapipes.iter.combining.List(*args, **kwargs)
torch.utils.data.datapipes.iter.combining.Literal(*args, **kwds)
torch.utils.data.datapipes.iter.combining.MultiplexerIterDataPipe(*datapipes)
torch.utils.data.datapipes.iter.combining.Optional(*args, **kwds)
torch.utils.data.datapipes.iter.combining.Sized(*args, **kwargs)
torch.utils.data.datapipes.iter.combining.StreamWrapper(file_obj, parent_stream=None, name=None)
torch.utils.data.datapipes.iter.combining.Tuple(*args, **kwargs)
torch.utils.data.datapipes.iter.combining.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.iter.combining.ZipperIterDataPipe(*datapipes: torch.utils.data.datapipes.datapipe.IterDataPipe)
torch.utils.data.datapipes.iter.combining.abstractmethod(funcobj)
torch.utils.data.datapipes.iter.combining.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.filelister.FileListerIterDataPipe(root: Union[str, Sequence[str], torch.utils.data.datapipes.datapipe.IterDataPipe] = '.', masks: Union[str, List[str]] = '', *, recursive: bool = False, abspath: bool = False, non_deterministic: bool = False, length: int = -1) -> None
torch.utils.data.datapipes.iter.filelister.IterDataPipe()
torch.utils.data.datapipes.iter.filelister.IterableWrapper(iterable, deepcopy=True)
torch.utils.data.datapipes.iter.filelister.Iterator(*args, **kwargs)
torch.utils.data.datapipes.iter.filelister.List(*args, **kwargs)
torch.utils.data.datapipes.iter.filelister.Sequence(*args, **kwargs)
torch.utils.data.datapipes.iter.filelister.Union(*args, **kwds)
torch.utils.data.datapipes.iter.filelister.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.filelister.get_file_pathnames_from_root(root: str, masks: Union[str, List[str]], recursive: bool = False, abspath: bool = False, non_deterministic: bool = False) -> Iterable[str]
torch.utils.data.datapipes.iter.fileopener.FileOpenerIterDataPipe(datapipe: Iterable[str], mode: str = 'r', encoding: Optional[str] = None, length: int = -1)
torch.utils.data.datapipes.iter.fileopener.IterDataPipe()
torch.utils.data.datapipes.iter.fileopener.Iterable(*args, **kwargs)
torch.utils.data.datapipes.iter.fileopener.Optional(*args, **kwds)
torch.utils.data.datapipes.iter.fileopener.Tuple(*args, **kwargs)
torch.utils.data.datapipes.iter.fileopener.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.fileopener.get_file_binaries_from_pathnames(pathnames: Iterable, mode: str, encoding: Optional[str] = None)
torch.utils.data.datapipes.iter.grouping.Any(*args, **kwds)
torch.utils.data.datapipes.iter.grouping.BatcherIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, batch_size: int, drop_last: bool = False, wrapper_class=<class 'torch.utils.data.datapipes.datapipe.DataChunk'>) -> None
torch.utils.data.datapipes.iter.grouping.Callable(*args, **kwargs)
torch.utils.data.datapipes.iter.grouping.DataChunk(items)
torch.utils.data.datapipes.iter.grouping.DefaultDict(*args, **kwargs)
torch.utils.data.datapipes.iter.grouping.GrouperIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, group_key_fn: Callable[[+T_co], Any], *, keep_key: bool = False, buffer_size: int = 10000, group_size: Optional[int] = None, guaranteed_group_size: Optional[int] = None, drop_remaining: bool = False)
torch.utils.data.datapipes.iter.grouping.IterDataPipe()
torch.utils.data.datapipes.iter.grouping.Iterator(*args, **kwargs)
torch.utils.data.datapipes.iter.grouping.List(*args, **kwargs)
torch.utils.data.datapipes.iter.grouping.Optional(*args, **kwds)
torch.utils.data.datapipes.iter.grouping.Sized(*args, **kwargs)
torch.utils.data.datapipes.iter.grouping.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.iter.grouping.UnBatcherIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, unbatch_level: int = 1)
torch.utils.data.datapipes.iter.grouping.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.routeddecoder.Any(*args, **kwds)
torch.utils.data.datapipes.iter.routeddecoder.Callable(*args, **kwargs)
torch.utils.data.datapipes.iter.routeddecoder.Decoder(*handler, key_fn=<function extension_extract_fn at 0x0000024A61ABC4C0>)
torch.utils.data.datapipes.iter.routeddecoder.IterDataPipe()
torch.utils.data.datapipes.iter.routeddecoder.Iterable(*args, **kwargs)
torch.utils.data.datapipes.iter.routeddecoder.Iterator(*args, **kwargs)
torch.utils.data.datapipes.iter.routeddecoder.RoutedDecoderIterDataPipe(datapipe: Iterable[Tuple[str, io.BufferedIOBase]], *handlers: Callable, key_fn: Callable = <function extension_extract_fn at 0x0000024A61ABC4C0>) -> None
torch.utils.data.datapipes.iter.routeddecoder.Sized(*args, **kwargs)
torch.utils.data.datapipes.iter.routeddecoder.Tuple(*args, **kwargs)
torch.utils.data.datapipes.iter.routeddecoder.decoder_basichandlers(extension, data)
torch.utils.data.datapipes.iter.routeddecoder.decoder_imagehandler(imagespec)
torch.utils.data.datapipes.iter.routeddecoder.extension_extract_fn(pathname)
torch.utils.data.datapipes.iter.routeddecoder.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.selecting.Callable(*args, **kwargs)
torch.utils.data.datapipes.iter.selecting.FilterIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, filter_fn: Callable, input_col=None) -> None
torch.utils.data.datapipes.iter.selecting.IterDataPipe()
torch.utils.data.datapipes.iter.selecting.Iterator(*args, **kwargs)
torch.utils.data.datapipes.iter.selecting.StreamWrapper(file_obj, parent_stream=None, name=None)
torch.utils.data.datapipes.iter.selecting.Tuple(*args, **kwargs)
torch.utils.data.datapipes.iter.selecting.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.iter.selecting.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.selecting.validate_input_col(fn: Callable, input_col: Union[int, tuple, list, NoneType])
torch.utils.data.datapipes.iter.sharding.Dict(*args, **kwargs)
torch.utils.data.datapipes.iter.sharding.IntEnum(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.utils.data.datapipes.iter.sharding.IterDataPipe()
torch.utils.data.datapipes.iter.sharding.SHARDING_PRIORITIES(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe(source_datapipe: torch.utils.data.datapipes.datapipe.IterDataPipe, sharding_group_filter=None)
torch.utils.data.datapipes.iter.sharding.Sized(*args, **kwargs)
torch.utils.data.datapipes.iter.sharding.Tuple(*args, **kwargs)
torch.utils.data.datapipes.iter.sharding.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.streamreader.IterDataPipe()
torch.utils.data.datapipes.iter.streamreader.StreamReaderIterDataPipe(datapipe, chunk=None)
torch.utils.data.datapipes.iter.streamreader.Tuple(*args, **kwargs)
torch.utils.data.datapipes.iter.streamreader.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.iter.utils.IterDataPipe()
torch.utils.data.datapipes.iter.utils.IterableWrapperIterDataPipe(iterable, deepcopy=True)
torch.utils.data.datapipes.map.Batcher(datapipe: torch.utils.data.datapipes.datapipe.MapDataPipe[~T], batch_size: int, drop_last: bool = False, wrapper_class=<class 'torch.utils.data.datapipes.datapipe.DataChunk'>) -> None
torch.utils.data.datapipes.map.Concater(*datapipes: torch.utils.data.datapipes.datapipe.MapDataPipe)
torch.utils.data.datapipes.map.Mapper(datapipe: torch.utils.data.datapipes.datapipe.MapDataPipe, fn: Callable = <function default_fn at 0x0000024A61ABDC60>) -> None
torch.utils.data.datapipes.map.SequenceWrapper(sequence, deepcopy=True)
torch.utils.data.datapipes.map.Shuffler(datapipe: torch.utils.data.datapipes.datapipe.MapDataPipe[+T_co], *, indices: Optional[List] = None) -> None
torch.utils.data.datapipes.map.Zipper(*datapipes: torch.utils.data.datapipes.datapipe.MapDataPipe[+T_co]) -> None
torch.utils.data.datapipes.map.callable.Callable(*args, **kwargs)
torch.utils.data.datapipes.map.callable.MapDataPipe()
torch.utils.data.datapipes.map.callable.MapperMapDataPipe(datapipe: torch.utils.data.datapipes.datapipe.MapDataPipe, fn: Callable = <function default_fn at 0x0000024A61ABDC60>) -> None
torch.utils.data.datapipes.map.callable.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.map.callable.default_fn(data)
torch.utils.data.datapipes.map.callable.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.map.combinatorics.IterDataPipe()
torch.utils.data.datapipes.map.combinatorics.Iterator(*args, **kwargs)
torch.utils.data.datapipes.map.combinatorics.List(*args, **kwargs)
torch.utils.data.datapipes.map.combinatorics.MapDataPipe()
torch.utils.data.datapipes.map.combinatorics.Optional(*args, **kwds)
torch.utils.data.datapipes.map.combinatorics.ShufflerIterDataPipe(datapipe: torch.utils.data.datapipes.datapipe.MapDataPipe[+T_co], *, indices: Optional[List] = None) -> None
torch.utils.data.datapipes.map.combinatorics.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.map.combining.ConcaterMapDataPipe(*datapipes: torch.utils.data.datapipes.datapipe.MapDataPipe)
torch.utils.data.datapipes.map.combining.MapDataPipe()
torch.utils.data.datapipes.map.combining.Sized(*args, **kwargs)
torch.utils.data.datapipes.map.combining.Tuple(*args, **kwargs)
torch.utils.data.datapipes.map.combining.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.map.combining.ZipperMapDataPipe(*datapipes: torch.utils.data.datapipes.datapipe.MapDataPipe[+T_co]) -> None
torch.utils.data.datapipes.map.combining.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.map.grouping.BatcherMapDataPipe(datapipe: torch.utils.data.datapipes.datapipe.MapDataPipe[~T], batch_size: int, drop_last: bool = False, wrapper_class=<class 'torch.utils.data.datapipes.datapipe.DataChunk'>) -> None
torch.utils.data.datapipes.map.grouping.DataChunk(items)
torch.utils.data.datapipes.map.grouping.List(*args, **kwargs)
torch.utils.data.datapipes.map.grouping.MapDataPipe()
torch.utils.data.datapipes.map.grouping.Sized(*args, **kwargs)
torch.utils.data.datapipes.map.grouping.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.datapipes.map.grouping.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.datapipes.map.utils.MapDataPipe()
torch.utils.data.datapipes.map.utils.SequenceWrapperMapDataPipe(sequence, deepcopy=True)
torch.utils.data.datapipes.utils.common.Any(*args, **kwds)
torch.utils.data.datapipes.utils.common.Callable(*args, **kwargs)
torch.utils.data.datapipes.utils.common.Dict(*args, **kwargs)
torch.utils.data.datapipes.utils.common.Iterable(*args, **kwargs)
torch.utils.data.datapipes.utils.common.List(*args, **kwargs)
torch.utils.data.datapipes.utils.common.Optional(*args, **kwds)
torch.utils.data.datapipes.utils.common.StreamWrapper(file_obj, parent_stream=None, name=None)
torch.utils.data.datapipes.utils.common.Tuple(*args, **kwargs)
torch.utils.data.datapipes.utils.common.Union(*args, **kwds)
torch.utils.data.datapipes.utils.common.dill_available()
torch.utils.data.datapipes.utils.common.get_file_binaries_from_pathnames(pathnames: Iterable, mode: str, encoding: Optional[str] = None)
torch.utils.data.datapipes.utils.common.get_file_pathnames_from_root(root: str, masks: Union[str, List[str]], recursive: bool = False, abspath: bool = False, non_deterministic: bool = False) -> Iterable[str]
torch.utils.data.datapipes.utils.common.match_masks(name: str, masks: Union[str, List[str]]) -> bool
torch.utils.data.datapipes.utils.common.validate_input_col(fn: Callable, input_col: Union[int, tuple, list, NoneType])
torch.utils.data.datapipes.utils.common.validate_pathname_binary_tuple(data: Tuple[str, io.IOBase])
torch.utils.data.datapipes.utils.decoder.Decoder(*handler, key_fn=<function extension_extract_fn at 0x0000024A61ABC4C0>)
torch.utils.data.datapipes.utils.decoder.ImageHandler(imagespec)
torch.utils.data.datapipes.utils.decoder.MatHandler(**loadmat_kwargs) -> None
torch.utils.data.datapipes.utils.decoder.StreamWrapper(file_obj, parent_stream=None, name=None)
torch.utils.data.datapipes.utils.decoder.audiohandler(extension, data)
torch.utils.data.datapipes.utils.decoder.basichandlers(extension, data)
torch.utils.data.datapipes.utils.decoder.extension_extract_fn(pathname)
torch.utils.data.datapipes.utils.decoder.handle_extension(extensions, f)
torch.utils.data.datapipes.utils.decoder.imagehandler(imagespec)
torch.utils.data.datapipes.utils.decoder.mathandler(**loadmat_kwargs)
torch.utils.data.datapipes.utils.decoder.videohandler(extension, data)
torch.utils.data.dataset.ChainDataset(datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None
torch.utils.data.dataset.ConcatDataset(datasets: Iterable[torch.utils.data.dataset.Dataset]) -> None
torch.utils.data.dataset.Dataset()
torch.utils.data.dataset.Dict(*args, **kwargs)
torch.utils.data.dataset.Generic()
torch.utils.data.dataset.Iterable(*args, **kwargs)
torch.utils.data.dataset.IterableDataset()
torch.utils.data.dataset.List(*args, **kwargs)
torch.utils.data.dataset.Optional(*args, **kwds)
torch.utils.data.dataset.Sequence(*args, **kwargs)
torch.utils.data.dataset.StackDataset(*args: torch.utils.data.dataset.Dataset[+T_co], **kwargs: torch.utils.data.dataset.Dataset[+T_co]) -> None
torch.utils.data.dataset.Subset(dataset: torch.utils.data.dataset.Dataset[+T_co], indices: Sequence[int]) -> None
torch.utils.data.dataset.T_dict(*args, **kwargs)
torch.utils.data.dataset.T_tuple(*args, **kwargs)
torch.utils.data.dataset.TensorDataset(*tensors: torch.Tensor) -> None
torch.utils.data.dataset.Tuple(*args, **kwargs)
torch.utils.data.dataset.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.dataset.Union(*args, **kwds)
torch.utils.data.dataset.cast(typ, val)
torch.utils.data.dataset.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.utils.data.dataset.random_split(dataset: torch.utils.data.dataset.Dataset[~T], lengths: Sequence[Union[int, float]], generator: Optional[torch._C.Generator] = <torch._C.Generator object at 0x0000024A60E11E50>) -> List[torch.utils.data.dataset.Subset[~T]]
torch.utils.data.default_collate(batch)
torch.utils.data.default_convert(data)
torch.utils.data.distributed.Dataset()
torch.utils.data.distributed.DistributedSampler(dataset: torch.utils.data.dataset.Dataset, num_replicas: Optional[int] = None, rank: Optional[int] = None, shuffle: bool = True, seed: int = 0, drop_last: bool = False) -> None
torch.utils.data.distributed.Iterator(*args, **kwargs)
torch.utils.data.distributed.Optional(*args, **kwds)
torch.utils.data.distributed.Sampler(data_source: Optional[Sized] = None) -> None
torch.utils.data.distributed.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.functional_datapipe(name: str, enable_df_api_tracing=False) -> None
torch.utils.data.get_worker_info() -> Optional[torch.utils.data._utils.worker.WorkerInfo]
torch.utils.data.graph.Collection()
torch.utils.data.graph.DataPipe(*args, **kwargs)
torch.utils.data.graph.DataPipeGraph(*args, **kwargs)
torch.utils.data.graph.Dict(*args, **kwargs)
torch.utils.data.graph.IterDataPipe()
torch.utils.data.graph.List(*args, **kwargs)
torch.utils.data.graph.MapDataPipe()
torch.utils.data.graph.Optional(*args, **kwds)
torch.utils.data.graph.Set(*args, **kwargs)
torch.utils.data.graph.Tuple(*args, **kwargs)
torch.utils.data.graph.Type(*args, **kwargs)
torch.utils.data.graph.Union(*args, **kwds)
torch.utils.data.graph.dill_available()
torch.utils.data.graph.traverse(datapipe: Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], only_datapipe: Optional[bool] = None) -> Dict[int, Tuple[Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], ForwardRef('DataPipeGraph')]]
torch.utils.data.graph.traverse_dps(datapipe: Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]) -> Dict[int, Tuple[Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], ForwardRef('DataPipeGraph')]]
torch.utils.data.graph_settings.Any(*args, **kwds)
torch.utils.data.graph_settings.DataPipe(*args, **kwargs)
torch.utils.data.graph_settings.DataPipeGraph(*args, **kwargs)
torch.utils.data.graph_settings.List(*args, **kwargs)
torch.utils.data.graph_settings.Optional(*args, **kwds)
torch.utils.data.graph_settings.SHARDING_PRIORITIES(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.utils.data.graph_settings.Set(*args, **kwargs)
torch.utils.data.graph_settings.apply_random_seed(datapipe: Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], rng: torch._C.Generator) -> Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]
torch.utils.data.graph_settings.apply_sharding(datapipe: Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], num_of_instances: int, instance_id: int, sharding_group=<SHARDING_PRIORITIES.DEFAULT: 1>) -> Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]
torch.utils.data.graph_settings.apply_shuffle_seed(datapipe: Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], rng: Any) -> Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]
torch.utils.data.graph_settings.apply_shuffle_settings(datapipe: Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], shuffle: Optional[bool] = None) -> Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]
torch.utils.data.graph_settings.deprecated(message: str, /, *, category: Optional[Type[Warning]] = <class 'DeprecationWarning'>, stacklevel: int = 1) -> None
torch.utils.data.graph_settings.get_all_graph_pipes(graph: Dict[int, Tuple[Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], ForwardRef('DataPipeGraph')]]) -> List[Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]]
torch.utils.data.graph_settings.traverse_dps(datapipe: Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe]) -> Dict[int, Tuple[Union[torch.utils.data.datapipes.datapipe.IterDataPipe, torch.utils.data.datapipes.datapipe.MapDataPipe], ForwardRef('DataPipeGraph')]]
torch.utils.data.guaranteed_datapipes_determinism() -> None
torch.utils.data.non_deterministic(arg: Union[Type[torch.utils.data.datapipes.datapipe.IterDataPipe], Callable[[], bool]]) -> None
torch.utils.data.random_split(dataset: torch.utils.data.dataset.Dataset[~T], lengths: Sequence[Union[int, float]], generator: Optional[torch._C.Generator] = <torch._C.Generator object at 0x0000024A60E11E50>) -> List[torch.utils.data.dataset.Subset[~T]]
torch.utils.data.runtime_validation(f)
torch.utils.data.runtime_validation_disabled() -> None
torch.utils.data.sampler.BatchSampler(sampler: Union[torch.utils.data.sampler.Sampler[int], Iterable[int]], batch_size: int, drop_last: bool) -> None
torch.utils.data.sampler.Generic()
torch.utils.data.sampler.Iterable(*args, **kwargs)
torch.utils.data.sampler.Iterator(*args, **kwargs)
torch.utils.data.sampler.List(*args, **kwargs)
torch.utils.data.sampler.Optional(*args, **kwds)
torch.utils.data.sampler.RandomSampler(data_source: Sized, replacement: bool = False, num_samples: Optional[int] = None, generator=None) -> None
torch.utils.data.sampler.Sampler(data_source: Optional[Sized] = None) -> None
torch.utils.data.sampler.Sequence(*args, **kwargs)
torch.utils.data.sampler.SequentialSampler(data_source: Sized) -> None
torch.utils.data.sampler.Sized(*args, **kwargs)
torch.utils.data.sampler.SubsetRandomSampler(indices: Sequence[int], generator=None) -> None
torch.utils.data.sampler.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False)
torch.utils.data.sampler.Union(*args, **kwds)
torch.utils.data.sampler.WeightedRandomSampler(weights: Sequence[float], num_samples: int, replacement: bool = True, generator=None) -> None
torch.utils.dlpack.Any(*args, **kwds)
torch.utils.dlpack.DLDeviceType(value, names=None, *, module=None, qualname=None, type=None, start=1)
torch.utils.dlpack.from_dlpack(ext_tensor: Any) -> 'torch.Tensor'
torch.utils.generate_methods_for_privateuse1_backend(for_tensor: bool = True, for_module: bool = True, for_packed_sequence: bool = True, for_storage: bool = False, unsupported_dtype: Optional[List[torch.dtype]] = None) -> None
torch.utils.get_cpp_backtrace(frames_to_skip=0, maximum_number_of_frames=64) -> str
torch.utils.hooks.Any(*args, **kwds)
torch.utils.hooks.BackwardHook(module, user_hooks, user_pre_hooks)
torch.utils.hooks.RemovableHandle(hooks_dict: Any, *, extra_dict: Any = None) -> None
torch.utils.hooks.Tuple(*args, **kwargs)
torch.utils.hooks.unserializable_hook(f)
torch.utils.hooks.warn_if_has_hooks(tensor)
torch.utils.rename_privateuse1_backend(backend_name: str) -> None
torch.utils.set_module(obj, mod)
torch.utils.swap_tensors(t1, t2)
torch.utils.throughput_benchmark.ExecutionStats(c_stats, benchmark_config)
torch.utils.throughput_benchmark.ThroughputBenchmark(module)
torch.utils.throughput_benchmark.format_time(time_us=None, time_ms=None, time_s=None)
torch.utils.weak.Mapping()
torch.utils.weak.MutableMapping()
torch.utils.weak.TensorWeakRef(tensor: 'Tensor')
torch.utils.weak.WeakIdKeyDictionary(dict=None, ref_type=<class 'torch.utils.weak.WeakIdRef'>)
torch.utils.weak.WeakIdRef(key, callback=None)
torch.utils.weak.WeakTensorKeyDictionary(dict=None, ref_type=<class 'torch.utils.weak.WeakIdRef'>)
torch.version.Optional(*args, **kwds)
torch.vmap(func: Callable, in_dims: Union[int, Tuple] = 0, out_dims: Union[int, Tuple[int, ...]] = 0, randomness: str = 'error', *, chunk_size=None) -> Callable
torch.xpu.Any(*args, **kwds)
torch.xpu.Callable(*args, **kwargs)
torch.xpu.Dict(*args, **kwargs)
torch.xpu.Event(enable_timing=False)
torch.xpu.List(*args, **kwargs)
torch.xpu.Optional(*args, **kwds)
torch.xpu.Stream(device=None, priority=0, **kwargs)
torch.xpu.StreamContext(stream: Optional[ForwardRef('torch.xpu.Stream')])
torch.xpu.Tuple(*args, **kwargs)
torch.xpu.Union(*args, **kwds)
torch.xpu.current_device() -> int
torch.xpu.current_stream(device: Union[torch.device, str, int, NoneType] = None) -> torch.xpu.streams.Stream
torch.xpu.device(device: Any)
torch.xpu.device_count() -> int
torch.xpu.device_of(obj)
torch.xpu.empty_cache() -> None
torch.xpu.get_device_capability(device: Union[torch.device, str, int, NoneType] = None) -> Dict[str, Any]
torch.xpu.get_device_name(device: Union[torch.device, str, int, NoneType] = None) -> str
torch.xpu.get_device_properties(device: Union[torch.device, str, int, NoneType] = None) -> torch._utils._XpuDeviceProperties
torch.xpu.get_rng_state(device: Union[int, str, torch.device] = 'xpu') -> torch.Tensor
torch.xpu.get_rng_state_all() -> List[torch.Tensor]
torch.xpu.init()
torch.xpu.initial_seed() -> int
torch.xpu.is_available() -> bool
torch.xpu.is_bf16_supported()
torch.xpu.is_initialized()
torch.xpu.lru_cache(maxsize=128, typed=False)
torch.xpu.manual_seed(seed: int) -> None
torch.xpu.manual_seed_all(seed: int) -> None
torch.xpu.seed() -> None
torch.xpu.seed_all() -> None
torch.xpu.set_device(device: Union[torch.device, str, int, NoneType]) -> None
torch.xpu.set_rng_state(new_state: torch.Tensor, device: Union[int, str, torch.device] = 'xpu') -> None
torch.xpu.set_rng_state_all(new_states: Iterable[torch.Tensor]) -> None
torch.xpu.set_stream(stream: torch.xpu.streams.Stream)
torch.xpu.stream(stream: Optional[ForwardRef('torch.xpu.Stream')]) -> torch.xpu.StreamContext
torch.xpu.streams.Event(enable_timing=False)
torch.xpu.streams.Stream(device=None, priority=0, **kwargs)
torch.xpu.synchronize(device: Union[torch.device, str, int, NoneType] = None) -> None
